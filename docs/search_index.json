[
["index.html", "A Reader on Data Visualization Chapter 1 Preface 1.1 References 1.2 Images 1.3 Basic Guidelines", " A Reader on Data Visualization MSIS 2629 Spring 2018 2018-05-29 Chapter 1 Preface This is a collaborative writing project as part of the course MSIS 2629 “Data Visualization” at Santa Clara University. The purpose of the class reader is to collaboratively engage with and reflect on data visualizations, to establish a solid theoretical background, and to collect useful practices and showcases. More information on the background of this project is available in the syllabus. The following text serves explains how we organize ourselves. 1.1 References EVERY references must be included in the book.bib file. This file uses the BibTeX notation (Learn how to use BibTeX here.). Most literature search engines allow you to export the reference information in BibTeX. For websites we use the following minimal notation (you may add further information - usually the more the better is a good strategy): @misc{great_viz, author = {{A great visualizer}}, year = {1982}, title = {A ficticious web page title}, howpublished = {\\url{http://great_viz_org/}}, note = {Accessed: 2018-04-26} } Particularly important is the note field. Websites change frequently, so links will break. If we do this correctly, [@great_viz] will produce [@great_viz]. 1.2 Images Images should not be loaded from external website because the links may change. Instead download a version of the image and create a reference that contains the link to the image. For example the following image is a deceptive visualization (the bars do start at zero). An Example of a deceptive visualization Source: [@halper_2012] referenced in [@andale_2014] The citation for the image looks like this. @misc{halper_2012, author={Halper, Daniel}, year={2012}, title = {Over 100 Million Now Receiving Federal Welfare}, url={https://www.weeklystandard.com/daniel-halper/over-100-million-now-receiving-federal-welfare}, note = {Accessed: 2018-04-26} } You have probably found this image through a different website that explains the visualization. For example the following website explains some problematic aspects of this visualization: @misc{andale_2014, author={Andalde, Stephanie}, year={2014}, title = {Misleading Graphs: Real Life Examples}, url={http://www.statisticshowto.com/misleading-graphs/}, note = {Accessed: 2018-04-26} } 1.3 Basic Guidelines Figures and tables with captions will be placed in figure and table environments, respectively.–&gt; par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 1.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 1.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 1.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 1.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package [@R-bookdown] in this sample book, which was built on top of R Markdown and knitr [@xie2015]. "],
["introduction.html", "Chapter 2 Introduction 2.1 What is Data Visualization? 2.2 Why is Data Visualization Important? 2.3 Data Visualizations in Industry 2.4 A Brief History of Data Visualization 2.5 Key Figures in the History of Data Visualization 2.6 Contemporary Visualists 2.7 Additional Resources for Aspiring Data Visualists", " Chapter 2 Introduction 2.1 What is Data Visualization? Data visualization refers to representing data in a visual context to help people understand the significance of that data. It helps to reveal insights and patterns that are not immediately visible in the raw data. It is an art through which information, numbers, and measurements can be made more understandable. According to [@viz]: The main goal of data visualization is to communicate information clearly and effectively through graphical means. It doesn’t mean that data visualization needs to look boring to be functional or extremely sophisticated to look beautiful. To convey ideas effectively, both aesthetic form and functionality need to go hand in hand, providing insights into a rather sparse and complex data set by communicating its key-aspects in a more intuitive way. Information visualization is the art of representing data so that it is easy to understand and manipulate, thus making the information useful. Visualization can make sense of information by helping to find relationships in the data and supporting (or disproving) ideas about the data. [@info_viz] shares some examples and common uses of information visualization, such as: Presentation: to explain or persuade Exploratory Analysis: to identify relationships or special cases in the data Confirmatory Analysis: to confirm our understanding and analysis of the data 2.2 Why is Data Visualization Important? The enormous volume of data available to companies, governments and people today means there is a huge (and growing) need for data to be presented so that it delivers value. From business decision making to route navigation, data visualization provides a simple, user-friendly approach to understanding data and making faster, better decisions. In his article on the importance of data visualization to businesses, Chris Pittenturf uses the example of an energy bill to explain the impact of data visualization: before we even read the text of the bill, we look at the graph first [@viz_importance]. This simple example demonstrates that data visualization is in every part of our daily lives and that we are more likely to analyze and understand the visualizations before reading further along. Pittenturf further explains most data used by businesses is highly unstructured, so visualization provides better understanding of the complex insights coming from this information. Visuals help us understand concepts that would otherwise be difficult to contextualize. In his TED talk, David McCandless gives an example of how expenditures or valuations of extremely large amounts of money are represented in the billion dollar-o-gram by color-coded, relatively-sized boxes. This allows the synthesis of a breadth of information to be delivered in a small, easily-digestible and aesthetically pleasing way. Visuals serve as a sort of map for a vast landscape of information—they direct your eyes to the important places and details. And the eye, as McCandless notes, is uniquely suited among our senses to process large amounts of information and detect patterns [@viz_ted]. (The billion dollar-o-gram is extremely readable and rather pretty, but it seems a bit dubious to compare the predicted Iraq War cost to the “mushroomed” actual cost of Iraq and Afghanistan wars, since its purpose seems only to conflate two wars for dramatic effect.) Beyond its ability to make information from several different sources and in large amounts easily understandable, data visualization can also reveal smaller interesting patterns, allowing us to play the “data detective” as McCandless calls it. In other words, as we have already discussed, data visualization can not only be extremely effective in a declarative manner, but can also be used as an exploratory tool [@viz_ted]. McCandless also postulates that we all have a latent “design literacy” that is being developed every day as we are constantly bombarded with visuals, and that our minds and our eyes are taking in this information and processing it so that we all have an intuitive sense of design, and have actually begun to demand a visual aspect to our information. This is an interesting perspective, since everyone does seem to have a sense of visual aspects like space, color, etc. Of course, the time-honored adage tells us that beauty is in the eye of the beholder, so while it might be whimsical to claim that we are all designers, there is still great value in learning formal principles of design [@viz_ted]. To that end, Pittenturf explains basic criteria that a data visualization should satisfy in order to be effective [@viz_importance]: Criteria Description Informative The visualization should be able to convey the desired information from the data to the reader. Efficient The visualization should not be ambiguous. Appealing The visualization should be captivating and visually pleasing. Interactive and Predictive (Optional) The visualizations can contain variables and filters with which the users may interact in order to predict results of different scenarios. Pittenturf goes on to give various day-to-day examples where visualization gives a better understanding of the data. One extremely simple example used by Pittenturf is that of an energy bill. Pittenturf states that when we, as consumers, receive an energy bill, we normally look at the graph in the bill first before proceeding to read the text in the bill. Pittenturf states that consumers are more likely to analyze and understand the visualizations before reading further along. The article ends with Pittenturf emphasizing the importance of data visualizations in our businesses as well as in our daily lives. It gives a simple, short and crisp understanding of what data visualization is and how it is relevant to everyone. Data visualization is an aid to get a better understanding of the complex insights that any business data provides. Most of the data used by the businesses is highly unstructured and these businesses can get a better understanding of their businesses by visualizing their data. 2.3 Data Visualizations in Industry Companies tend to rely on dashboards (a compilation of several related data visualizations) to give them high-level insights on company-wide, market-level, or employee-level performance. The following are some common applications of dashboards in business. Application Description Sales &amp; Marketing This is one of the most popular uses for dashboards. Companies like to regularly track their revenue, conversions, lead sources, etc. and rely on data visualization to synthesize these large and constantly updated data into visual summaries. Customer Success These dashboards can be created by the team, but are also often built into customer service platforms such as Zendesk. They include various KPIs of the customer success team, such as the ratio of tickets open to tickets closed and time to resolution. Product Management These dashboards tend to synthesize sales, marketing, and customer research data together and are typically used for executive reporting. The visuals display metrics such as dollars and hours devoted to various projects and most requested features by customers. Data visualization is also used across many different industries. One popular area right now is healthcare, especially involving big data. The benefits and uses of interactive data viz are detailed in a paper from the University of Maryland (2013). [@data_viz_healthcare] The paper highlights three types of data that can and should be visualized to help in decision-making: personal, clinical, and public health information. Examples include: exploration of prescription patterns of different drugs and tracking personal health and fitness statistics. (Even the nice, clean Fitbit app home screen is a comprehensive dashboard!) Importantly, making sense of all this data collected from individuals will help healthcare organizations and companies provide more personalized and effective health treatment. 2.4 A Brief History of Data Visualization “The only new thing in the world is the history you don’t know.” — Harry S Truman 2.4.1 Data Visualization: A Modern Product? Given the recent explosion in data availability and in visualization tools, it would be natural to assume that statistical graphics and data visualizations are relatively modern developments. However, the graphic representation of quantitative information has deep roots that reach into the histories of the earliest map-making and visual depictions, and up to thematic cartography, statistics, medicine, and other fields. Developments in technologies (printing, reproduction) mathematical theory and practice, and empirical observation and recording, and those developments enabled the wider use of graphics and new advances in form and content. This paper provides an overview of the intellectual history of data visualization from medieval to modern times, as well as describes and illustrates some significant advances along the way [@data_viz_history]. Time Phase Description Pre-17th Century Early Maps and Diagrams Data visualization has come a long way. Prior to the 17th century, data visualization already existed. Though displayed in other format such as maps, the content is much similar to today’s visualizations, which mostly presented geologic, economic, and medical data. The earliest seeds of visualization arose in geometric diagrams, in tables of the positions of stars and other celestial bodies, and in the making of maps to aid in navigation and exploration. 1600-1699 Measurement and Theory Among the most important problems of the 17th century were those concerned with physical measurement of time, distance, and space for astronomy, surveying, map making, navigation and territorial expansion. This century also saw considerable new growth in theory as well as the dawn of practical application. 1700-1799 New Graphic Forms With some rudiments of statistical theory, data of interest and importance, and the idea of graphic representation somewhat established, the 18th century witnessed the expansion of these aspects to new domains and new graphic forms. 1800-1850 Beginnings of Modern Graphics With the foundation provided by the previous innovations of design and technique, the first half of the 19th century witnessed explosive growth in statistical graphics and thematic mapping at a rate which would not be equaled until modern times. 1850–1900 The Golden Age of Statistical Graphics By the mid-1800s, all the conditions for the rapid growth of visualization had generated a “perfect storm” for data graphics. Official state statistical offices were established throughout Europe, in recognition of the growing importance of numerical information for social planning,industrialization, commerce, and transportation. 1900-1950 The Modern Dark Ages If the late 1800s were the “golden age” of statistical graphics and thematic cartography, the early 1900s can be called the “modern dark ages” of visualization. There were few graphical innovations, and by the mid-1930s, the enthusiasm for visualization which characterized the late 1800s had been supplanted by the rise of quantification and formal, often statistical, models in the social sciences. 1950–1975 Rebirth of Data Visualization Still under the influence of the formal and numerical zeitgeist from the mid-1930s on, data visualization began to rise from dormancy in the mid 1960s. 1975–present High-D, Interactive and Dynamic Data Visualization During the last quarter of the 20th century, data visualization has blossomed into a mature, vibrant and multidisciplinary area of research, as seen in this handbook, and software tools for a wide range of visualization methods and data types are available for every computer. 2.5 Key Figures in the History of Data Visualization The history of data visualization is full of incredible stories marked by major events, led by a few key players. The article [@history_viz] introduces some of the amazing men and women who paved the way by combining art, science, and statistics. One of them is Charles Joseph Minard, whose most famous work is the map of Napoleon’s Russian campaign of 1812 which could be used as a data product for Data Visualization. Below we have some visualists with their famous works, and other stories in the article [@history_viz]. 2.5.1 William Playfair (1759–1823) William Playfair is considered the father of statistical graphics, having invented the line and bar chart we use so often today. He is also credited with having created the area and pie chart. Playfair was a Scottish engineer and political economist who published “The Commercial and Political Atlas” in 1786. This book featured a variety of graphs including the image below. In this famous example, he compares exports from England with imports into England from Denmark and Norway from 1700 to 1780 [@history_data_viz]. 2.5.2 John Snow (1813–1858) In 1854, a cholera epidemic spread quickly through Soho in London. The Broad Street area had seen over 600 dead, and the surviving residents and business owners had largely fled the terrible disease. Physician John Snow plotted the locations of cholera deaths on a map. The surviving maps of his work show a method of tallying the death counts, drawn as lines parallel to the street, at the appropriate addresses. Snow’s research revealed a pattern. He saw a clear concentration around the water pump on Broad Street, which helped find the cause of the infection. 2.5.3 Charles Joseph Minard (1781–1870) Charles Joseph Minard was a French civil engineer famous for his representation of numerical data on maps. His most famous work is the map of Napoleon’s Russian campaign of 1812 illustrating the dramatic loss of his army over the advance on Moscow and the following retreat.This classic lithograph dates back to 1869, displaying the number of men in Napoleon’s 1812 Russian army, their movements, and the temperatures they encountered along their way. It’s been called one of the “best statistical drawings ever created.” The work is an important reminder that the fundamentals of data visualization lie in a nuanced understanding of the many dimensions of data. Tools like D3.js and HTML are no good without a firm grasp of your dataset and sharp communication skills.It represents the earliest beginning of data journalism. 2.6 Contemporary Visualists 2.6.1 Hans Rosling Hans Rosling took his interest in global health and developed stunning visualizations about it using statistical methods and data from the UN. He was a noted TED speaker and one of his most interesting TED talks is “Asia’s Rise: How and When” [@hans]. In this video, Hans shows trends of the Western countries vs Developing countries like India and China and makes predictions using stunning visualizations like the Bubble chart. He also predicts the exact date on which India and China will move ahead of USA as strong economic forces. Hans was the co-founder and developer of the foundation “Gapminder” which develops tools to help the people make sense of global data [@gapminder]. One of the most important goals of Gapminder foundation is to end ignorance in the world by developing fact-based visualizations to show how the world really is [@gapminder]. 2.6.2 David McCandless David McCandless is a British data-journalist and his blog “Information is Beautiful” [@info_beautiful] hosts some of the most visually stunning graphs, charts, and maps on a wide range of topics like science, food, dogs and countries. One such chart, “International Number Ones: Because every country is good at something (according to data),” is a captivating work that displays something each country is the best at [@country_chart]. The visualizations on this website are updated and revised whenever new data is available. 2.7 Additional Resources for Aspiring Data Visualists Data visualization domain is huge and an aspiring visualist, a person who has the capability to link between storytelling and data-experience design can further broaden his/her knowledge through: 2.7.1 Tableau Community [@Tableau_Community] helps you to explore Tableau further : It will help us enhance our learning Get answers for most of your doubts In tableau Post new questions and crowd source answers Attend events, seminars and join conferences conducted locally/ globally Give back to the community once you become an expert in that field There are very active Tableau social media groups [@LinkedIn_Groups]: Tableau Enthusiasts: LinkedIn Group (19K members) Tableau Software Fans &amp; Friends: LinkedIn Group (45k members) 2.7.2 Blogs Here is a list of the top blogs that Tableau itself suggests to follow [@Top_10_Blogs]: Storytelling with Data Information is Beautiful Flowing Data Visualizing Data Junk Charts The Pudding The Atlas Graphic Detail Tableau Blog 2.7.3 Resources for Trends, News, Resources and Opinions of Data Visualization Beautiful Data Improving data visualisation for the public sector Michael Sandberg’s Data Visualization Blog US Census FEMA 2.7.4 Useful Links on Data Visualization Trends, Tutorials and Research Papers Resource Description Link [@charts_viz] You can find different types of plots used in data visualization https://datavizcatalogue.com. [@eagereyes_viz] Robert Kosara’s website which contains recent developments happening in visualization and are likely to have an impact. [@research_viz] About Robert Kosara and his research papers. [@twitter_Kosara] Robert Kosara’s twitter handle. [@flowingdata] Website which offers courses, tutorials and happenings in viz. http://flowingdata.com/ [@infogram] An infogram helps a user making different types of plots and learning the art of visualization. Engaging infographics, reports, charts, dashboards and maps can be easily created in minutes with it. 2.7.5 Infographics Data visualization and infographics both present visual information to users. Although they look similar in their purpose there can be different use cases where each one can be used. In this article we will go over the differences between infographics and data visualization [@VIZVSINFO]. 2.7.5.1 Data Visualization Data visualization is mostly related to summary statistics related to data presented in a visual form such as graphs, plots or charts. Focus of data visualization is on two things: data and design and it provides more clear information about the summary of your research. An important aspect of data visualization is design which should be based on the data itself. For example, for a particular data set which type of graph, chart or plot would make most sense. Since visualizations are important in telling stories (such as trending) it should not distract the users. The visualization should be self-explanatory and users should be able to draw conclusion on their own. 2.7.5.2 Infographics Infographics is a combination of different this which include illustrations, facts and text. All these combined together tell users a visual story. Infographics might include few components which are from data visualization. Infographics convey multiple ideas together; the design should be visually appealing and should complement the visual story. 2.7.5.3 When Should You Use Infographics or Data Visualization? Each of these have their own use cases but more often than not they can be used together. Some of the effective ways to choose one is described below. Data Visualization: Newsletters: Newsletter for the most part have to be on target so that it catches eyes of the viewer. Putting good data visualization in newsletters makes it more interesting with detail such as company’s unique findings, statistics, or status. White papers &amp; eBooks: Include data visualization to help prove the points you make in the document to influence your readers. Annual Reports: Things like overview of past year, success stories, company performance can be all done well using data visualization. Infographics: Blog Posts: Blog posts are generally written for specific purpose. Including infographics would resound the point you are trying to make. Case Studies: Paired with a study of a particular context, an infographic can provide engaging visuals and succinctly summarize a lengthy report, offering valuable insights to your readers. Marketing Content: Marketing content generally tells a story. Best way to tell a story is using proper infographics. These can be great for social media campaigns as infographics can contain all the main points. 2.1 The History of Data Visualization Author: Dashboard Insight, Dashboard Insight, 2013 URL: http://www.dashboardinsight.com/news/news-articles/the-history-of-data-visualization.aspx 2.2 Current research: Deceptive visualizations Author: Infogram, 2016 URL:https://medium.com/@Infogram/study-asks-how-deceptive-are-deceptive-visualizations-8ff52fd81239 Author: Agata Kwapien in Data Visualization, 2015 URL: https://www.datapine.com/blog/misleading-data-visualization-examples/ 2.3 A Brief History of Data Visualization, York University. Auhtor: Michael Friendly, 2006 URL:http://www.datavis.ca/papers/hbook.pdf Summary: This paper provides an overview of the intellectual history of data visualization from medieval to modern times, describing and illustrating some significant advances along the way. 2.4 Data Visualization and the 9 Fundamental Design Principles Auhthor: Melissa Anderson, 2017 URL:https://www.idashboards.com/blog/2017/07/26/data-visualization-and-the-9-fundamental-design-principles/ 2.5 A Practitioner Guide to Best Practices in Data Visualization.Interfaces 47(6):473-488. Auhtor: Jeffrey D. Camm, Michael J. Fry, Jeffrey Shaffer, 2017 URL: https://doi.org/10.1287/inte.2017.0916 2.6 The 7 Best Data Visualization Tools In 2017 Author: Bernard Marr, 2017 URL: https://www.forbes.com/sites/bernardmarr/2017/07/20/the-7-best-data-visualization-tools-in-2017/#3a12b8ea6c30 2.7 The Data Visualisation Catalogue URL: https://datavizcatalogue.com 2.8 The Extreme Presentation(tm) Method Aurthor: Dr. Abela, 2015 URL: http://extremepresentation.typepad.com/blog/2015/01/announcing-the-slide-chooser.html 2.9 Data Visualization: How to Pick the Right Chart Type? Author: Janis Gulbis 2016 URL: https://eazybi.com/blog/data_visualization_and_chart_types/ 2.10 Data Visualization Best Practices Author: melindasantos, 2017 URL: http://paristech.com/blog/data-visualization-best-practices/ http://paristech.com/blog/data-visualization-best-practices/ http://extremepresentation.typepad.com/blog/2015/01/announcing-the-slide-chooser.html 2.11 3 simple rules for intuitive dashboard design Author: Happy Dashboarding, 2017 URL: https://www.klipfolio.com/blog/intuitive-dashboard-design 2.12 How deceptive are deceptive visualizations? Author: Pandey, A. V., Rall, K., Satterthwaite, M. L., Nov, O., &amp; Bertini, E. ,2015 2.13 An empirical analysis of common distortion techniques Author: Anshul Vikram Pandey, 2015 2.14 Factors in Computing Systems: Crossings (Vol. 2015-April, pp. 1469-1478). Association for Computing Machinery. DOI: 10.1145/2702123.2702608 (2) Tufte, E. R., and Graves-Morris, P. The visual display of quantitative information, vol. 2. Graphics press Cheshire, CT,1983. 2.15 Axes of evil: How to lie with graphs Author: ANDREA ROBERTSON URL: http://hypsypops.com/axes-evil-lie-graphs/ 2.16 Misleading Graphs: Real Life Examples Author: Stephanie, February 28th, 2016 URL: http://www.statisticshowto.com/misleading-graphs/ 2.17 Next Steps for Data Visualization Research Author: UW Interactive Data Lab, 2015 URL: https://medium.com/@uwdata/next-steps-for-data-visualization-research-3ef5e1a5e349 2.18 Using Typography to Expand the Design Space of Data Visualization. She Ji: The Journal of Design, Economics and Innovation, 2(1), pp 59-87. 2.19 Using Typography to Expand the Design Space of Data Visualization Banissi, Ebad, &amp; Brath, Richard. (2016). URL: https://www.sciencedirect.com/science/article/pii/S2405872616300107. 2.20 Using Data Visualization to Find Insights in Data URL: http://datajournalismhandbook.org/1.0/en/understanding_data_7.html 2.21 Building advanced analytics application with TabPy URL: https://www.tableau.com/about/blog/2017/1/building-advanced-analytics-applications-tabpy-64916 2.22 Some best practices for visualization: URL: http://www.dataplusscience.com/files/visual-analysis-guidebook.pdf 2.23 Avoiding Common Mistakes with Time Series Author: TOM FAWCETT,2015 URL: https://www.svds.com/avoiding-common-mistakes-with-time-series/ 4.1 The Baseline and Working with Time Series in R Author: Nathan Yau, 2013 URL: https://flowingdata.com/2013/11/26/the-baseline/ 4.2 Using design patterns to find greater meaning in your data Author: Julie RodriguezPiotr Kaczmarek May 11, 2016 URL: https://www.oreilly.com/ideas/using-design-patterns-to-find-greater-meaning-in-your-data 4.3 Design Iron Fist Author: Jarrod Drysdale URL: https://studiofellow.com/newsletter/ 4.4 The Creative Aid Handbook URL: https://issuu.com/koorookooroo/docs/kooroo_kooroo_creative_aid 5.1 Importance of Ethics in Visualization: Data visualization in political and social sciences Author: Andrei Zinovyev, year: N/A URL: https://github.com/mschermann/data_viz_reader/files/1933699/Zinovyev_Data_Visualization.pdf * Type Classification Type Classification is a helpful beginner’s guide to typography. It should give you the foundations you need to not only start classifying various forms of type but also understanding when and how to use them to alarmingly great effect. It covers a history of each of the type forms and the basic facts you need know about them.[@design_ebooks] 5.2 Data Visualization in Political and Social Sciences: Data visualization in political and social sciences Author: Andrei Zinovyev, year: N/A URL: https://github.com/mschermann/data_viz_reader/files/1933699/Zinovyev_Data_Visualization.pdf 5.3 Data Visualization in Business: How Data Visualization Impacts Your Business Strategy, Author: Katherine Lazarevich, 2018 URL: https://www.iotforall.com/data-visualization-strategy-for-business/ 5.4 Implications of (Good/Bad) Data Visualization: How Writers Use Misleading Graphs to Manipulate You Author: Ryan McCready, 2017 URL: https://venngage.com/blog/misleading-graphs/ 5.5 General Guidelines for Ethical Visuals: A Code of Ethics for Data Visualization Professionals Author: Drew Skau, 2012 URL: https://visual.ly/blog/a-code-of-ethics-for-data-visualization-professionals/ 1. Expert Data Visualization Tips for Grabbing Readers’ Attention Author: Payman Taei,2017 URL: https://towardsdatascience.com/3-expert-data-visualization-tips-for-grabbing-readers-attention-206d8c4621bf 2.7.6 Tableau: Viz of the Day Tableau has a gallery called Viz of the Day that displays great data visualization examples created by Tableau. It is cool to see how people are using all kinds of data to create informative yet fun data visuals. Data being used is also attached so we can try to mimic what other people did as well. Describe Artists with Emoji. Using the data from Spotify, the author listed the 10 most distinctive emoji used in the playlists related to popular artists. The table being used in this visual is very straight-forward to link artist to the emojis and is very easy to compare among artists. When you hover over the emoji, further information is presented. 2. Choose best colors for cartography visualization in a professional manner Author: Cynthia Brewer, Mark Harrower ,and The Pennsylvania State University URL: http://colorbrewer.org 5.1 Importance of Ethics in Visualization: Data visualization in political and social sciences Author: Andrei Zinovyev, year: N/A URL: https://github.com/mschermann/data_viz_reader/files/1933699/Zinovyev_Data_Visualization.pdf "],
["fundamentals.html", "Chapter 3 Fundamentals 3.1 Determine the Story with Insights 3.2 Design Principles 3.3 Tufte’s Design Principles of Graphical Excellence 3.4 Adapt your story to a different set of audiences 3.5 Three Rules to Follow in order to Develop Intuitive Dashboards 3.6 Data Visualization Tools 3.7 Comparison of Different Tools 3.8 What I learned recreating one chart using 24 tools 3.9 Typography and Data Visualization 3.10 Data visualization in Business 3.11 Corporate Scorecards and Data Visualization 3.12 Contemporary Research Results &amp; What’s Next 3.13 More ways to improve your visualization design", " Chapter 3 Fundamentals 3.1 Determine the Story with Insights Storytelling is an essential part of data visualization. It is extremely important to effectively communicate information through the visualization. Stikeleather’s article (2013) discussed the way in which a visual designer tells a story with a visualization. Find the compelling narrative Think about the audience (e.g., novice, generalist, managerial, export, executive) Be objective and offer balance Don’t censor Data visualization will not always unleash a ready-made story on its own. There are no rules, no protocol that will guarantee us a story. Instead, it makes more sense to look for insights, which can be artfully woven into stories in the hands of a good journalist [@data_journ][@design_principles][@DataVizTips][@practitioners_guide]. Here is a process that may be followed for finding insights to tell a story [@VisualizeToInsights] 3.1.1 Visualize Loading any data set into a spreadsheet can also be a form of visualization as the data becomes visible in a table. Hence the focus should not be whether we need data visualization or not but should be on which form of data visualization is best for the situation. Focus Description 5 Second Rule Research shows that the average modern attention span for viewing anything online is less than 5 seconds, so if you can’t grab attention within 5 minutes, you’ve likely lost your viewer. Include clear titles and instructions, and tell people succinctly what the visualization shows and how to interact with it. Design and layout matter The design and layout should facilitate ease of understanding to convey your message to the viewer. Artists use design principles as the foundation of any visual work. If you want to take your data visualization from an everyday dashboard to a compelling data story, incorporate graphic designer Melissa Anderson’s principles of design: balance, emphasis, movement, pattern, repetition, proportion, rhythm, variety, and unity, discussed in more detail in the design principles section [@design_principles]. Keep it simple Keep charts simple and easy to interpret. Instead of overloading viewers’ brains with lots of information, keep only necessary elements in the chart and help the audience understand quickly what is going on. Pretty doesn’t mean effective There is a misconception that aesthetically pleasing visualization is more effective. To draw attention, sometimes we want them to be pretty and eye-catching. But if it fails to communicate the data properly, you’ll lose your audience’s interest as quickly as you gained it. Use color purposely and effectively Use of color may be prettier and attractive but can be distracting too. Thus, the color should be used only if it assists in conveying your message. Data is simply a collection of many individual elements (i.e., observations, typically represented as rows in a data table). In data viz, our goal is usually to group these elements together in a meaningful way to highlight patterns and anomalies. Described this way, it makes sense that the following principles are a good set of guidelines to assemble different elements into groups [@principles-fusioncharts]. Principle Description Proximity White space can be used to group elements together and separate others Similarity Objects that look similar are instinctively grouped together in our minds Enclosure Helps distinguish between groups Symmetry Objects should not be out of balance, or missing, or wrong. If an object is asymmetrical, the viewer will waste time trying to find the problem instead of concentrating on the instruction. Closure We tend to complete shapes and paths even if part of them is missing Continuity We tend to continue shapes beyond their ending points (similar to closure) Connection Helps group elements together Figure and ground We typically notice only one of several main visual aspects of a graph; what we do notice becomes the figure, and everything else becomes the “background”. This one is especially interesting because it is not as obvious as some of the others, but is really important in matching a data viz design to its purpose. 3.1.2 Analyze and interpret Once the data is visualized, the next step is to learn something from the visualization that is created. Questions that can be asked based on the picture can be: What can be seen in this image? Is it what that was expected? Are there any interesting patterns? What does this mean in the context of the data? Sometimes we might end up with visualization that, in spite of its beauty, might seem to tell that nothing of interest can be found from data. But there is almost always something that we can learn from any visualization, however trivial. 3.1.3 Document Your Insights and Steps If you think of this process as a journey through the dataset, the documentation is your travel diary. It will tell you where you have traveled to, what you have seen there and how you made your decisions for your next steps. You can even start your documentation before taking your first look at the data. In most cases when we start to work with a previously unseen dataset, we are already full of expectations and assumptions about the data. Usually, there is a reason why we are interested in that dataset that we are looking at. It’s a good idea to start the documentation by writing down these initial thoughts. This helps us to identify our bias and reduces the risk of misinterpretation of the data by just finding what we originally wanted to find. I really think that the documentation is the most important step of the process, and it is also the one we’re most likely to tend to skip. As you will see in the example below, the described process involves a lot of plotting and data wrangling. Looking at a set of 15 charts you created might be very confusing, especially after some time has passed. In fact, those charts are only valuable (to you or any other person you want to communicate your findings) if presented in the context in which they have been created. Hence, you should take the time to make some notes on things like: Why have I created this chart? What have I done to the data to create it? What does this chart tell me? 3.1.3.1 Transform Data Naturally, with the insights that you have gathered from the last visualization, you might have an idea of what you want to see next. You might have found some interesting pattern in the dataset which you now want to inspect in more detail. Possible transformations are the following. Transformation Description Zooming This allows us to have look at a certain detail in the visualization Aggregation To combine many data points into a single group Filtering This helps us to (temporarily) remove data points that are not in our major focus Outlier handling This allows us to get rid of single points that are not representative of 99% of the dataset. Let’s consider the following example: You have visualized a graph and what came out of this was nothing but a mess of nodes connected through hundreds of edges (a very common result when visualizing so-called densely connected networks), one common transformation step would be to filter some of the edges. If, for instance, the edges represent money flows from donor countries to recipient countries we could remove all flows below a certain amount [@DataVizBestPrac]. 3.2 Design Principles 3.2.1 Melissa Anderson’s Principles of Design The following principles are from [@design_principles]. Criteria Description Balance A design is said to be balanced if key visual elements such as color, shape, texture, and negative space are uniformly distributed. Balance doesn’t mean that each side of the visualization needs perfect symmetry, but it is important to have the elements of the dashboard/visualization distributed evenly. And it is important to remember the non-data elements, such as a logo, title, caption, etc. that can affect the balance of the display. Emphasis Draw viewers’ attention towards important data by using key visual elements. Emphasis is the component that is most related to when reading the nine principles of design. It is the key to be conscious of what is drawing the viewers attention to the art. When thinking about the art design of data visualization it is also very important to remain keen on the main point of your story and how the entire visualization is either drawing the viewer to that point of emphasis or how they are being distracted or drawn elsewhere. Movement Ideally movement should mimic the way people usually read, starting at the top of the page, moving across it, and then down. Movement can also be created by using complementary colors to pull the user’s attention across the page. Pattern patterns are ideal for displaying similar sets of information, or for sets of data that equal in value. Disrupting the pattern can also be effective in drawing viewers’ attention; it naturally draws curiosity. Repetition Relationships between sets of data can be communicated by repeating chart types, shapes, or colors. Proportion If a person is portrayed next to a house, the house is going to look bigger. In data visualization, the proportion can indicate the importance of data sets, along with the actual relationship between numbers. Proportion can be subtle but it can go a long way to enhancing a viewer’s experience and understanding of the data. The danger of proportion though is that it can be easy to deceive people subconsciously. Naturally, images will have a greater impact on how our brains perceive the dashboard or visualization. For example, someone can change the scale of a graph or images to inflate their results and even if they write the numbers next to it, the shortcut many people will take is to interpret the data based on the image. This is why it is important we take care to accurately reflect proportion in our data visualization and remain critical of how others use proportion in their visualization. Rhythm A design has proper rhythm when the design elements create the movement that is pleasing to the eye. If the design is not able to do so, rearranging visual elements may help. Variety Variety in color, shape, and chart-type draws and keeps users engaged with data. Including more variety can increase information retention by the viewer. But when there is too much variety, important details can be overlooked. Variety, which could seem counter to balance, but when done correctly, variety can help increase the recall of information. However if overdone, too much variety can feel cluttered and blur together the images and data in the mind of the viewer. Unity Unity across design will happen naturally if all other design principles are implemented. 3.3 Tufte’s Design Principles of Graphical Excellence A graph should be impressive and can obtain audience’s attention. How can we achieve this? We must consider several aspects: efficiency, complexity, structure, density and beauty. We also should consider the audience whether they will be confused about the design. 3.3.1 Principle 1: Maximizing the data-ink ratio, within reason Data-ink is the non-erasable core of a graphic, the non-redundant ink arranged in response to variation in the numbers represented. It is also the proportion of graphic’s ink devoted to the non-redundant display of data-information. \\[{Data \\ Ink \\ Ratio} = \\frac{{Data \\ Ink}}{{Total \\ Ink}}\\] This basic idea is illustrated in the following visualizations. Erase non-data-ink and redundant data-ink. (Source:[@Tufte_2001]) Erase non-data-ink and redundant data-ink. (Source: [@appli_2017]) (Source: [@appli_2017]) Always revise and edit (Source: [@Tufte_2001]) The graphs will be better for more information per unit of space and per unit of ink is displayed. Graphics are almost always going to improve as they go through editing, revision, and testing against differernt design options. Try to figure out whehter the audience looking at the new designs be confused? Nothing is lost to those puzzled by the frame of dashes,and something is gained by those who do understand. We can also assume that if you understand the statistical graphics, most other readers will, too because it is a frequent mistake in thinking about statistical graphics to underestimate the audience. Some of the new designs may appear odd, but this is probably because we have not seen them before. 3.3.2 Principle 2: Mobilize every graphical element, perhaps several times over, to show the data. The danger of multifunctioning elements is that they tend to generate graphical puzzles, with encodings that can only be broken by their inventor.Thus design techniques for enhancing graphical clarity in the face of complexity must be developed along with multifunctioning elements. In other words, we should try to make all present graphical elements data encoding elements. We must make every graphical element effective (See the following example). (Source: [@Tufte_2001]) 3.3.3 Principle 3: Maximize data density and the size of the data matrix, within reason. High performation graphics should be designed with special care. As volume of data increases, data measures must shrink (smaller dots for scatters,thinner lines for busy time-series). \\[{Data \\ Density} = \\frac{{Entries \\ in \\ the \\ Data \\ Matrix}}{{Area \\ of \\ Chart}}\\] 3.3.4 Principle 4: Escape flatland - small multiples, parallel sequencing. Data is multivariate. Doesn’t necessarily mean 3D projection. How can we enhance mulitvariate data on inherently 2D surfaces? (Source: [@Tufte_2001]) (Source: [@Tufte_2001]) 3.3.5 Principle 5: Provide the user with an overview and details on demand. Carefully designed view can show a macro structure (overview) as well as micro structure (detail) in one space. (Source: [@Tufte_2001]) 3.3.6 Principle 6: Utilize Layering &amp; Separation. Supported by Gestalt laws (The principles of grouping): Grouping with colors Using Color to separate 1 + 1 = 3 (clutter) (Source: [@Tufte_2001]) 3.3.7 Principle 7: Utilize narratives of space and time. Tell a story of position and chronology through visual elements. (Source: [@narratives_2017]) (Source: [@narratives_2017]) 3.4 Adapt your story to a different set of audiences Jonathon Corum is a graphics designer for The New York Times and he provided a very informative talk to a strictly scientific audience on how to create and design visualizations that explain material originally created for a certain audience, i.e. the scientific community, but now is to be related to a different audience, (in his case, the readership of the Times or maybe the public at large). The talk is filled with examples and break downs of how he has moved from his base content to the final product, all of which are illuminating examples by themselves. There is also great power in the broader themes that he is trying to convey. Of course is knowing the audience that you are producing the work for, but even in this step, do not lose sight of the ultimate goal of conveying understanding, of explaining a concept. You are searching for a visual idea in your content that can be communicated to your audience. Some of the main highlights to help you make this connection with your audience involve. Principle Description Focusing the attention What can be removed? Realize that consistency can help eliminate unnecessary distractions. There may be a trade off between losing information but conveying the ultimate meaning more clearly. Label important things rather than relying on a legend, which requires the viewer to hold on to too much information at once. Involving your audience: Give them opportunities to connect their own general knowledge on the topic. Use real world comparisons or examples to help build and relate context. Encourage comparisons and make this easy for the viewer to process and see. Explaining why Providing context, adding time sequence details, showing movement, change and mechanism will all guide your audience in connecting the dots and understanding the significance of what you are trying to communicate. 3.5 Three Rules to Follow in order to Develop Intuitive Dashboards Often a designer can become too concerned with coming up with a visual that is too intricate and overly complicated. A dashboard should be appealing but also easy to understand. Following these rules will lead to effective presentation of the data [@intuitive-dash]. 3.5.1 The dashboard should read left to right Because we read from top to bottom and left to right, a reader’s eyes will naturally look in the upper left of a page. The content should therefore flow like words in a book. It is important to note that the information at the top of the page does not always have to be the most important. Annual data is usually more important to a business but daily or weekly data could be used more often for day to day work. This should be kept in mind when designing a dashboard as dashboards are often used as a quick convenient way to look up data. 3.5.2 Group related information together Grouping related data together is an intuitive way to help the flow of the visual. It does not make sense for a user to have to search in different areas to find the information they need. 3.5.3 Find relationships between seemingly unrelated areas and display visuals together to show the relationship. Grouping unrelated data seems contradictory to the second rule, but the important thing is to tell a story not previously observed. Data analytics is all about finding stories the data are trying to tell. Once they are discovered, the stories need to be presented in an effective manner. Grouping unrelated data together makes it easier to see how they change together. 3.6 Data Visualization Tools Due to the rise of big data analytics, there has been an increased need for data visualization tools to help understand the data. Besides Tableau, there are several other software tools one can use for data visualization like Sisense, Plotly, FusionCharts, Highcharts, Datawrapper, and Qlikview. This article is from Forbes and has a brief, clear introduction about these 7 powerful software options for data visualization. This could be helpful for future reference because for different purposes I may need to use different tools. Each option has its advantages and disadvantages and this article helps highlight them. Tool Description Tableau The most popular in the group and has many users. It is simple to use, making it easy to learn and can handle large data sets. Tableau can handle big data thanks to integration with database handling applications such as MySQL, Hadoop, and Amazon AWS. Qlikview The the main competitor to Tableau and is also quite popular. Qlikview is customizable and has a wide range of features which can be a double-edged sword. These features take more time to learn and get acquainted with. However, once one gets past the learning curve, they have a powerful tool at their disposal. FusionCharts The distinctive aspect of FusionCharts is that graphics do not have to be created from scratch. Users can start with a template and insert their own data from their project. Highcharts It proudly claims to be used by 72% of the 100 biggest companies in the world. It is a simple tool that does not require specialized training and quickly generates the desired output. Unlike some tools, Highcharts focuses on cross-browser support, allowing for greater access and use. Datawrapper It is making a name for itself in the media industry. It has a simple user interface making it easy to generate charts and embed into reports. Plotly It can create more sophisticated visuals thanks to integration with programming languages such as Python and R. The danger is creating something more complicated than necessary. The whole point of data visualization is to quickly and clearly convey information. Sisense It can bring together multiple sources of data for easier access. It can even work with large data sets. Sisense makes it easy to share finished products across departments, ensuring everyone can get the information they need. 3.7 Comparison of Different Tools 3.7.1 Interactive Data Visualization Interactive or Dynamic data visualization delivers today’s complex sea of data in a graphically compelling and an easy-to-understand way. It enables direct actions on a plot to change elements and link between multiple plots. It enables users to accomplish traditional data exploration tasks by making charts interactive [@benefits_interactive_viz]. Interactive Data Visualization Software has the following benefits: Absorb information in constructive ways: With the volume and velocity of data created everyday, dynamic data viz enables enhanced process optimization, insight discovery and decision making. Visualize relationships and patterns: Helps in better understanding of correlations among operational data and business performance. Identify and act on emerging trends faster: Helps decision makers to grasp shifts in behaviors and trends across multiple data sets much more quickly. Manipulate and interact directly with data: Enables users to engage data more frequently. Foster a new business language: Ability to tell a story through data that instantly relates the performance of a business and its assets. There are multiple ways by which interactive data visualizations can be developed. 3.7.2 D3.js D3.js stands for Data Driven Document, a JS library for interactive Big Data visualization in literally ANY way required real-time[@d3_interactive_viz]. This is not a tool, mind you, so a user should have a solid understanding of JavaScript to work with the data and present it in a humanly-understandable form. To say more, this library renders the data into SVG and HTML5 formats, so older browsers like IE7 and 8 cannot leverage D3.js capabilities. The data gathered from disparate sources like huge-scale data sets is bind in real-time with DOM to produce interactive animations ( 2D and 3D alike) in an extremely rapid way. The D3 architecture allows the users to intensively reuse the codes across a variety of add-ons and plug-ins. Some of the key advantages are: It is dynamic, free and open source and very flexible with all web technologies, the ability to handle big data and the functional style allows to reuse the codes. The Hitchhiker’ Guide to d3.js is a wonderful guide for self-teaching d3.js. This guide is meant to prepare readers mentally as well as give readers some fruitful directions to pursue. There is a lot to learn besides the d3.js API, both technical knowledge around web standards like HTML, SVG, CSS and JavaScript as well as communication concepts and data visualization principles. Chances are you know something about some of those things, so this guide will attempt to give you good starting points for the things you want to learn more about. It starts from the insights of learning d3.js by showing interviews with those top visualization practitioners. Then the author gives key concepts and useful features for learning visualization like d3-shape, d3 selection, d3-collection, ds-hierarchy, ds-zoom as well as d3-force. My favorite part of this guide is it lists a lot of useful resources links for learning d3.js. For example, it recommends d3 API Reference, 2000+ d3 case studies and tutorials for d3. I did my exploratory analysis version of group project on d3. And I found this guide helpful during the progress. It also includes some meetup groups here in the bay area. So, maybe we can meet data friends through the group. 3.7.3 Tableau Tableau is amid the market leaders for the Big Data visualization, especially efficient for delivering interactive data visualization for the results derived from Big Data operations, deep learning algorithms and multiple types of AI-driven apps [@tableau_interactive_viz]. Tableau can be integrated with Amazon AWS, MySQL, Hadoop, Teradata and SAP, making this solution a versatile tool for creating detailed graphs and intuitive data representation. This way the C-suite and middle-chain managers are able to make grounded decisions based on informative and easily-readable Tableau graphs. Tableau is business intelligence (BI) and analytics platform created for the purposes of helping people see, understand, and make decisions with data. It is the industry leader in interactive data visualization tools, offering a broad range of maps, charts, graphs, and more graphical data presentations. It is a painless option when cost is not a concern and you do not need advanced and complex analysis.The application is very handy for quickly visualizing trends in data, connecting to a variety of data sources, and mapping cities/regions and their associated data. The followin tips for Tableau are still missing: 1. Running totals 2. Common Baseline 3. Weighted averages 4. Moving average 5. Grouping by aggregates 6. Different years comparison 7. Appending excel sheets 8. Bar chart totals 9. Fixed axis when re-drawing charts 10. Auto-fitting screen behavior depending on data selection The key advantages are: It provides non technical user the ability to build complex reports and dashboard with zero coding skills. Using drag-n-drop functionalities of Tableau, user can create a very interactive visuals within minutes. It can handle millions of rows of data with ease and users can make live to connections to different data sources like SQL etc [@VizBP][@ExtremePre]. 3.7.4 R Shiny R Shiny enables us to produce interactive data visualizations with a minimum knowledge of HTML, CSS, or Java using a simple web application framework that runs under the R statistical platform [@shiny_interactive_viz]. Standalone apps can be hosted on a webpage or embedded in R Markdown documents and dashboards can be built using R shiny. It combines the computational power of R with the interactivity of the modern web. The main advantages of using R Shiny are : Its flexibility of pulling in whatever package in R that you want to solve your problem, reaping the benefits of an open source ecosystem for R and JavaScript visualization libraries, thereby allowing to create highly custom applications and enabling timely, high quality interactive data experience without (or with much less) web development and without the limitations or cost of proprietary BI tools. 3.7.5 Jupyter 3.7.6 Google chart A free and powerful integration of all Google power. The tool is rendering the resulting charts to HTML5/SVG, so they are compatible with any browser. Support for VML ensures compatibility with older IE versions, and the charts can be ported to the latest releases of Android and iOS. What’s even more important, Google chart combines the data from multiple Google services like Google Maps. This results in producing interactive charts that absorb data real-time and can be controlled using an interactive dashboard [@Top4VizTools]. 3.8 What I learned recreating one chart using 24 tools Lisa Rost’s article “What I learned recreating one chart using 24 tools” describes lessons learned from recreating one chart using many different data visualization tools [@different_tools]. The author used apps Excel, Plotly, Easycharts, Google Sheets, Lyra, Highcharts, Tableau, Polestar, Quadrigram, Illustrator, RAW, and NodeBox, as well as charting libraries ggvis, Bokeh, Highcharts, ggplot2, Processing, NVD3, Seaborn, Vega, D3, matplotlib, Vega-Lite, and R. She links her github page on the project which details the data set she used, containing the health expectancy in years as well as GDP per capita and population for about 200 countries in the year 2015, as well has her process and results of visualizing the data using each tool. However, in the article, she focuses on the main takeaways from the exercise, which was especially interesting in the context of our class discussion on different types of tools and their respective strengths. She also provides her own graphics to help illustrate her lessons learned. 3.8.1 Takeaway 1: There Are No Perfect Tools, Just Good Tools for People with Certain Goals Since data visualization is necessary in many spheres, from science to journalism, data visualization projects will often have quite disparate objectives, and the people working on them will have different requirements. And as the author aptly points out, it is impossible for one tool to satisfy the needs of every data visualizer; so there will necessarily be tools better suited to specific situations. For example, does the user need a tool for exploratory visualization of the data, or does the user seek to create graphs and charts to show the public or a specific audience something? The author also notes that the flexibility of a tool is a sticking point as well if you need to change your data while developing a data visualization, certain apps like Illustrator will not be ideal because changing the data even slightly requires you to build the graph again from scratch. Another thing to think about is the type of chart you are trying to create is a basic, canned bar or line graph all you need (in which case something like Excel will do the trick), or does your project necessitate a more innovative or custom chart (like something possible in D3.js)? Interactivity is another big question only certain tools will make this possible. 3.8.2 Takeaway 2: There Are No Perfect Tools, Just Good Tools for People with Certain Mindsets This section of the article is all about the difference in people’s preferences and opinions; from the people who build the tools to the users, everyone thinks differently. Therefore, certain tools will be inherently more intuitive to use for different people. 3.8.3 Takeaway 3: We Still Live in an ‘Apps Are for the Easy Stuff, Code Is for the Good Stuff in the World’ Basically, writing code can be scary for anyone without a coding background, but it provides more flexibility, and, as mentioned in class, code is perfectly reproducible. On the other hand, apps are much more user-friendly for the less computer science-savvy. 3.8.4 Takeaway 4: Every Tool Forces You Down a Path Rost quotes her former NPR Visuals teammate for the final lesson header, pointing out that tools themselves influence the development of a data visualization with their respective features, strengths, and limitations. 3.9 Typography and Data Visualization This article discusses less common applications of typography in data visualization. While data components such as quantitative or categorical data are commonly represented by visual features like colors, sizes or shapes, utilization of boldface, font variation, and other typographic elements in data visualization are less prevalent. Highlighted in the article are preattentive visual attributes. Preattentive attributes are those that perceptual psychologists have determined to be easily recognized by the human brain irrespective of how many items are displayed. Therefore, “preattentive visual attributes are desirable in data visualization as they can demand attention only when a target is present, can be difficult to ignore, and are virtually unaffected by load.” Examples of preattentive attributes are size/area, hue, and curvature. This brings us to the disparate situation of the popularity of visual aspects like color and size and typographic aspects such as font variation, capitalization and bold. The authors present several possible reasons for this, beginning with the preattentiveness of visual attributes like size and hue.However, some typographic attributes such as line width or size, intensity, or font weight (a combination of the two) are considered preattentive as well. Furthermore, these visual attributes are inherently more viscerally powerful, and they are easy to code in a variety of programming languages. Technology has also perhaps previously limited the use of typographic attributes, for only recently have fine details such as serifs, italics, etc. been made readily visible to the audiences of data visualizations by technological advances. Lastly, the authors remark that it is possible the lack of variety of typographic elements used in data visualizations is due to the limited knowledge of computer scientists and other individuals pursuing data visualization in how to apply these elements effectively. While the first few proposed explanations make sense from personal experience with technology and exposure to data visualizations and design in general, the hypothesis that lack of knowledge of typographic elements in data visualization seems more plausible if it was being applied to a small group of people rather than all of the data visualization design community. I would say that it is more likely that the use of typographic elements in data visualization is less popular because there are fewer instances in which it can be used appropriately, or a status quo bias if current visual attributes are received well, the prevailing attitude may be not to fix what is not broken. However, the authors also point out that despite the dearth of typographic attributes in data visualization, other spheres like typography, cartography, mathematics, chemistry, and programming have a rich history with type and font attributes that informs the scope of the parameter space? The authors continue by pointing out some tips for using typographic attributes to encode different data types, since certain attributes may be suited to particular purposes. For example, font weight (size and intensity) is ideal for representing quantitative or ordered data, and font type (shape) is better suited to denote categories in the data. Furthermore, as in typography and cartography, use of typographic attributes in data visualization raises concerns of legibility, the ability to understand both individual characters and commonalities that identify a font family, and readability, the ability to read lines and blocks of words. Often, interactivity of a visualization will not only improve functionality, but also provide a solution to readability issues by providing a means to zoom in on small text. There are a few examples of unusual/innovative use of typography for data visualization in the article, not all of which I agree are made more effective by the interesting utilization of typographic attributes, but the “Who Survived the Titanic” visualization’s use of typographic attributes allowed it to not only answer macro-questions very quickly, such as if women and children were actually first to be evacuated across classes, but also to provide answers to micro-questions, like whether or not the Astors survived. It used common visual elements like color and area to indicate whether or not a person survived and number/proportion of people, as well as typographic aspects like italic and simple text replacement to indicate gender and the passengers names. The authors round out the article by addressing the most common criticisms of typography in data visualization, the foremost one being whether or not text should even be considered an element of data visualization, since visualization connotes preattentive visual encoding of information, and text or sequential information necessitates more investment of attention to understand. Another criticism is that textual representations are not as visually appealing even when used effectively. However, the authors counter that “this criticism indicates both the strength and weakness of type? that while text may not be suited for adding style or drama to a visualization, it can be particularly powerful in situations where a finer level of detail is needed, without sacrificing representation of higher level patterns. Lastly, a label length problem is common when using text in visualizations; differing lengths of names or labels may skew perception so that longer labels seem more important than shorter labels. This problem was encountered in the Titanic visualization with the varying lengths representations of passengers’ names, and was corrected by only including a given name and a surname, the length of which could only vary so much. 3.10 Data visualization in Business [@biz_strategy] According to an Experian report, 95% of U.S. organizations say that they use data to power business opportunities, and another 84 percent believe data is an integral part of forming a business strategy. Visualization helps data impact business in following ways: 3.10.1 Cleaning The simplest way to explain the importance of visualization is to look at visualization as the means to making sense of data. Even the most basic, widely-used data visualization tools that combine simple pie charts and bar graphs help people comprehend large amounts of information fast and easily, compared to paper reports and spreadsheets. In other words, visualization is the initial filter for the quality of data streams. Combining data from various sources, visualization tools perform preliminary standardization, shape data in a unified way and create easy-to-verify visual objects. As a result, these tools become indispensable for data cleansing and vetting and help companies prepare quality assets to derive valuable insights. Cleaning the data is usually the first step in data processing and is done to remove the unwanted elements as well as to reduce the size of the data sets, which will make it easier for the algorithms to analyze it. Data cleansing is typically done by using instance reduction techniques. Instance reduction helps reduce the size of the data set without compromising the quality of insights that can be extracted from the data. It removes instances and generates new ones to make the data set compact. There are two major instance reduction algorithms: Instance selection: Instance selection is used to identify the best examples from a very large data set with many instances in order to curate them as the input for the analytics system. It aims to select a subset of the data that can act as a replacement for the original data set while completely fulfilling the goal. It will also remove redundant instances and noise. Instance generation: Instance generation methods involve replacing the original data with artificially generated data in order to fill regions in the domain of an issue with no representative examples in the master data. A common approach is to relabel examples that appear to belong to wrong class labels. Instance generation thus makes the data clean and ready for the analysis algorithm. Tools you can use: Drake, DataWrangler, OpenRefine 3.10.2 Extracting Known versatile tools for data visualization and analytics Elastic Stack, Tableau, Highcharts, and more complex database solutions like Hadoop, Amazon AWS and Teradata, have wide applications in business, from monitoring performance to improving customer experience on mobile tools. New generation of data visualization based on AR and VR technology, however, provides formerly unfeasible advantages in terms of identifying patterns and drawing insights from various data streams. Building 3D data visualization spaces, companies can create an intuitive environment that helps data scientists grasp and analyze more data streams at the same time, observe data points from multiple dimensions, identify previously unavailable dependencies and manipulate data by naturally moving objects, zooming, and focusing on more granulated areas. Moreover, these tools allow us to expand the capabilities of data visualization by creating collaborative 3D environments for teams. As a result, new technology helps extract more valuable insights from the same volume of data. Data has shown phenomenal growth over the past decade and it’s widespread application by businesses as a growth catalyst continues to deliver positive results. The scale of data is massive and the volume, velocity and variety of data calls for more efficient processing to make it machine-ready. Although there are a multitude of ways to extract data such as public APIs, custom web scraping services, internal data sources, etc., there would always remain the need to do some pre-processing to make the data perfectly suitable for business applications. Data pre-processing techniques like: Data cleansing Data Manipulation Data normalization Data Transformation Missing values imputation Noise identification Minimizing the pre-processing tasks play a key role in the process. 3.10.3 Strategizing As the amount of data grows, it becomes harder to catch up with it. Therefore, data strategy becomes the necessary part of the success in applying data to businesses. Then how data visualization become an important tool in your strategic kit? First, it helps you cleanse your data. Secondly, it allows you to identify and extract meaningful information from it. Finally, data visualization tools enable continuous real-time monitoring of how your strategy and now data-driven decisions influence performance and business outcomes. In other words, these tools visualize not only the data, but also the results, and help correct and optimize strategy on the go. Data visualization is one of the initial steps made to derive value from data. It’s also one of the most important steps, as it determines how efficiently analysts can work with data assets, what insights they are able to extract and how their data strategy will develop over time. Therefore, the quality and capabilities of data visualization directly influence how data impacts your business strategy and what benefits data applications can bring to the companies and their industries. 3.11 Corporate Scorecards and Data Visualization Corporate transparency, flat organizations, open book policies, etc. are terms executives and entrepreneurs learn about all the time [@SCORECARDS]. As the corporate world shifts towards a more open culture, the demand for open data and insights have increased dramatically. This shift has helped the overall corporate strategic planning and management process easing the alignment of business activities towards a series of goals. Being transparent top down aligns the culture to sail towards the same North Star. The growth of corporate transparency is not only important internally, but externally as well. Corporate certifications like B Corporations certifications (B Corp), require companies to provide a transparent view on their social conscious efforts to the general public. Achieving the certification is one step of the process; the true goal is to show the world how and why the certification is truly deserved. Corporate transparency, flat organizations, open book policies, etc. are terms executives and entrepreneurs hear about all the time [@SCORECARDS]. As the corporate world shifts towards a more open culture, the demand for open data and insights have increased dramatically. This shift has improved the overall corporate strategic planning and management process, easing the alignment of business activities towards a series of goals. Being transparent top down aligns the culture to sail towards the same North Star. The growth of corporate transparency is not only important internally, but externally as well. Corporate certifications like B Corporations certifications (B Corp), require companies to provide a transparent view on their social conscious efforts to the general public. Achieving the certification is one step of the process; the true goal is to show the world how and why the certification is truly deserved. Here’s the process on how to get it done. Step Name Description 1 Perform Data Discovery and Determine The Story Before this step it is easy to underestimate the effort level it takes to pull the best insights from the data. Data manipulation products like Tableau, Domo, Pentaho, IBM’s Many Eyes, and R, among others, make insight extraction that much easier to gain understanding of data using a visual medium. The key is to start with a simple portion of your data and to start pulling basic insights to visualize and correlate with each other. This process leads towards a compound series of questions, which helps provide an overall vision to the end product. We see the effect during our discovery process, which leads to unforeseen avenues for data intelligence. 2 Data Infrastructure Setup Data infrastructures can be simple or complex depending what the end goal is. Many clients prefer to go the route of complete data integration in order to centralize their data repositories. Technologies such as Hadoop have helped by unifying disparate data sources, but other options such as data cloud environments can help produce API’s for future product deployments. Why is this important? Accessibility of data is an important foundation not only within the context of dashboards, but also the possibility of branching out to other products. 3 Product Design &amp; Development Wireframing, prototyping, and application development are the main engines to transform an idea into a final product. Products can range from static presentations/reports to full interactive applications. Mobile, tablet, TV, and workstation platforms can all be mediums to help deliver the final product. The secret to a great end product is how well the data story is conceptualized. If the story is weak then the end product will also suffer. 4 QA &amp; Product Release The best part of any project is to get it finalized and released for all to see. All data gets verified for accuracy, functionality testing (if applicable), application flow (if applicable), design testing, and remaining items are all completed. The end result is an engaging visual product for all intended audiences to see and use. 3.12 Contemporary Research Results &amp; What’s Next With the development, studies and new tools applied in data visualization, more people understand it matters. But given its youth and interdisciplinary nature, research methods and training in the field of data visualization are still developing. So, we asked ourselves: what steps might help accelerate the development of the field? Based on a group brainstorm and discussion, this article shares some of the proposals of ongoing discussion and experiment with new approaches [@next_steps]: Adapting the Publication and Review Process: As the article states, “both ‘good’ and ‘bad’ reviews could serve as valuable guides,” so providing reviewer guidelines could be helpful for fledgling practitioners in the field. Promoting Discussion and Accretion: Discussion of research papers actively occurs at conferences, on social media, and within research groups. Much of this discussion is either ephemeral or non-public. So ongoing discussion might explicitly transition to the online forum. Research Methods Training: Developing a core curriculum for data visualization research might help both cases, guiding students and instructors alike. For example, recognizing that empirical methods were critical to multiple areas of computer science, Stanford CS faculty organized a new course on Designing Computer Science Experiments. Also, online resources could be reinforced with a catalog of learning resources, ranging from tutorials and self-guided study to online courses. Useful examples include Jake Wobbrock’s Practical Statistics for HCI and Pierre Dragicevic’s resources for reforming statistical practice. 3.13 More ways to improve your visualization design From online surveys to beefed-up analytics, we’re able to gather and analyze more data than ever before. But how do you turn your findings from a dense spreadsheet into something that really makes your point? Good information design is the key. There’s a wealth of free resources out there in the form of handy little design ebooks. Title Author Description Design’s Iron Fist Jarrod Drysdale This free ebook is a collection of Drysdale’s previous work all wrapped up in one neat little package. Aside from practical tutorials and processes, this book also offers help on how to get into the mindset of being a truly great designer. The Creative Aid Handbook Kooroo Kooroo Creativity doesn’t just happen overnight. It’s something that each and every designer has to work at on a day-to-day basis. If you find that your innovative juices are running dry, The Creative Aid Handbook could be the answer. The helpful guide looks at how you can boost your intellect, foster your well-being, and, most importantly, become more creative. Designbetter.co InVision InVision released three fantastic design books that are available for free. Each book discusses various aspects of design like design process, management, and business. Moreover, some of the materials are available in audio format. Type Classification Type Classification is a helpful beginner’s guide to typography. It should give you the foundations you need to not only start classifying various forms of type but also understanding when and how to use them to alarmingly great effect. It covers a history of each of the type forms and the basic facts you need know about them.[@design_ebooks] "],
["case-studies.html", "Chapter 4 Case Studies 4.1 Geographic Visualizations 4.2 Demographic Comparisons 4.3 Evolving Demographics 4.4 Environmental Related Problems 4.5 Animated Data Visualization 4.6 Language 4.7 Political Relationships 4.8 Uncategorized", " Chapter 4 Case Studies Visualization is like art; it speaks where words fail. There are phenomena like the Syrian war, the number flights during Thanksgiving in the USA, the understanding of depths for developing a perspective about the range of the issue, the controversy of ‘#OscarsSoWhite’, etc. on which we can write endless paragraphs, but which might still fail to convince the readers. The links show some intricate visualizations of some of these important and relevant topics - visualizations that speak volumes and are much more persuasive than an essay, with a tiny fraction of the text. The usefulness of data visualizations is not just limited to business and analytics; almost anything in the world can be explained by visualizations. Wars, rescue operations, social issues etc. can be visualized to get a clear idea of all the details of the issues. This chapter contains some useful case studies on such visualizations. Case studies contain valuable information about development records. The examination and evaluation of case studies helps show that new designs are just as usable as existing techniques, demonstrating that the field is suitable for future development. Many of the case studies below come from the following articles: Source Description [@10_BEST] This source picks the top 10 best data visualizations of 2015. For each pick, the author displays the project plot and also describes his reasoning for choosing that chart as an exemplary visualization. This article is useful for getting a basic understanding of what characteristics a good visualization should include. [@cool_data] The author has chosen fifteen of the best infographics and data visualizations from 2016 and explained the reasoning behind these choices. [@int_viz_capt] 16 Captivating Data Visualization Examples [@15_mindblowing] 15 Data Visualizations That Will Blow Your Mind: These 15 data visualizations show the vast range that data analysis is applicable to - from pop culture to public good. Take a look at them to get inspiration/understanding for your own work. [@int_viz_capt][@int_viz_current] 15 Data Visualizations That Explain Trump, the White Oscars and Other Crazy Current Events [@vizwiz] Vizwiz is a blog about Tableau-based data visualization. It has case studies about how to improve your visualizations, written by Andy Kriebel, a famous Tableau Zen Master. I would like to recommend this blog because it is not only practical but also full of insights. My favorite part of this blog is the “Makeover Monday,” which develops a new visualization based on an original one. This blog also includes great tips for and examples of Tableau. 4.1 Geographic Visualizations Often, people use maps to visualize data that should not be mapped. Here are some examples of when a map visualization is a good choice. 4.1.1 Spies in the Skies The map is filled with red and blue lines (representing FBI and DHS aircraft, respectively) which illustrate the flight paths of the planes. When planes circle an area more than once, the circles become darker. The circles change in accordance to day and time, and individual cities can be typed into a search bar to see the flight patterns over them. The visualization rather creatively looks almost like a hand-drawn map. While presenting a normally uncomfortable topic, this allows individuals to check things for themselves, hopefully providing some peace of mind [@spies_sky] referenced in [@cool_data]. New York Flight Patterns 4.1.2 Two Centuries of U.S. Immigration The interactive map shows the rate of immigration into the U.S. from other countries over the last 200 years in 10-year segments. Colored dots represent 10,000 people coming from the specified country. Countries then light up when they have one of the highest rates of migration. What makes this a good visualization is that it is engaging and easy to read and interpret. The movement of the dots draws the reader’s attention while the brightly lit countries make it easy to pick out the highest total migrations [@immigration][@cool_data]. US Immigration 4.1.3 Uber: Crafting Data-Driven Maps Map visualization is very important for companies like Uber that need to track metrics using geo-space points. In this article, the designer from Uber talks about the challenges of designing such visualizations and the possible solutions [@uber_maps]. The challenges that Uber faced to craft geospatial visualizations include: There are great individual maps but lack consistency as a company. Common graphing tooling like Sketch does not support GIS file, which is essential to Uber’s insights. The scale of the framework includes more than 400 cities in the world with variety in different geographic features and data types. To tackle these problems, Uber started by defining base map themes by optimizing detail, color and typography. Based on that, data layers are added using scatter plots and hex bins, with careful color selection to help their team make decisions. To make it even better, Uber took a further step by adding trip lines (see images below), which became a signature visualization of Uber. Choropleths are also used to help visualize how metrics and values differ across geographic areas. The visualization in this article is a classic problem of visualizing geographic data. The detailed explanation in the problems and how they are solved can be beneficial for people/startups to pinpoint and make appropriate visualization that support decision making process. Uber Route Maps 4.2 Demographic Comparisons One common use of visualization is to compare different groups against each other, such as political parties or generations. 4.2.1 Young voters, class and turnout: How Britain voted in 2017 This article’s goal is to convey the change in party votes in the 2017 UK general election compared to votes in 2015 [@UKvotes2017]. The change in party votes was shown with regards to three demographic factors: age, class, and ethnicity. For each factor, there are four graphs (one per political party), each illustrated in the party’s standard color. The change in the percent of votes is shown as an arrow where the arrow’s shaft is the length of the difference from 2015 to 2017 while the x-axis is the demographic factor split into different bins. What makes this a good visualization is that it is very easy to read and interpret. The color-coding of the arrows and party names makes it easy to pick out the different parties. The arrow lengths highlight just how large of a change happened. For example, in the Age section, it is easy to see the pattern between the Labour party gaining many voters aged 18 to 44 and the Conservative party gaining voters aged 45 and up. UK Party Votes by Age 4.2.2 U.S. Migration Patterns The New York Times data team mapped out Americans’ moving patterns from 1900 to present, and the results are fascinating to interact with [@migration]. You can see where people living in each state were born, and where people are moving to and from. The groupings of the destinations varies based on that state’s trends, preventing unnecessary clutter while still showing detail when important, as can be seen by the difference between their charts for California and Pennsylvania. Migration from California Migration from Pennsylvania 4.2.3 The American Workday NPR tapped into American Time Use Survey data to ascertain the share of workers in a wide range of industries who are at work at any given time [@NPR_workday]. The chart overlays the traditional 9 AM-5 PM standard over the graph for a reference point, helping the audience draw interesting conclusions. 4.2.4 How People Like You Spend Their Time This visualization lists several categories such as “personal care” and “work” along one side of a graph with a line illustrating the amount of time the average person in a certain demographic spends on each subject. Entering different statistics at the top, such as changing gender or age, causes the lines to shift to feature that demographic. The simplicity of this visualization helps the information get across and avoids bogging down the statistics. Sometimes, less is more [@spendingtime] referenced in [@cool_data]. 4.2.5 Britain’s diet in data This is a good example about how to present a large amount of comprehensive data - distributed across different categories and measured in different metrics - in a simple yet effective manner, while still maintaining interest and aesthetics. The data product attempts to show how the average Briton’s diet has changed over the last 4 decades for the better [@britain_diet_2016]. It does this by displaying simple trend lines that show that more harmful and rich foods are being consumed less and the healthier and leaner foods are being consumed more. It further breaks down every major food category into tens of its constituent products, and in both the overview and deep-dive versions, provides further levers to massage more meaning out of the data. It also shows how the contribution of different foods to the typical diet has changed over the years. Here, we can toggle the year to see exactly how much of each food was consumed, again with another deep-dive into the constituents of every major food group. Source: [@britain_diet_2016] Such a visualization is ideal for the layman who would want to walk away with a basic but accurate understanding of the dietary changes. It also provides plenty for the more discerning viewer who might have more time and inclination to dissect and parse through the graphs. It is difficult to use the same data product to cater to both types of viewers in such a satisfactory capacity, which is what makes this particular data product so impressive and effective. It satisfies the principles of graphical excellence as stated by Edward Tufte :“Graphical excellence is that which gives to the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space.” [@visual_display]. 4.2.6 Selfie City Selfie City, a detailed multi-component visual exploration of 3,200 selfies from five major cities around the world, offers a close look at the demographics and trends of selfies [@selfie]. The team behind the project collected and filtered the data using Instagram and Mechanical Turk. Explore the differences between selfies snapped in New York and Berlin for example, as well as those between men and women across the world. Estimated Age and Gender Distribution 4.3 Evolving Demographics Another common use is to look at how something changes over time. Time-series data can be shown many ways and these are some examples. 4.3.1 Millennial Generation Diversity The millennial generation is bigger and more diverse than the baby boomer generation [@age_groups]. CNNMoney’s interactive chart showing the size and diversity of the millennial generation compared to baby boomers was built using U.S. Census Data. It turns dry numbers into an intriguing story, illustrating the racial makeup of different age groups from 1913 to present. Racial Diversity of US Generations 4.3.2 How the Recession Reshaped the Economy, in 255 Charts The first large graph contains 255 lines to show how the number of jobs has changed for every industry in America, using color to highlight the lines and let viewers see the specifics for each industry [@recession_economy]. By hovering over a line, viewers can get the detailed information of that industry’s job trend. Keeping this extra data hidden until needed makes it easier for readers to absorb the bigger picture from this huge data visualization. Below the overall chart are subsets categorized by job sector and sub-industries. Readers can choose the industry or sector they are interested in and, like in the first graph, view the more detailed information by hovering over a line. 4.3.3 An Aging Nation: Projected Number of Children and Older Adults Aging population is always a hot topic in social economics and politics [@aging_nation]. There are several different data visualizations collected to show the aging population in the world. This one includes a bar chart and a line graph to demonstrate the aging population compared with the population of children. The good things about this visualization are that it is simple to see and compare, employs color to differentiate the categories, and highlights the intersection point. 4.3.4 From Pyramid to Pillar: A Century of Change, Population of the U.S. This is a population pyramid. “A population pyramid is a pair of back-to-back histograms for each sex that displays the distribution of a population in all age groups and in gender” [@population_pyramid]. It is a good candidate to visualize changes in population distributions (sex, age, year). The shape of a pyramid is also used to represent other characteristics of a population. To illustrate, A pyramid with a very wide base and a narrow top section suggests a population with both high fertility and death rates. It is a useful tool for making sense of census data. [@animated_pyramid] offers an animated pyramid. Comparison of aging population in US and Japan This is an animated and multiple-population pyramid. It used to compare different patterns across countries. One additional benefit for the interactive population pyramid is that it shows the shape changes by year, which is useful for continuous time-series comparison. A similar project with R code is here. 4.3.5 Music Timeline Google’s Music Timeline illustrates a variety of music genres waxing and waning in popularity from 2010 to the present day, based on how many Google Play Music users have an artist or album in their library, and other data such as album release dates [@google_music]. One part of why this is a good visualization is that in addition to the general timeline of all music, the reader is able to drill down to one specific genre to see its subgenres. The drill-down interaction allows for more details without creating one detailed and cluttered visualization. 4.4 Environmental Related Problems There are many case studies on visualizations of environment related issues. 4.4.1 Global Carbon Emissions This data visualization, based on data from the World Resource Institute’s Climate Analysis Indicators Tool and the Intergovernmental Panel on Climate Change, shows how national CO₂ emissions have transformed over the last 150 years and what the future might hold. It also allows the audience to explore emissions by country for a range of different scenarios [@CO2_emission]. 4.4.2 What’s really warming the world? This case study begins by clearly explaining necessary background information and the analytic questions it seeks to answer. Next, it analyzes each factor separately using both verbal explanations and dynamic graphics to compare the observed temperature movements, and then categorizes related factors into “natural factors” or “human factors”. After that, it combines all the dynamic graphics into one, which makes the results easier and more straightforward to compare. Lastly, the authors provide further detailed explanations with data set sources to support their results. Overall, this case study is straightforward, easy to understand and informative [@world_warming] referenced in [@int_viz_capt]. 4.4.3 Understanding Plastic pollution using visualization Plastic pollution is the accumulation of plastic products in the environment that adversely affects wildlife, wildlife habitat, or humans. Human usage of plastic has increased manifolds in last few decades. Since plastic is inexpensive and durable, they have a wide variety of usage in our everyday life. Since the 1950’s an estimated 6.3 billion tons of plastic has been produced, of which only about 9% is recycled [@Wiki_Plastic_Pollution]. Usage of plastic in last few decades [@Plastic_Pollution_visualizations]: Plastic has become part of our daily life and human dependence on plastic has increased over time. Below shows some of the plastic products used day in day out by us undermining their effects on environment. [@Plastic_Pollution_visualizations] What is plastic used for. [@Plastic_Pollution_visualizations] With a share of 26 percent, China may be the largest plastic producer in the world - yet the largest plastic consumer is neighboring Japan. The people living in the island nation have a consumption that exceeds even that of the entire rest of Asia and Africa combined. [@Plastic Pollution visualizations] Plastic Use: Industrial nations top the charts [@Plastic_Pollution_visualizations] Visualization of Ocean Plastic collection: This world view visualization shows how much plastic is in our oceans.[@Ocean_Plastic_Pollution] Infographic plastic pollution [@Plastic_Pollution_Infographics] Infographic plastic pollution [@Plastic_Pollution_Infographics] How long does plastic remain in the ocean? [@Plastic_Pollution_visualizations] 4.5 Animated Data Visualization Like evolving demographics, these visualizations are demographics that change over time. These however, are self-animated instead of interactive. 4.5.1 A Day in the Life of Americans This animated data visualization shows the time people spend on daily activities throughout the day [@American_life]. The plot is simple and easy to interpret, but it also includes a good number of variables including time, activity type, number of people doing each activity, and the order in which activities are done. One of the plot’s biggest strengths is that by using one dot to represent each person in the study and using animation, we can actually drill down to the level of an individual and follow him or her throughout the day. The accumulation of dots for each particular activity also gives us an aggregate-level view of the same data, so we get both individual and aggregate insights. A drawback of the plot is that it is hard for our eyes to keep track of 1000 simultaneously moving dots. The author of the post addresses this by creating subsequent plots with stationary lines at key times of the day. This represents people’s movements from one activity to another without overwhelming the reader. Overall, this is an engaging, informative, and a fun animated plot that has relevance and tells a story. 4.5.2 Hans Rosling’s 200 Countries, 200 Years, 4 Minutes Global health data expert Hans Rosling’s famous statistical documentary The Joy of Stats aired on BBC in 2010, but it’s still turning heads. In the remarkable segment “200 Countries, 200 Years, 4 Minutes”, Rosling uses augmented reality to explore public health data in 200 countries over 200 years using 120,000 numbers, in just four minutes [@hans_rosling]. Screenshot from “200 Countries, 200 Years, 4 Minutes” 4.6 Language 4.6.1 Green Honey The visualization spans a webpage [@green_honey] referenced in [@cool_data]. As you scroll down, the text changes, as do many colored dots that move over the white background. The dots are used to represent not only each colors’ hue, but the numbers that fall into each category—for example, what colors are the most popular “base” colors for English and Chinese. The continuous flow of this visualization helps bring it together, allowing users to scroll through the information at their own pace, but also creating a seamless, creative work. 4.6.2 Linguistic Concepts This case study is about the usage of linguistic concepts; it discusses how the data is being used and how visual graphics are used to deliver the main insights. It presents an educational tool that integrates computational linguistics resources for use in non-technical undergraduate language science courses. By using the tool in conjunction with case studies, it provides opportunities for students to gain an understanding of linguistic concepts and analysis through the lens of realistic problems in feasible ways [@lingui_data]. HistoBankVis, is a novel visualization system designed for the interactive analysis of complex, multidimensional data to facilitate historical linguistic work [@lingui_data1]. In this paper, the visualization’s efficacy and power is illustrated by means of a concrete case study investigating the diachronic interaction of word order and subject case in Icelandic. Much of what computational linguists fall back upon to improve natural language processing and model language “understanding” is structure that has, at best, only an indirect attestation in observable data. The sheer complexity of these structures, and the observable patterns on which they are based, however, usually limits their accessibility, often even to the researchers creating or studying them. Traditional statistical graphs and custom-designed data illustrations fill the pages of CL papers, providing insight into linguistic and algorithmic structures, but visual ‘externalizations’ such as these are almost exclusively used in CL for presentation and explanation. Visualizations can also be used as an aid in the process of research itself. There are special statistical methods, falling under the rubric of “exploratory data analysis”, and visualization techniques just for this purpose. But these are not widely used or even known in CL. These novel data visualization techniques offer the potential for creating new methods that reveal structure and detail in data. Visualization can provide new methods for interacting with large corpora, complex linguistic structures, and can lead to a better understanding of the states of stochastic processes. 4.6.3 State of the Union 2014 Minute by Minute on Twitter Twitter’s data team assembled an impressive interactive data hub that depicts how Twitter users across the globe reacted to each paragraph of President Obama’s 2014 State of the Union address [@SotU2014]. You can slice and dice the data by topic hash tag (for example, #budget, #defense, or #education) and state, resulting in a pretty powerful visualization. 4.7 Political Relationships 4.7.1 Connecting the Dots Behind the Election This article by the New York Times lists several different candidates and creates compelling visuals that link their campaigns to previous ones [@campaign_staff][@cool_data]. Each visual contains several different sized dots that represent a specific campaign, administration, or other governmental organization related to the candidate’s current campaign, which are then connected by arrows. Hovering over a specific dot highlights the connections between the groups. The visual is a great way to summarize what would otherwise require a long slog through years of information into an easily accessible and viewable format so that voters can figure out where the candidates’ experiences lie. Source: [@campaign_staff] referenced in [@cool_data] Clinton 2016 Campaign Staff 4.7.2 A Guide to Who is Fighting Whom in Syria One of the charts shown in the link [@int_viz_capt], the visualization of ‘A Guide to Who is Fighting Whom in Syria’ is an interesting graphic to study. The visualization and its report can be seen at [@syria_chart]. Who is Fighting Whom in Syria This visualization helps elucidate an extremely complicated topic like the Syrian War. It consists of 3 different emojis in three different colors, with each (color+facial expression) combination showing the ties and conflicts between the various groups involved in the Syrian War. When you click on each emoji, a small dialogue box pops up that explains the relationships between the various countries and rebel groups involved in the war. This is not only easy to understand, but is also pleasing to the eyes. Green emoji shows ‘Friendly’ relationship Red emoji shows the ‘Enemies’ relationship Yellow emoji shows ‘Complicated’ relationship 4.7.3 Law enforcement and fraud detection “Data is the new oil”– it may be a cliche, but it’s true. Like oil, data in its raw, unrefined form is pretty worthless. To unlock its value, data needs to be refined, analyzed and understood [@lawfraud]. You can say the same about graphs. More and more organizations are seeing potential in their data connections. The question is, how do you get non-experts to analyze graphs at scale and understand potentially complex insight? Most of the time, the answer is through interactive graph visualization. There are four reasons why graph visualization is such a powerful tool: It’s intuitive – presenting a graph as a node-link structure instantly makes sense, even to people who’ve never worked with graphs before. It’s fast – our brains are great at spotting patterns, but only when data is presented in a tangible format. Armed with visualization, we can spot trends and outliers very effectively. It’s flexible – the world is densely connected, so as long as there’s an interesting relationship in your data somewhere, you’ll find value in a graph visualization. It’s insightful – exploring graph data interactively allows users to gain deeper knowledge, understand context and ask more questions, compared to static visualization or raw data. In a growing number of domains, graph visualization has become a must-have data analysis tool. Let’s take a quick look at the ways graph visualization is being used in real life. The police have been using Graph visualization, or link analysis as it’s commonly known – for decades to ‘join the dots’ in investigations. What has changed is the use of technology to make joining the dots a more automated and scalable process. A failure to analyze the bigger, joined-up picture was cited as a shortcoming of the intelligence services after the 9/11 terror attacks. In the years that followed, law enforcement and security agencies drove graph visualization forward. New approaches and technologies were created specifically for large-scale data analysis of communications records, open source intelligence (OSINT), and police databases. Lawful interception, the legally mandated interception of personal communications data, provided huge volumes of data on criminal and terrorist activity. Paired with social network analysis, graph visualization techniques allowed non-specialized staff to explore the data and uncover important insight. Another early adopter of graph visualization techniques was the financial services industry. Fraud detection is about finding unusual connections – between accounts, transactions, insurance policies, devices, etc. There’s great value in visualizing that data as a graph. Known fraud detection is largely automated with rule scoring and pattern matching. Visualization lets you review edge-cases and outliers more quickly. Speed is important, because sometimes analysts only have seconds to approve or deny a transaction. In those cases, visualizations are simple, small and with limited interaction. To get a clear overview quickly, analysts need effective layouts. Other functionalities, like expanding and filtering helps fraud analysts to see context on demand. Three things are consistent across both graph visualization use cases: They involve highly connected data (obviously). That highly connected data conceals risk insight. That insight is needed to power quick and confident decision making. When connected data insight is critical, only interactive and robust visualization tools are up to the task. 4.8 Uncategorized 4.8.1 Simpson’s Paradox The Visualizing Urban Data Idealab (VUDlab) out of the University of California-Berkeley put together this visual representation of data that disproves the claim in a 1973 suit that charged the school with sex discrimination. Though the graduate schools had accepted 44% of male applicants but only 35% of female applicants, researchers later uncovered that if the data were properly pooled, there was actually a small but statistically significant bias in favor of women. This is called a Simpson’s Paradox. Simpson’s Paradox originally from vudlab.com 4.8.2 Every Satellite Orbiting Earth Reference: This interactive graph, built using a database from the Union of Concerned Scientists, displays the trajectories of the 1,300 active satellites currently orbiting the Earth. Each satellite is represented by a circular icon, color-coded by country and sized according to launch mass [@Satellite]. Low Earth Orbit Satellites 4.8.3 Malaria The authors of Vizwiz redesigned “The Seasonality of Confirmed Malaria Cases in Zambia Southern Province” by pointing out what works well, what could be improved, and why their new visualization will be better New Version: [@malaria_cases_zambia] Original Version: [@malaria_zambia_original] Original visualization of malaria cases Redesigned visualization of malaria cases The original visualization effectively shows the seasonality of malaria cases but is unclear if the two reporting categories are stacked or one behind the other (and is rather garish). The creator of the redesign made the seasonality more obvious by combining the reporting categories. However it is unclear what his intent was when adding the yearly data split by districts. 4.8.4 Is it Better to Rent or Buy? There are many factors involved in deciding to rent or buy a house which has led to many calculators that are supposed to simplify this decision. This calculator includes several sloping charts, each including a factor that will affect how much you’ll have to pay, such as the individual cost of your home and your mortgage rates [@rent_or_buy]. A movable scale along the bottom of each chart allows you to enter different data, such as changing the “cost of rent per month” on the side. This can be useful in price comparison: if you can find a similar house to rent for that much per month or less, it’s more cost effective to just rent the home. This visualization is incredibly thorough and a useful tool for homeowners of any age and status. 4.8.5 An Interactive Visualization of NYC Street Trees Reference: [@trees] Using data from NYC Open Data, this interactive visualization shows the variety and quantity of street trees planted across the five New York City boroughs. As the reader hovers over a tree or bar segment, the connected sections light up, making it easier for the reader to look at what otherwise could have been a very dense chart. NYC Street Trees 4.8.6 Adding up the White Oscars Winners A visualization of all previous winners of the Best Actor/Actress Oscar winners can be seen in an article by Bloomberg [@adding_oscars]. From the attributes of past Ocsars winners, the authors have developed a set of attributes that they believe will continue to be prevalent in future Oscar winners. It is extremely interesting to see how the article shows the features of the Best Actress, Actor, movies, etc. in a simple and captivating visual. The visualization is interactive and we can click on each attribute like ‘Hair Color’, ‘Eye Color’, etc. to see the features of the actors and actresses who are likely to win the Oscars. Best Actor and Best Actress [@oscars_sowhite_chart] Similarly, the visualization gives also information about the different aspects of movies that are more likely to win, like ‘Length,’ ‘Month,’ ‘Budget,’ etc. Best Picture 4.8.7 Kissmetrics blog: visualization of metrics [@facebook_organic] Kissmetrics blog is a place where people talk about analytics, marketing, and testing through narratives and visualization of metrics. Metrics are important in the real world, especially when developing/promoting products. Visualization of metrics is also essential so that stakeholders can monitor performance, identify problems and dive deep into potential issues. A good example from the Kissmetrics blog is about Facebook’s organic reach. One important point discussed in the blog is whether the Facebook’s organic reach is decreasing drastically. The general trend shows that there is a huge decline in Facebook’s page organic reach. The following graphs show that the engagement is increasing; that is, while the quantity of content is decreasing, the quantity is increasing. This resonates with what we have learned at class in terms of how different perspectives of interpreting data can lead to different conclusions. 4.8.8 Describe Artists with Emoji Using the data from Spotify, the author listed the 10 most distinctive emoji used in the playlists related to popular artists [@artist_emoji]. The table being used in this visual is very straightforward to link the artist to the emojis and is very easy to compare among artists. When you hover over the emoji, further information is presented. 4.8.9 Goldilocks Exoplanets https://news.nationalgeographic.com/news/2014/04/140417-exoplanet-interactive/ Using data from the Planetary Habitability Laboratory at the University of Puerto Rico, the interactive graph plots planetary mass, atmospheric pressure, and temperature to determine what exoplanets might be home, or have been home at one point, to living beings. 4.8.10 Washington Wizards’ Shooting Stars [@basketball] This detailed data visualization demonstrates D.C.’s basketball team’s shooting success during the 2013 season. Using statistics released by the NBA, the visualization allows viewers to examine data for each of 15 players. For example, viewers are able to see how successful each player was at a variety of types of shots from a range of spots on the court, compared to others in the league. 4.8.11 Visualization of big data security: a case study on the KDD99 cup data set This paper utilized a visualization algorithm together with big data analysis in order to gain better insights into the KDD99 dataset: Abstract Cybersecurity has been thrust into the limelight in the modern technological era because of an array of attacks often bypassing untrained intrusion detection systems (IDSs). Therefore, deciphering better methods for identifying attack types to train IDSs more effectively has become a field of great interest. Key cyber-attack insights exist in big data; however, an efficient approach is required to determine strong attack types to train IDSs to become more effective in key areas. Despite the rising growth in IDS research, there is a lack of studies involving big data visualization, which is key. The KDD99 dataset has served as a strong benchmark since 1999; therefore, this data set was utilized in the experiment. This study utilized a hash algorithm, a weight table, and sampling method to deal with the inherent problems caused by analyzing big data: volume, variety, and velocity. By utilizing a visualization algorithm, the researchers were able to gain insights into the KDD99 data set with a clear identification of “normal” clusters and described distinct clusters of effective attacks. To read the full paper, please follow the reference link: [@gapminder] 4.8.12 How Data Visualization is Helping in Healthcare Decision Making? [@marksman] Healthcare service providers increasingly investigate different visual and interactive methods in creating and examining large graphs, charts, interactive visualizations, and 2D/3D visualization of discrete event simulation (DES) to comprehend complex and large datasets, recognize connections and trends, model and simulate healthcare events, and communicate and interpret the findings. Expected results include more efficient and effective clinical performance monitoring and improvement, patient flow modeling and management, better patient care quality, security and effectiveness, better support for clinical costing and resource coordination, better-planned development and competitive advantage. Traditional visualization strategies often require significant processing time, which restrains high-throughput analysis. Interactive visualization frameworks maintain a closed loop between the user and the system and, thus, need to be very fast. Building such a framework requires the development of new visualization methods, and there exists the need to design new and effective interaction techniques which are being developed by researchers. Informatics for Integrating Biology and the Bedside (i2b2), an initiative sponsored by the NIH Roadmap National Centers for Biomedical Computing is another such program that provides a query tool that supplies aggregate counts and basic analyses of patient populations from clinical data warehouses (CDWs). i2b2 (i2b2 to Tableau) is effective in estimating patient cohort sizes and has an extendable design where modules with additional features can be developed. Other tools such as R, Python, etc. also helping healthcare a lot. Today, data visualization solutions can be found everywhere in healthcare systems from hospital operations monitoring and patient profiling to demand projection and capacity planning. Moreover, health informatics databases and networks have amplified benefits with information visualization as it dramatically expands the capacity of patients, clinicians, and public health policy makers to make better decisions. 4.8.13 The Atlas of Sustainable Development Goals 2018 - Data Visualization of World Development [@Word_Bank_Data] This is an interesting source and a good visual guide to data and development. It discusses trends, comparisons, and measurement issues using accessible and shareable data visualizations. As the graphs cite below, they’re informative and clean: 1 2 The data draws on the World Development Indicators- the World Bank’s compilation of internationally comparable statistics about global development and the quality of people’s lives. For each of the SDGs, relevant indicators have been chosen to illustrate important ideas. The contents of this publication are available as a PDF, the data is available in the World Bank’s Data Catalog and the code used to generate the majority of figures is available on Github. "],
["patterns.html", "Chapter 5 Patterns 5.1 How to customize a legend in MATLAB 5.2 Best Practices in Visual Analysis 5.3 Color 5.4 Using Shapes as Filters in Tableau When Your Fields Are Measures 5.5 Outlier Detection 5.6 Genetic Network Reconstruction 5.7 Tips to Improve Data Visualization 5.8 Building Advanced Analytics Application with TabPy 5.9 Pick the Right Chart Type 5.10 Why pie chart is bad: a comparison with the bar chart 5.11 Use maps only when effective 5.12 Chose the right baseline in data visualization 5.13 Using design patterns to find greater meaning in your data 5.14 Chart types 5.15 Word Cloud 5.16 An example to back some of our theories on ‘how to tell stories using data visualization’ / ‘exploratory data visualization’ 5.17 Reusable Data Visualization Code in R 5.18 Data Mining and Data Visualization 5.19 Creating a Diverging Bar Chart 5.20 10 Useful Python Data Visualization Libraries 5.21 Top 5 best practices for creating effective dashboards and the 7 mistakes you don’t want to make [@dashboard_practices]:", " Chapter 5 Patterns 5.1 How to customize a legend in MATLAB Legend creates a legend with descriptive labels for each plotted data series. A good legend helps us to better understand the graph. For instance, we can accurately tell the meaning for a line of a plot or we can understand the extent range for certain colors from a legend. Without a legend, everything can be confusing for the readers. I would like to introduce some basic methods of customizing a legend. Add a basic legend First, we use the legend() function to add a basic legend. For example, say we already have a line graph and there are several lines on that plot. We can simply add a legend to distinguish them from each other by using the ax.legend() function. &lt;!DOCTYPE html&gt; import matplotlib.pyplot as plt plt.style.use(&#39;classic&#39;) %matplotlib inline import numpy as np x = np.linspace(0, 10, 1000) fig, ax = plt.subplots() ax.plot(x, np.sin(x), &#39;-b&#39;, label=&#39;Sine&#39;) ax.plot(x, np.cos(x), &#39;--r&#39;, label=&#39;Cosine&#39;) ax.axis(&#39;equal&#39;) leg = ax.legend(); &lt;/script&gt; Add a legend on different position If we want it on a specific position of the plot, we can use loc=‘upper left’ inside the function to indicate where you want to put the legend at. &lt;!DOCTYPE html&gt; ax.legend(loc=&#39;upper left&#39;, frameon=False) fig &lt;/script&gt; Customize a box surrounding the legend Also, we can decide whether you need a box surrounding the legend or not. &lt;!DOCTYPE html&gt; ax.legend(fancybox=True, framealpha=1, shadow=True, borderpad=1) fig &lt;/script&gt; Legend for size of points import pandas as pd cities = pd.read_csv(&#39;data/california_cities.csv&#39;) # Extract the data we&#39;re interested in lat, lon = cities[&#39;latd&#39;], cities[&#39;longd&#39;] population, area = cities[&#39;population_total&#39;], cities[&#39;area_total_km2&#39;] # Scatter the points, using size and color but no label plt.scatter(lon, lat, label=None, c=np.log10(population), cmap=&#39;viridis&#39;, s=area, linewidth=0, alpha=0.5) plt.axis(aspect=&#39;equal&#39;) plt.xlabel(&#39;longitude&#39;) plt.ylabel(&#39;latitude&#39;) plt.colorbar(label=&#39;log$_{10}$(population)&#39;) plt.clim(3, 7) # Here we create a legend: # we&#39;ll plot empty lists with the desired size and label for area in [100, 300, 500]: plt.scatter([], [], c=&#39;k&#39;, alpha=0.3, s=area, label=str(area) + &#39; km$^2$&#39;) plt.legend(scatterpoints=1, frameon=False, labelspacing=1, title=&#39;City Area&#39;) plt.title(&#39;California Cities: Area and Population&#39;); &lt;/script&gt; Multiple legends &lt;!DOCTYPE html&gt; fig, ax = plt.subplots() lines = [] styles = [&#39;-&#39;, &#39;--&#39;, &#39;-.&#39;, &#39;:&#39;] x = np.linspace(0, 10, 1000) for i in range(4): lines += ax.plot(x, np.sin(x - i * np.pi / 2), styles[i], color=&#39;black&#39;) ax.axis(&#39;equal&#39;) # specify the lines and labels of the first legend ax.legend(lines[:2], [&#39;line A&#39;, &#39;line B&#39;], loc=&#39;upper right&#39;, frameon=False) # Create the second legend and add the artist manually. from matplotlib.legend import Legend leg = Legend(ax, lines[2:], [&#39;line C&#39;, &#39;line D&#39;], loc=&#39;lower right&#39;, frameon=False) ax.add_artist(leg); 5.1.1 R for Data Visualization Summary from book “R for Data Science” Chapter 3 link #### Formula: layered Grammar of Graphics ggplot(data = &lt;DATA&gt;) + (mapping = aes(&lt;MAPPINGS&gt;), stat = &lt;STAT&gt;, position = &lt;POSITION&gt; ) + + The grammar of graphics [@Grammar_Graphics] is based on the implication that you can uniquely describe any plot as a combination of 1) a dataset, 2) a geom, 3) a set of mappings, 4) a stat, 5) a position adjustment, 6) a coordinate system, and 7) a faceting scheme. 5.1.1.1 Explanations of Formula Aes/Mapping: Global Mapping and Local Mapping ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(mapping = aes(color = class)) + geom_smooth() “mapping = aes(x = displ, y = hwy)” is a global mapping, where “mapping = aes(color = class)” is a local mapping. ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(mapping = aes(color = class)) + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; Position Adjustment “Identity” position will place each object exactly where it falls in the context of the graph. This is not very useful for bars. “Fill” position works like stacking, but makes each set of stackedbars the same height. This makes it easier to compare proportions across groups. “Dodge” position places overlapping objects directly beside one another, which makes it easier to compare individual values. “Jitter” position adds a small amount of random noise to each point. This spreads the points out because no two points are likely to receive the same amount of random noise. Coordinate Systems 1. default: Cartesian coord_flip() switches the x- and y-axes. Very usefulif you want horizontal boxplots. ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() + coord_flip() 3. coord_quickmap() sets the aspect ratio correctly for maps. This is very important if you draw map. coord_polar() uses polar coordinates. Polar coordinates reveal an interesting connection between a bar chart and a Coxcomb chart. 5.1.2 Data Mining vs.Data Visualization In Data Mining, there are different processes involve carrying out the data mining process such as data extraction, data management, data transformations, data pre-processing, etc. In Data Visualization, the primary goal is to convey the information efficiently and clearly without any deviations or complexities in the form of statistical graphs, information graphs, and plots. Also, the author listed the top 7 comparisons between data mining and data visualization, and 12 key differences between data mining and data visualization. After reading the article, you will have a very clear understanding of what are data mining and data visualization and the characters for those two techniques. Building advanced analytics application with TabPy [@TabPy] Imagine a scenario where we can just enter some x values in a dashboard form, and the visualization would predict the y variable!!! Here is a link that shows how to integrate and visualize data from Python in Tableau. This is especially relevant to all data science students, as this is one of the tools used for visualizing advanced analytics. The author here has given an example using data from Seattle’s police department’s 911 calls and he tries to identify criminal hotspots in the area.The author uses machine learning (spatial clustering) and creates a great interactive visualization, where you can click on the type of criminal activity and the graph will show various clusters. There are other examples and use cases that may be downloaded, and the scripts are also given by the author for anyone who is interested in trying it out. 5.2 Best Practices in Visual Analysis Referenced below is a free pdf with some examples of best practices in visual analysis. It discusses the most effective charts for various kinds of analysis. It is a helpful and relevant resource for data science students interested in presenting analyses using simple and effective visualizations that tell the complete story. Some of the key areas the author highlights are visualizing trends over time, comparison and ranking, correlation, distribution, geographical data etc. The author gives examples of how simple graphs can also be made more effective simply by adding a few more elements or making simple adjustments. This is a great starting point for creating effective charts and we may use these principles also when we start doing advanced analytics. 5.2.1 Three Rules to Follow in order to Develop Intuitive Dashboards Often a designer can become too concerned with coming up with a visual that is too intricate and overly complicated. A dashboard should be appealing but also easy to understand. Following these rules will lead to the effective presentation of the data [@intuitive-dash]. 5.2.1.1 The dashboard should read left to right Because we read from top to bottom and left to right, a reader’s eyes will naturally look in the upper left of a page. The content should therefore flow like words in a book. It is important to note that the information at the top of the page does not always have to be the most important. Annual data is usually more important to a business but daily or weekly data could be used more often for day to day work. This should be kept in mind when designing a dashboard as dashboards are often used as a quick convenient way to look up data. 5.2.1.2 Group related information together Grouping related data together is an intuitive way to help the flow of the visual. It does not make sense for a user to have to search in different areas to find the information they need. 5.2.1.3 Find relationships between seemingly unrelated areas and display visuals together to show the relationship. Grouping unrelated data seems contradictory to the second rule, but the important thing is to tell a story not previously observed. Data analytics is all about finding stories the data are trying to tell. Once they are discovered, the stories need to be presented in an effective manner. Grouping unrelated data together makes it easier to see how they change together. Maps Use of maps can be tricky. Geographical data doesn’t imply a map. Maps can be useful for application where proximity matters, but for straight “what is higher” type comparisons, they’re not very effective as large regions will draw attention easier than smaller regions due to more concentrated color. 5.3 Color A. Color for Numerical Scales: Color for numerical scales should be used with caution. The way you interpret a shade depends on the colors around it and sometimes it can lead to false conclusions. B. Leverage Color Associations: When we say strawberries we associate red color with it. If we can leverage the how people associate different colors for different things, we will not even need a legend to interpret things. Color can be used to leverage long-term memory very quickly. C. Use Bright Colors to Highlight: To attract attention to a certain part of data, bright colors can be used. Alarm colors draw the eye quickly to areas that need attention and help get that message across. 5.4 Using Shapes as Filters in Tableau When Your Fields Are Measures Reference:[@Measures] This article [@interworks] is useful to analyze and redesign different graphs presented in the article “America’s unique gun violence problem, explained in 17 maps and charts” [@gunviolence].This article introduces the methodologies on how to use shapes as filters in Tableau when your fields are measures. Basically, it teaches you how to load custom shapes as action filters and use them for showing different graphs with those filters, which can make your visualization more interesting and interactive. You can also download the tableau file for practice. [@interworks] [@gunviolence] This article is useful to analyze and redesign different graphs presented in the article “America’s unique gun violence problem, explained in 17 maps and charts” referenced above .This article introduces the methodologies on how to use shapes as filters in Tableau when your fields are measures. It teaches you how to load custom shapes as action filters and use them for showing different graphs with those filters, which can make your visualization more interesting and interactive. You can also download the tableau file for practice. This article explains how data visualization can enhance awareness of the data available and its importance in business decisions. The author explains a situation where poor data visualization led to bad decisions and the negative impact of these decisions. 5.5 Outlier Detection We can use data visualization for outlier detection in a data set[@outliar]. Different methods for outlier detection in functional data have been developed during the years. Several of these methods rely on different notions of functional depth, robust principal components, or random projections of infinite-dimensional data into R. Some distributional approaches have also been considered (Gervini, 2009). In functional data analysis, we observe curves defined over a given real interval and shape outliers may be defined as those curves that exhibit a different shape from the rest of the sample. Other types of outliers include: Type 1: Global outliers (also called “point anomalies”): A data point is considered a global outlier if its value is far outside the entirety of the data set in which it is found. Type 2: Contextual (conditional) outliers: A data point is considered a contextual outlier if its value significantly deviates from the rest of the data points in the same context. Note that this means that the same value may not be considered an outlier if it occurred in a different context. If we limit our discussion to time series data, the “context” is almost always temporal, because time series data are records of a specific quantity over time. Contextual outliers are common in time series data. Type 3: Collective outliers: A subset of data points within a data set is considered anomalous if those values as a collection deviate significantly from the entire data set, but the values of the individual data points are not themselves anomalous in either a contextual or global sense. In time series data, one way this can manifest is as normal peaks and valleys occurring outside of a time frame when that seasonal sequence is normal or as a combination of time series data that is in an outlier as a group. Below is a simple example. Outlier treatment is important because it can drastically bias/change the fit estimates and predictions. Illustration: # Inject outliers into data. cars1 &lt;- cars[1:30, ] # original data cars_outliers &lt;- data.frame(speed=c(19,19,20,20,20), dist=c(190, 186, 210, 220, 218)) # introduce outliers. cars2 &lt;- rbind(cars1, cars_outliers) # data with outliers. # Plot of data with outliers. par(mfrow=c(1, 2)) plot(cars2$speed, cars2$dist, xlim=c(0, 28), ylim=c(0, 230), main=&quot;With Outliers&quot;, xlab=&quot;speed&quot;, ylab=&quot;dist&quot;, pch=&quot;*&quot;, col=&quot;red&quot;, cex=2) plot(cars2$dist,cars2$speed) # Plot of original data without outliers. Note the change in slope (angle) of best fit line. plot(cars1$speed, cars1$dist, xlim=c(0, 28), ylim=c(0, 230), main=&quot;Outliers removed \\n A much better fit!&quot;, xlab=&quot;speed&quot;, ylab=&quot;dist&quot;, pch=&quot;*&quot;, col=&quot;red&quot;, cex=2) Detection of Outliers is performed using: Univariate Approach Multivariate Approach Multivariate Model Approach 5.6 Genetic Network Reconstruction Data visualization techniques are used to reconstruct genetic networks from genomics data. Reconstructed genetic networks are predicted interactions among genes of interest and these interactions are inferred from genomics data, microarray data or DNA sequences. Genomics data are generally contaminated and high-dimensional. It is important to examine and clean data carefully to attain meaningful inferences. Thus, visualization tools that are used in the preprocessing of data associated with genetic network reconstruction are also reviewed and chosen wisely. 5.7 Tips to Improve Data Visualization 5.7.1 Comparison Include a zero baseline if possible. Although a line chart does not have to start at a zero baseline, it should be included if it gives more context for comparison. If relatively small fluctuations in data are meaningful (e.g., in stock market data), you may truncate the scale to showcase these variances. Always choose the most efficient visualization. Watch your placement - You may have two nice stacked bar charts that are meant to let your reader compare points, but if they’re placed too far apart to “get” the comparison, you’ve already lost. Tell the whole story. Maybe you had a 30% sales increase in Q4. Exciting! But what’s more exciting? Showing that you’ve actually had a 100% sales increase since Q1. 5.7.2 Copy Don’t over explain if the copy already mentions a fact. The subhead, callout, and chart header don’t have to reiterate it. Keep the chart and graph headers simple and to the point. There’s no need to get clever, verbose, or pun-tastic. Keep any descriptive text above the chart brief and directly related to the chart underneath. Remember: Focus on the quickest path to comprehension. Use callouts wisely. Callouts are not there to fill space. They should be used intentionally to highlight relevant information or provide additional context. Don’t use distracting fonts or elements. Sometimes you do need to emphasize a point. If so, only use bold or italic text to emphasize a point — and don’t use them both at the same time. 5.7.3 Color Use a single color to represent the same type of data. Watch out for positive and negative numbers. Don’t use red for positive numbers or green for negative numbers. Those color associations are so strong it will automatically flip the meaning in the viewer’s mind. Make sure there is sufficient contrast between colors. Avoid patterns. Stripes and polka dots sound fun, but they can be incredibly distracting. If you are trying to differentiate, say, on a map, use different saturation of the same color. On that note, only use solid-colored lines (not dashes). Select colors appropriately. Don’t use more than 6 colors in a single layout. 5.7.4 Ordering Order data intuitively. There should be a logical hierarchy. Order categories alphabetically, sequentially, or by value. Order consistently. Order evenly. Use natural increments on your axes (0, 5, 10, 15, 20) instead of awkward or uneven increments (0, 3, 5, 16, 50). 5.7.5 Audience perspective Let the users lead. Know your audience. Designers should consider the way users prefer to understand the information, even in choosing basic analytic approaches. For users to feel comfortable adopting and sharing insights from analytics, they must be able to explain and defend the data. 5.7.6 Use layers to tell a story While style is one form of customization, layering unique data sets on a single visualization can tell a richer narrative and connect users to the data without getting too crowded. On a map, this can be as simple as zooming in and out, but it can also involve drill-downs (choosing a data point and expanding it to show more detail), links and other shortcuts. 5.7.7 Keep it simple Analytic results shouldn’t be presented to 10 decimal places when the user doesn’t need that level of precision to make a decision or understand a concept. Effective visual interfaces avoid 3-D effects or ornate gauge designs (a.k.a. “chart junk”) when simple numbers, maps or graphs will suffice. Reference: [@French] [@Steier] 5.8 Building Advanced Analytics Application with TabPy [@TabPy] Imagine a scenario where we can just enter some x values in a dashboard form, and the visualization would predict the dependent variable! Here is a link that shows how to integrate and visualize data from Python in Tableau. This is especially relevant to all data science students, as this is one of the tools used for visualizing advanced analytics. The author here has given an example using data from Seattle’s police department’s 911 calls and he tries to identify criminal hotspots in the area. The author uses machine learning (spatial clustering) and creates a great interactive visualization, where you can click on the type of criminal activity and the graph will show various clusters. There are other examples and use cases that may be downloaded, and the scripts are also given by the author to anyone who is interested in trying it out. 5.9 Pick the Right Chart Type Data visualization is a combination of art and science. When it comes to the artistic aspect, there are no correct answers for doing the visualization. There are many ways to present the data. However, when making sense of facts, numbers, and measurements, the better understanding is promoted by a logical path to follow. To determine the best type of chart is hard for those new to data visualization. Most people learn it by referring to other people’s work without understanding the underlying logic, so they don’t have the theory in their mind to make the judgment. When we are choosing the type of chart, we need to answer some questions: How many features would you like to show in a chart? How many data points do you want to display for each variable? Will you display time series data or other items or groups. After answering these questions, you should able to get a better imagination of your ideal graph. The simple guidance for using the different types of chart is - line charts for tracking trends over time, bar charts to compare quantities, scatter plots for a joint variation of two data items, bubble charts showing joint variation of three data items, and pie charts to compare parts of a whole. 5.10 Why pie chart is bad: a comparison with the bar chart Using pie chart is usually considered as a bad idea when it comes to data visualization. But why? Here, we explore some cons of using the pie chart to convey information and compare its effectiveness to the bar chart. [@hickey-pie-worst] [@henry-defense-pie] [@quach-penny] Some information may look nearly identical in a pie chart. But if the data is presented with bar charts, the story is different. See figure ?? and ?? for examples. Source: [@hickey-pie-worst] Source: [@hickey-pie-worst] It is difficult to compare the slices of a circle to figure out the distinctions in size between each pie slice, especially when there are a lot of categories. See figure ?? for example. Source: [@hickey-pie-worst] A Pie chart is easy to be manipulated (e.g. using a 3D pie chart). See figure ?? for example. Source: [@hickey-pie-worst] A Pie chart may be useful when comparing 2 different categories with different amounts of information. Specifically, it does a better job to distinguish two parts with a 25:75 split or one that is not 50:50 as people are sensitive to a right angle or a dividing line that is not straight. But this could be simply done by showing two numbers! See figure ?? and ?? for examples. Source: [@henry-defense-pie] Source: [@henry-defense-pie] 5.11 Use maps only when effective Maps are a popular choice when it comes to displaying geographical data. They are more exciting than a simple bar or line chart but still easy to comprehend. Maps grab the reader’s attention, so at the first glance they seem like a great option. However, just because the data can be represented on a map doesn’t mean it should be. The map should be serving a purpose and telling a story. When used properly, a map does an excellent job at this. But they are not the solution every time. As with any visual, one should step back and evaluate if the map is the best way to convey their message. One good use of a map is to show points or specific locations. This style can show how points are distributed and reveal patterns such as certain areas having more high end restaurants. This is not the right approach if the points do not tell a story. If the story is more about comparing data such as median salary, a map is not the most effective. A map of this kind can also lose its meaning if there are too many points and the data blurs together. Encoding the data is another potential area for confusion. The most popular methods are using color, shape, and size. Again, each of these can be effective when done properly but must avoid common mistakes. Using too many colors can make the chart harder to interpret. If necessary, data can be grouped into categories such as good and bad or high, medium and low. Shapes should be easily distinguished, so there shouldn’t be too many unique ones. Also, if the use of shapes doesn’t significantly add to the story, it is probably best to remove them. The size of a marker is a clear way to describe amounts but can easily become a problem if there are outliers. Locations with large values could obscure other data points. The best practice is to use just one of these methods rather than combining two or more. Source: [@Bradshaw] 5.12 Chose the right baseline in data visualization The baseline is very important to data visualization. If the baseline is different, the meaning will change a lot. Now here is a case study to show the importance of baseline and how to use it in different ways. # Create the data. a &lt;-rep(c(2010,2011,2012,2013,2014,2015),each = 4) b &lt;- seq(1:24) c &lt;- c(64.9,65.33,71.67,79.17,68.78,69.83,78.61,92.68,89.28,90.43,97.96,106.96,100.66,107.53,117.06,119.21,110.05,97.42,93.62,97.99,80,88.74,102.06,83) data &lt;- as.data.frame(cbind(a,b,c)) colnames(data) &lt;-c(&quot;year&quot;,&quot;quater&quot;,&quot;sales&quot;) Regular quarterly sales. We can see sales decreased a lot around 2014. The baseline here is historical sales. # Regular time series for sales par(cex.axis=0.7) data.ts &lt;- ts(data$sales, start=c(2010, 1), frequency=4) plot(data.ts, xlab=&quot;&quot;, ylab=&quot;&quot;, main=&quot;sales per quater&quot;, las=1, bty=&quot;n&quot;) Quarterly and yearly change sales. The baseline here is zero and look at the percentage changes. # Quaterly change curr &lt;- as.numeric(data$sales[-1]) prev &lt;- as.numeric(data$sales[1:(length(data$sales)-1)]) quaChange &lt;- 100 * round( (curr-prev) / prev, 2 ) barCols &lt;- sapply(quaChange, function(x) { if (x &lt; 0) { return(&quot;#2cbd25&quot;) } else { return(&quot;gray&quot;) } }) barplot(quaChange, border=NA, space=0, las=1, col=barCols, main=&quot;% sales change, quaterly&quot;) # Year-over-year change curr &lt;- as.numeric(data$sales[-(1:4)]) prev &lt;- as.numeric(data$sales[1:(length(data$sales)-4)]) annChange &lt;- 100 * round( (curr-prev) / prev, 2 ) barCols &lt;- sapply(annChange, function(x) { if (x &lt; 0) { return(&quot;#2cbd25&quot;) } else { return(&quot;gray&quot;) } }) barplot(annChange, border=NA, space=0, las=1, col=barCols, main=&quot;% sales change, annual&quot;) From this plot, it is very clear that the magnitude drops in sales for some quarters. The sales difference compare to now. The baseline here is the current sales. # Relative to current 2015 curr &lt;- as.numeric(data$sales[length(data$sales)]) salesDiff &lt;- as.numeric(data$sales) - curr barCols.diff &lt;- sapply(salesDiff, function(x) { if (x &lt; 0) { return(&quot;gray&quot;) } else { return(&quot;black&quot;) } } ) barplot(salesDiff, border=NA, space=0, las=1, col=barCols.diff, main=&quot;Sales difference from last quater 2015&quot;) Sales difference compared to the first quarter. ** The baseline here is the first quater sales.** # Relative to first quater ori &lt;- as.numeric(data$sales[1]) salesDiff &lt;- as.numeric(data$sales) - ori barCols.diff &lt;- sapply(salesDiff, function(x) { if (x &lt; 0) { return(&quot;gray&quot;) } else { return(&quot;black&quot;) } } ) barplot(salesDiff, border=NA, space=0, las=1, col=barCols.diff, main=&quot;Sales difference from first quater 2010&quot;) The difference between quarter sales and mean. ** The baseline is mean now.** # difference from the mean mean &lt;- mean(as.numeric(data$sales)) salesDiff &lt;- as.numeric(data$sales) - mean barCols.diff &lt;- sapply(salesDiff, function(x) { if (x &lt; 0) { return(&quot;gray&quot;) } else { return(&quot;black&quot;) } } ) barplot(salesDiff, border=NA, space=0, las=1, col=barCols.diff, main=&quot;Sales difference from mean&quot;) So before we start to plot, we should decide the baseline we want to use. Different baselines will lead to totally different graphs. source: [@Baseline_2013] 5.13 Using design patterns to find greater meaning in your data Visualizations that show comparisons, connections, and conclusions offer analytical clarity. Patterns based on function can help you see differences and similarities more clearly, understand relationships and behaviors more intimately, and predict future results with a greater level of certainty. When these patterns are presented as visualizations, they help you - 1) see comparisons, 2) make connections, and 3) draw conclusions from your data sets. The major functions can be described as: 5.13.1 Comparisons As shown in Figure 1, the bar chart with sparkline enables you to review the data at two different levels: a high-level assessment of the short-term three-month returns is represented with the bar chart, while the sparkline (the line chart below the bar) provides the details of the historical returns. Quickly and concisely, the sparkline shows you the path that has led up to the most recent returns. You can then assess that a narrow path provides consistent returns across the years while a wide path provides varied returns. Side-by-side comparisons of funds organized into two columns—% Returns and % Ahead of Benchmark—enables peer comparisons and fund-specific benchmark comparisons. Hence, you can see that not only has Global Large Cap Core provided positive returns, it has also provided the best and most consistent returns when compared to the benchmark. 5.13.2 Connections The string of charts in Figure 2 shows 10-year to year-to-date (YTD) performance returns, which can be interpreted as individual charts or a group of category charts. Similar to sounds waves, the symmetrical area charts grow equidistant from the source (the zero line) at each time interval to accentuate the returns even further. Here, the y-axis is shown in percentage. Instead of using the zero line to indicate positive or negative returns, it uses color to denote if the category returns are positive (black) or negative (red). For example, Multi-Cap Russell 3000 Growth produced 20% positive returns within the one-year time period and is shown with color fill in both directions from the zero line to purposefully duplicate the large gains and specifically uses black color fill to indicate the returns are positive. As evident from the name, the symmetrical chart doubles the returns to emphasize the amount of color fill. What else can you derive from organizing the information in a spectrum of negative to positive returns? Based on this organization, three groups of categories have resulted in straight losses (red), heavy gains (black), or a mix of gains and losses across a decade of returns. The string of charts makes it easier for you to see these three groups of categories to assess their distribution. Just like sound waves, each chart is a sound bite that streams the returns for each category with a “scream” announcing a huge gain (e.g., Multi-Cap Russel 3000 Growth) or loss (e.g., Mid-Cap Russel Mid Cap Growth). In some cases (e.g., Large Cap S&amp;P 500), the chart quietly announces mixed returns to adequately demand less attention. Next, you might wonder how you would have fared if you had invested in certain funds. You might ask: if I had purchased this fund five years ago, what would my return be? And what about the YTD returns? Since market timing is key to investment choices, the following presentation of hypothetical investments represents a range of results. 5.13.3 Conclusions In Figure 3, varied performance results become clear with a layered approach to show five potential entry points (10-year, 5-year, 3-year, 1-year, YTD) into an investment. For example, the International Large Cap Core fund provided 27% YTD returns, which contrast the negative returns you would have received had you invested in the fund 1, 5, or 10 years ago. Here, conclusions are derived based on known inputs with a divided review of positive or negative outcomes (shown on the y-axis). The line weights help to identify each entry point and show the range of differences between the entry points. Accordingly so, resulting returns are shown with simplified curves that connect the inputs and outputs. In this case, the chart has been customized to show an instance in which the user has opted to see the YTD return values as percentages listed to the right of each resulting output.[@greater] 5.14 Chart types Let’s review the most commonly used chart types, where it would be appropriate to use the typical chart and the pros and cons of each type of charts. Before introducing different types of charts, you can use the following website to familiarize yourself with different types of charts [@charts_viz]. 5.14.1 Time Series Data What are some of the most common data visualizations seen in newspapers, textbooks, and corporate annual reports? Graphs showing a country’s GDP growth trends or charts capturing a company’s sales growth in the last 4 quarters would be high up on the list. Essentially, these are visualizations that track time series data – the performance of an indicator over a period of time – also known as temporal visualizations. Temporal visualizations are one of the simplest and quickest ways to represent important time series data. There are 7 handy temporal visualization styles for your time series data. source: [@aya-time-series] 5.14.2 Line Graph A line graph is the simplest way to represent time series data. It is intuitive, easy to create, and helps the viewer get a quick sense of how something has changed over time. 5.14.3 Stacked Area Chart Stacked area charts are area charts similar to a line chart. In an area chart, multiple variables are “stacked” on top of each other, and the area below each line is colored to represent each variable. Stacked area charts are useful to show how both a cumulative total and individual components of that total changed over time. The order in which we stack the variables is crucial because sometimes, there can be a difference in the actual plot versus the human perception. The figure below is a stacked area chart showing time series data: Source: [@aya-time-series] 5.14.4 Bar Charts Bar charts represent data as horizontal or vertical bars. The length of each bar is proportional to the value of the variable at that point in time. A bar chart is the right choice when you wish to look at how the variable moved over time or when you wish to compare the variable with each other. Grouped or stacked bar charts help you combine both these purposes in one chart while keeping your visualization simple and intuitive. The chart plots the value vertically whereas we perceive the value to be at right angles to the general direction of the chart. For instance, in the figure below, a bar graph would be a cleaner alternative. Source: [@aya-time-series] For instance, the grouped bar chart in this interactive visualization of number of deaths by disease type in India not only lets you compare the deaths due to diarrhea, malaria, and acute respiratory disease across time, but also lets you compare the number of deaths by these three diseases in a given year. By switching to the stacked bar chart view, you get an intuitive sense of the proportion of deaths caused by each disease. We can use two different bar charts to represent time series data. 5.14.5 Column Charts for Time Series data This should be the most popular chart type. This chart is good to do a comparison between different values when specific values are important. Still have hard time to choose? There are many resources online which can help you make the decision. For example, Dr. Andre Abela creates a chart selection diagram that is helpful to pick the right chart depending on the data type. The link of website is]** Source: [@aya-time-series] Source: [@aya-time-series] To avoid clutter and confusion, make sure not to use more than 3 variables in a stacked or group bar chart. It is also a good practice to use consistent bold colors and leave appropriate space between two bars in a bar chart. 5.14.6 Gantt Chart Gantt charts are a popular project management tool since they present a concise snapshot of various tasks spread across various phases of the project. You can show additional information such as the correlation between individual tasks, resources used in each task, overlapping resources, etc., by the use of colors and placement of bars in a Gantt chart. It is a horizontal bar chart showing work completed in a certain period of time with respect to the time allocated for that particular task. It is named after the American engineer and management consultant Henry Gantt who extensively used this framework for project management. Assume you’re planning the logistics for a dance concert. There are lots of activities to be completed, some of which will take place simultaneously while some can be done only after another activity has been completed. For instance, the choreographers, soundtrack, and dancers need to be finalized before the choreography can begin. However, the costumes, props, and stage decor can be planned at the same time as the choreography. With careful preparation, Gantt charts can help you plan for complex, long-term projects that are likely to undergo several revisions and have various resource and task dependencies. Gantt charts are a popular project management tool since they present a concise snapshot of various tasks spread across various phases of the project. You can show additional information such as the correlation between individual tasks, resources used in each task, overlapping resources, etc., by the use of colors and placement of bars in a Gantt chart. 5.14.7 Stream Graph Stream graphs are great to represent and compare time series data for multiple variables. Stream graphs are, thus, apt for large data sets. Remember that choice of colors is very important, especially when there are lots of variables. Variables that do not have significantly high values might tend to get drowned out in the visualization if the colors are not chosen well. (Source: [@aya-time-series])is essentially a stacked area graph, but displaced around a central horizontal axis. The stream graph looks like flowing liquid, hence the name. They are great to represent and compare time series data for multiple variables. Stream graphs are, thus, apt for large data sets. Remember that choice of colors is very important, especially when there are lots of variables. Variables that do not have significantly high values might tend to get drowned out in the visualization if the colors are not chosen well. A stream graph showing a randomly chosen listener’s last.fm music-listening habits over time. 5.14.8 Heat Map Heat maps are perfect for a two-tiered time frame – for instance, 7 days of the week spread across 52 weeks in the year, or 24 hours in a day spread across 30 days of the month, and so on. The limitation, though, is that only one variable can be visualized in a heat map. Comparison between two or more variables is very difficult to represent. Source: [@aya-time-series] Geo-spatial visualizations often use heat maps since they quickly help identify “Hot spots” or regions of high concentrations of a given variable. When adapted to temporal visualizations, heat maps can help us explore two levels of time in a 2D array. This heat map visualizes birthdays of babies born in the United States between 1973 and 1999. The vertical axis represents the 31 days in a month while the horizontal axis represents the 12 months in a year. This chart quickly helps us identify that a large number of babies were born in the later half of July, August, and September. Source: [@aya-time-series] 5.14.9 Polar Area Diagram Think beyond the straight line! Sometimes, time series data can be cyclical – a season in a year, time of the day, and so on. Polar area diagrams help represent the cyclical nature time series data cleanly. A polar diagram looks like a traditional pie chart, but the sectors differ from each other not by the size of their angles but by how far they extend out from the center of the circle. Polar area diagrams are useful for representing seasonal or cyclical time series data, such as climate or seasonal crop data. Multiple variables can be neatly stacked in the various sectors of the pie. It is crucial to clarify whether the variable is proportional to the area or radius of the sector. It is a good practice to have the area of the sectors proportional to the value being represented. In that case, the radius should be proportional to the square root of the value of the variable (since the area of a circle is proportional to the square of the radius). This popular polar area diagram created by Florence Nightingale shows causes of mortality among British troops in the Crimean War. Each color in the diagram represents a different cause of death. (Check out the the text legend for more details.) Source: [@aya-time-series] [@TimeSeries] This article explains how time series data visualization can sometimes be deceptive. It first takes an example of two random time series data and plots them on a graph which gives an impression that the two are strongly correlated. But if we do some statistical testing, the two do not show any relationship, this is an example of “correlation does not necessary mean causation”. In another set of examples, the author has taken trending two random time series data and shown how even statistical tests can give a wrong interpretation. The article then explains using visualization how a general trended time series can be different than a more controlled and measured trending time series. 5.15 Word Cloud A Word Cloud or Tag Cloud is a visual representation of text data in the form of tags, which are typically single words whose importance is visualized by way of their size and color. It displays how frequently words appear in a given body of text, by making the size of each word proportional to its frequency. Word clouds can add clarity during text analysis in order to effectively communicate your data results.It is an effective tool for Q researchers, marketers, Non-profits, Human resources ,Educators, Politicians and journalists. Pros of Word Clouds It is easy to understand and make an impact. It can easily be shared. It is visually engaging than a table data. It is fast and reveals the essential. They delight and provide emotional connection. Cons of Word Clouds Emphasis based on length of the words. Words whose letters contain many ascenders and descenders may receive more attention. They’re not very accurate. A lot of data cleaning required before generating the word cloud. Context is lost. [@wordcloud] Ways to generate a word cloud R: The procedure of creating word clouds is very simple in R with text mining package (TM) and the word cloud generator package. The major steps involved are: text mining which involves text cleaning and transformation, building term-document matrix and generating word cloud [@r]. Wordle: Wordle is a toy for generating “word clouds” from text that you provide.It is very popular, free and easy to use. You do need Java though Chrome. In Wordle, you generate word clouds from text you input. Clouds can be tweaked with different color schemes, layouts, and fonts. Images created from this tool can be saved and reused [@wordle]. Other popular tools include ABCya, Tagul, Tag Crowd, CloudArt. 5.15.1 Calendar View [@Calendar_Layout] We have all seen the calendar views in the various data products that we worked on. Please find an open source code that I found, this will help you replicate and create your own calendar: [@CalendarView] Reproducible code for reference: This example demonstrates loading of CSV data, which is then quantized into a diverging color scale. The values are visualized as colored cells per day. Days are arranged into columns by week, then grouped by month and years. &lt;!DOCTYPE html&gt; &lt;body&gt; &lt;script src=&quot;https://d3js.org/d3.v4.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; var width = 960, height = 136, cellSize = 17; var formatPercent = d3.format(&quot;.1%&quot;); var color = d3.scaleQuantize() .domain([-0.05, 0.05]) .range([&quot;#a50026&quot;, &quot;#d73027&quot;, &quot;#f46d43&quot;, &quot;#fdae61&quot;, &quot;#fee08b&quot;, &quot;#ffffbf&quot;, &quot;#d9ef8b&quot;, &quot;#a6d96a&quot;, &quot;#66bd63&quot;, &quot;#1a9850&quot;, &quot;#006837&quot;]); var svg = d3.select(&quot;body&quot;) .selectAll(&quot;svg&quot;) .data(d3.range(1990, 2011)) .enter().append(&quot;svg&quot;) .attr(&quot;width&quot;, width) .attr(&quot;height&quot;, height) .append(&quot;g&quot;) .attr(&quot;transform&quot;, &quot;translate(&quot; + ((width - cellSize * 53) / 2) + &quot;,&quot; + (height - cellSize * 7 - 1) + &quot;)&quot;); svg.append(&quot;text&quot;) .attr(&quot;transform&quot;, &quot;translate(-6,&quot; + cellSize * 3.5 + &quot;)rotate(-90)&quot;) .attr(&quot;font-family&quot;, &quot;sans-serif&quot;) .attr(&quot;font-size&quot;, 10) .attr(&quot;text-anchor&quot;, &quot;middle&quot;) .text(function(d) { return d; }); var rect = svg.append(&quot;g&quot;) .attr(&quot;fill&quot;, &quot;none&quot;) .attr(&quot;stroke&quot;, &quot;#ccc&quot;) .selectAll(&quot;rect&quot;) .data(function(d) { return d3.timeDays(new Date(d, 0, 1), new Date(d + 1, 0, 1)); }) .enter().append(&quot;rect&quot;) .attr(&quot;width&quot;, cellSize) .attr(&quot;height&quot;, cellSize) .attr(&quot;x&quot;, function(d) { return d3.timeWeek.count(d3.timeYear(d), d) * cellSize; }) .attr(&quot;y&quot;, function(d) { return d.getDay() * cellSize; }) .datum(d3.timeFormat(&quot;%Y-%m-%d&quot;)); svg.append(&quot;g&quot;) .attr(&quot;fill&quot;, &quot;none&quot;) .attr(&quot;stroke&quot;, &quot;#000&quot;) .selectAll(&quot;path&quot;) .data(function(d) { return d3.timeMonths(new Date(d, 0, 1), new Date(d + 1, 0, 1)); }) .enter().append(&quot;path&quot;) .attr(&quot;d&quot;, pathMonth); d3.csv(&quot;dji.csv&quot;, function(error, csv) { if (error) throw error; var data = d3.nest() .key(function(d) { return d.Date; }) .rollup(function(d) { return (d[0].Close - d[0].Open) / d[0].Open; }) .object(csv); rect.filter(function(d) { return d in data; }) .attr(&quot;fill&quot;, function(d) { return color(data[d]); }) .append(&quot;title&quot;) .text(function(d) { return d + &quot;: &quot; + formatPercent(data[d]); }); }); function pathMonth(t0) { var t1 = new Date(t0.getFullYear(), t0.getMonth() + 1, 0), d0 = t0.getDay(), w0 = d3.timeWeek.count(d3.timeYear(t0), t0), d1 = t1.getDay(), w1 = d3.timeWeek.count(d3.timeYear(t1), t1); return &quot;M&quot; + (w0 + 1) * cellSize + &quot;,&quot; + d0 * cellSize + &quot;H&quot; + w0 * cellSize + &quot;V&quot; + 7 * cellSize + &quot;H&quot; + w1 * cellSize + &quot;V&quot; + (d1 + 1) * cellSize + &quot;H&quot; + (w1 + 1) * cellSize + &quot;V&quot; + 0 + &quot;H&quot; + (w0 + 1) * cellSize + &quot;Z&quot;; } &lt;/script&gt; 5.16 An example to back some of our theories on ‘how to tell stories using data visualization’ / ‘exploratory data visualization’ [@DataUSA] MIT Media Lab in collaboration with Deloitte has created a new visualization tool, that aggregates US government open source data and mines information to generate trends and stories about cities, jobs, industries etc. Just looking at any of the open data sources would give us an idea about the vastness (breadth and depth) of the available data. It is impressive that they have brought it all together on a single platform in a convenient format. What stands out is the categorization of information on the website which enables the following: Easy browsing of various categories of information available at a single glance An easy search on any topic of interest and get deeper information Logical construction of information using data and visuals under each category Comparative analysis of cities Variety of exploratory visualizations to learn from Most important - Storytelling through data, such as the evolution of the American Worker, how poverty is bad for your health, how men still dominate in the highest paying industries, and opioid addiction damage. We think of a topic, and it’s possible it’s there! The benefits to students, organizations, governments etc. is a better understanding of your consumers, talent pool, jobs, climate, which helps improve our decision-making ability. The best part is that the data is also available for download so we can replicate the visuals, redesign and tell our own stories with this data. There are also other similar websites, that has some good visualizations on census data: [@CensusDataViz] Automatic visualization is a bad idea, generally speaking. Some might argue that automated visualization is a worthwhile pursuit. And I would agree that some parts of visualization certainly should be automatic, such as standard chart types and recurring geometries. Pieces of visualization, such as annotation and axis construction can be automatic. There are plenty of tools to make our lives easier. But full-on automation where insight fountains out from any dataset are farfetched at this point, because this requires automatic analysis. The analysis is context-specific and requires more than boilerplate statistics. The most interesting visualization is context-specific.[@auto_viz] In 2016, Arden Manning believed Workplace Automation making Data Visualization Smarter. According to him, the goal of data visualization tools was to make understanding data easier, but more often than not it doesn’t quite go to plan. We’ve all been there. The software is able to analyze huge amounts of data and incredible speeds, but how can it explain the results of that analysis? Today, the only means of doing this is with graphics. However, data visualization can’t explain data, leaving room for interpretation. The thought behind graphics makes sense – turn data into something easy to understand – but the reality is more complex, and we are left working late writing reports explaining how many trades were canceled and by what desks or why sales fell in August of 2015. Whenever I am stuck doing a repetitive task, I always think ‘why can’t we automate this’? And now, finally, technology has caught up. Narrative generation software can run as a plug-in to your dashboards. Tools like Savvy actually install on your server and allow every dashboard user to get a written summary anytime they want. This software is fully plugged and play, it takes seconds to install, and it’s easy to use. Today, it runs with Microsoft Excel, Qlik Sense 3.0, and is available as an API. In fact, the software even lets you copy and paste the text it generates so that you can use it in emails and reports explaining data. Yet again automation is making our working lives easier by automating repetitive tasks and allowing us to fully leverage existing data reserves.[@work_place] According to Alysson Ferreira, a UI Engineer, he published his idea of Data Visualization tools in 2017. In this new era of information, there’s an increasing need to understand the latest trends quickly and efficiently, which means there’s also a need for meaningful sources of trustworthy information.[@UI_engineer] This is where data visualization comes in. Data visualization is the art of displaying information by combining the beauty of imagery with the conciseness of statistics, which allows us to organize complex data into convenient graphical representations. In simple terms, data visualization is the art of translating complex data into meaningful information.[@future_viz] We can also find the topic of data visualization’s future on Quora. Amalie Sharma thought in future trend of data visualization are better tools, open for all, Increase in Interactivity/Animation and Portable Data. Plug in any data set into a magic box and it spits out a lovely visualization you can show all of your co-workers, friends, and family. That’s the promise of a lot of startups, but it doesn’t quite work that way. The goal of data visualization tools was to make understanding data easier, but more often than not it doesn’t quite go to plan. The problem is that graphics alone don’t fully explain data, and so we are inundated with queries: why did the numbers fall in whatever month? Data visualization can’t explain data, leaving room for interpretation. Although simple visualizations such as standard chart types (bar chart, line chart etc.) are already automated to a certain extend in Microsoft Office tools and other software available in the market, but full on automation where insight fountains out from any data set is far-fetched at this point, because this requires automatic analysis. The automated analysis here means that the tool or algorithm has to understand the context and also select the best visualization. The focus in today’s world has been on open source tools and technologies and these tools although being free for the most part require more effort to seamlessly integrate to the current visualization workflow. As mentioned in one of the articles about D3.js: D3.js is one of the first data visualization tools that comes to mind when talking about free, open-source alternatives. It’s a JavaScript-based library for creating web visualization and displays the results on the web page. However, with great power comes great responsibility. D3.js is extremely powerful and flexible, because it allows you to build amazing things with it, but as a trade-off, it’s not the easiest tool to use, so you might need to spend some time going through the helpful library documentation. At the end, it’s not only about the tool its more about what you are trying to do; what your professor, client, business or whatever needs. 5.17 Reusable Data Visualization Code in R [@viz_R] This site includes full sets of R code to generate specific types of graphs in ggplot2. Plots in ggplot2 are created by using “layering”. There is a base plot and then other aspects of the plot such as aesthetics, titles ,and labels are added to using extra code. For those who favor Python for data visualization, this layering approach in R is actually similar to the syntax in Python’s matplotlib library, in which set_style and specifying the axes labels and title are done separately from the code that generates the plot itself. To provide an example the “layering” mentioned above, here is a generic snippet of code for creating a scatterplot with ggplot2 and the mtcars data set in R base, using this website’s code as a template: library(ggplot2) theme_set(theme_bw()) #set background theme plot1 &lt;- ggplot(mtcars, aes(x = hp, y = mpg)) + geom_point(aes(col=factor(vs), size = 2)) + geom_smooth(method = &quot;loess&quot;, se = F) + xlim(c(0, 400)) + ylim(c(0, 40)) + labs(title = &quot;Horsepower vs. MPG&quot;, y = &quot;Miles Per Gallon&quot;, x = &quot;Horsepower&quot;) plot(plot1) #we have to actually call the plot() function on the plot object we created The ggplot2 package allows R users to go beyond the simple and often rudimentary-looking graphs in R and offers many ways of customizing data visualizations. In a way, the layering technique also makes it easier to remember the code to generate these plots, since geom functions for the layers remain constant and they are all included in a single line of code. 5.18 Data Mining and Data Visualization According to a paper in 2018, we can tell the difference of data mining from data visualizations. Here is a chart that helps us understand this better. [@data_mining] In Data Mining, there are different processes involved in carrying out the data mining process such as data extraction, data management, data transformations, data pre-processing, etc. In Data Visualization, the primary goal is to convey the information efficiently and clearly without any deviations or complexities in the form of statistical graphs, information graphs, and plots. The author has also listed top 7 comparisons between data mining and data visualization, and 12 key differences between data mining and data visualization. The article provides a very clear understanding of data mining and data visualization techniques. BASIS FOR COMPARISON Data Mining Data Visualization Definition Searches and produces a suitable result from large data chunks Gives a simple overview of complex data Preference This is has different applications and preferred for web search engines Preferred for data forecasting and predictions Area Comes under data science Comes under the area of data science Platform Operated with web software systems or applications Supports and works better in complex data analyses and applications Generality New technology but underdeveloped More useful in real time data forecasting Algorithm Many algorithms exist in using data mining No need of using any algorithms Integration Runs on any web-enabled platform or with any applications Irrespective of hardware or software, it provides visual information 5.19 Creating a Diverging Bar Chart A diverging bar chart shows and compares positive and negative values for a particular variable. One popular use case is survey analysis, in which multiple options are given as the categories, so each option has one bar, and there are two opposite ends of the spectrum for the values. These two sides are usually ‘positive’ vs ‘negative’, but they can also be categorical values such as ‘agree’ or ‘disagree’. Below is the R code template one can use to create a diverging bar chart. Reference for the code: [@viz_R] library(ggplot2) theme_set(theme_bw()) # Data Prep data(&quot;mtcars&quot;) # load data mtcars$`car name` &lt;- rownames(mtcars) # create new column for car names mtcars$mpg_z &lt;- round((mtcars$mpg - mean(mtcars$mpg))/sd(mtcars$mpg), 2) # compute normalized mpg mtcars$mpg_type &lt;- ifelse(mtcars$mpg_z &lt; 0, &quot;below&quot;, &quot;above&quot;) # above / below avg flag mtcars &lt;- mtcars[order(mtcars$mpg_z), ] # sort mtcars$`car name` &lt;- factor(mtcars$`car name`, levels = mtcars$`car name`) # convert to factor to retain sorted order in plot. # Diverging Barcharts ggplot(mtcars, aes(x=`car name`, y=mpg_z, label=mpg_z)) + geom_bar(stat=&#39;identity&#39;, aes(fill=mpg_type), width=.5) + scale_fill_manual(name=&quot;Mileage&quot;, labels = c(&quot;Above Average&quot;, &quot;Below Average&quot;), values = c(&quot;above&quot;=&quot;#00ba38&quot;, &quot;below&quot;=&quot;#f8766d&quot;)) + labs(subtitle=&quot;Normalised mileage from &#39;mtcars&#39;&quot;, title= &quot;Diverging Bars&quot;) + coord_flip() Diverging bar charts are also convenient to create in Tableau. Below is an example using survey response data. 5.20 10 Useful Python Data Visualization Libraries [@PythonDataVizLibraries] [Click here for sample charts for each]https://blog.modeanalytics.com/python-data-visualization-libraries/ 1. Matplotlib Because matplotlib was the first Python data visualization library, many other libraries are built on top of it or designed to work in tandem with it during analysis. While matplotlib is good for getting a sense of the data, it’s not very useful for creating publication-quality charts quickly and easily. 2. Seaborn Seaborn harnesses the power of matplotlib to create beautiful charts in a few lines of code. The key difference is Seaborn’s default styles and color palettes, which are designed to be more aesthetically pleasing and modern. Since Seaborn is built on top of matplotlib, you’ll need to know matplotlib to tweak Seaborn’s defaults. 3. Ggplot ggplot is based on ggplot2, an R plotting system, and concepts from The Grammar of Graphics. ggplot operates differently than matplotlib: it lets you layer components to create a complete plot. For instance, you can start with axes, then add points, then a line, a trendline, etc. Although The Grammar of Graphics has been praised as an “intuitive” method for plotting, seasoned matplotlib users might need time to adjust to this new mindset. 4. Bokeh Like ggplot, Bokeh is based on The Grammar of Graphics, but unlike ggplot, it’s native to Python, not ported over from R. Its strength lies in the ability to create interactive, web-ready plots, which can be easily output as JSON objects, HTML documents, or interactive web applications. Bokeh also supports streaming and real-time data. 5. Pygal Like Bokeh and Plotly, pygal offers interactive plots that can be embedded in the web browser. Its prime differentiator is the ability to output charts as SVGs. As long as you’re working with smaller datasets, SVGs will do you just fine. But if you’re making charts with hundreds of thousands of data points, they’ll have trouble rendering and become sluggish. 6. Plotly You might know Plotly as an online platform for data visualization, but did you also know you can access its capabilities from a Python notebook? Like Bokeh, Plotly’s forte is making interactive plots, but it offers some charts you won’t find in most libraries, like contour plots, dendograms, and 3D charts. 7. Geoplotlib geoplotlib is a toolbox for creating maps and plotting geographical data. You can use it to create a variety of map-types, like choropleths, heatmaps, and dot density maps. You must have Pyglet (an object-oriented programming interface) installed to use geoplotlib. Nonetheless, since most Python data visualization libraries don’t offer maps, it’s nice to have a library dedicated solely to them. 8. Gleam Gleam is inspired by R’s Shiny package. It allows you to turn analyses into interactive web apps using only Python scripts, so you don’t have to know any other languages like HTML, CSS, or JavaScript. Gleam works with any Python data visualization library. Once you’ve created a plot, you can build fields on top of it so users can filter and sort data. 9. Missingno Dealing with missing data is a pain. missingno allows you to quickly gauge the completeness of a dataset with a visual summary, instead of trudging through a table. You can filter and sort data based on completion or spot correlations with a heatmap or a dendrogram. 10. Leather Leather’s creator, Christopher Groskopf, puts it best: “Leather is the Python charting library for those who need charts now and don’t care if they’re perfect.” It’s designed to work with all data types and produces charts as SVGs, so you can scale them without losing image quality. Since this library is relatively new, some of the documentation is still in progress. The charts you can make are pretty basic-but that’s the intention. 5.21 Top 5 best practices for creating effective dashboards and the 7 mistakes you don’t want to make [@dashboard_practices]: What is a dashboard? Stephen Few wrote: “A dashboard is a visual display of the most important information needed to achieve one or more objectives; consolidated and arranged on a single screen so the information can be monitored at a glance.” 5 best practices &amp; avoiding 7 critical mistakes to create effective dashboards: 1. Choose metrics based on why they matter: Metrics that are chosen should be important and relevant to the current task. But, that doesn’t mean each metric ought to be incorporated. You ought to be highly selective in determining which metrics earn a spot on your dashboard. Organization’s core objectives, availability of data that can shed light on the objectives, effectiveness of metric to explain contribution to the objectives etc. are some of the aspects to consider while choosing metrics. In short, every metric on your dashboard should connect to organization objectives. Keep it visual: Dashboards are meant to be fast and easy to read. A well-designed, highly visual dashboard will be more widely adopted by audiences. Since metrics are also chosen in line with corporate objective, it will help in speeding peoples understanding and will also help see the the translation of individual department objectives into broader organizations objective. Things to consider when designing a dashboard are use of colors, shapes, lines, thicknesses, degrees of shading etc.. Things to avoid are cute widgets, 3D graphic treatments, and graph types not commonly seen. Make it interactive: When different information are on the same page, different viewers will have different questions as per their area of interest. Dashboard should allow viewers to customize to get the information they need. Interactive, highly visual dashboards should enable audience to perform basic analytical tasks, such as filtering the views, drilling down, and examining underlying data etc. Viewers should be able to get the big picture from the dashboard and then be able to drill down into a view that tells them the information they need to get their jobs done. 4. Keep it current or don’t bother: Selected metrics should reflect current business challenges. You don’t need up-to-the-minute data.It can be a quarter, week , hour as relevant to the right timeline of the organization.Ability to change and update the metrics represented in the dashboard is also one important aspect 5. Make it simple to access and use: Making dashboards easily accessible is very critical. Ideal is Web distribution- especially if dashboards can constantly pull current data and can adhere to IT protocols and security standards. Another alternative is like posting files on websites, Wiki’s or blogs 7mistakes to avoid : Starting off with too much complexity: It’s very tempting to provide highly detailed, real-time dashboards. But instead of spending lot of time working through first iteration, its better to work through several short cycles of prototype, test and adjust. Using metrics no one understands: Dashboard should use metrics or concepts that broader audience understands. Cluttering the dashboard with unimportant graphics and unintelligible widgets: Dashboard should be simple in its visual appeal. It should not be too flashy or over-designed so that it doesn’t get in the way with primary dashboard’s objective which is rapidly and easily informing the audience. Waiting for complex technology and big BI deployment projects: Implementations of some of traditional Business Intelligence tools often take a much longer time than originally anticipated, waiting for a traditional BI project to materialize may mean delays. Underestimating the time or resources to create and maintain the dashboard: Considering that a dashboard is typically one page or one screen, we should not assume that it would be very quick and simple to create and maintain. Failing to match metrics to the goal: Instead of showcasing the activities of a single department, a dashboard should connect department’s efforts to organization’s actual goals and objectives. Using ineffective, poorly designed graphs and charts: While designing graphs and charts for dashboard extreme care should be taken. Principles for designing good data visualizations; should be followed to avoid dashboard with poorly designed graphs and charts. "],
["ethics.html", "Chapter 6 Ethics 6.1 Ethical Theory and Practice from Journalism and Engineering 6.2 Importance of Ethics in Visualization 6.3 Implications of (Good/Bad) Data Visualization 6.4 General Guidelines for Ethical Visuals 6.5 Definitions of Data Deception and Graphic Integrity 6.6 Visual Lies 6.7 Data Visualization: A Tool for Social Change 6.8 Misinformation can be beautiful too", " Chapter 6 Ethics 6.1 Ethical Theory and Practice from Journalism and Engineering [@poli_social_science] Over the years, researchers and lawyers have come up with rules and practices for proper data collection and utilization, with particular attention on human subject research. Consent of the subjects to use their data, evaluation of any risk with use or collection of data, and protecting the anonymity of data are some of the rules that must be considered for ethical research methods. Under U.S. law, research institutions receiving federal funding must consider ethical aspects of their research. These rules continue to evolve. Data presented in charts can persuade viewers on the subject matter, even if viewers do not support the idea presented. This means that visualizations can also be used to deceive and there are many techniques for this leading viewer to wrong conclusions. Misleading, incomprehensible, or incredible data visualization can jeopardize people’s trust, goodwill, or faith in research and advocacy on vital human rights issues. Its ethical responsibility to create visualizations to give the correct and faithful representation of data and subjects. The fundamental objective of data visualization is to provide an efficient graphical display for summarizing and reasoning about quantitative information. Moreover, during the last decades, political science has accumulated a large corpus of various kinds of data, which gradually become a more scientific and requires using quantitative information in the analysis and reasoning. Under U.S. law, research institutions receiving federal funding must consider ethical aspects of their research. Over the years, researchers and lawyers have established rules and practices for proper data collection and utilization, with particular attention to human subject research. Some of the most important of these rules for ethical research methods include consent of the subjects to use their data, evaluation of any risk with use or collection of data, and protecting the anonymity of data. However, these rules continue to evolve. Data presented in charts can persuade viewers on the subject matter, even if viewers do not support the idea presented. This means that visualizations can also be used to present misleading arguments and deceive viewers. Misleading, incomprehensible, or incredible data visualization can jeopardize people’s trust, goodwill, or faith in research and advocacy on vital human rights issues. There is no shortage of techniques for deception through data visualization, and researchers have an ethical responsibility to give a correct and faithful representation of data and subjects. The primary objective of data visualization is to provide an efficient graphical display for summarizing and posing a claim about quantitative information. However, the value of data visualization is not limited to business and the hard sciences. During the last decades, political science has accumulated a large corpus of various kinds of data and has gradually become a quantitative and scientific field that requires the use of quantitative information in analysis and reasoning. Under U.S. law, research institutions receiving federal funding must consider ethical aspects of their research. Over the years, researchers and lawyers have come up with rules and practices for proper data collection and utilization, with particular attention on human subject research. Consent of the subjects to use their data, evaluation of any risk with use or collection of data, and protecting the anonymity of data are some of the rules that must be considered for ethical research methods. Under U.S. law, research institutions receiving federal funding must consider ethical aspects of their research. These rules continue to evolve. The basic objective of data visualization is to provide an efficient graphical display for summarizing and reasoning about quantitative information. However, the value of data visualization is not limited to business and the hard sciences. During the last decades, political science has accumulated a large corpus of various kinds of data, which is gradually becoming more scientific and requires using quantitative information in analysis and reasoning. Obtaining the consent of the subjects to use their data, evaluating any risk with use or collection of data or protecting the anonymity of data are some of the rules that must be considered for ethical research methods. Data presented in charts can persuade viewers on the subject matter, even if viewers do not support the idea presented. This means that visualizations can also be used to deceive and there are many techniques for this, leading viewers to wrong conclusions. Research has found that even if viewers do not support an idea, data presented in charts can persuade viewers on the subject matter. It means that visualization can also be used for deception and many techniques can produce a dangerous visualization. Techniques such as truncated axis (where the y-axis does not start at zero) or using the area to represent a quantity (for instance comparing the size of two adjacent circles) were found to lead to wrong conclusions. Misleading, incomprehensible, or incredible data visualization can jeopardize people’s trust, goodwill, or faith in research and advocacy on vital human rights issues. Its ethical responsibility to create visualizations to give a correct and faithful representation of data and subjects. Data visualization plays several essential roles in it: There are lots of techniques that can produce a dangerous visualization. Techniques such as truncated axis (where the y-axis does not start at zero) or using the area to represent a quantity (for instance comparing the size of two adjacent circles) were found to lead to wrong conclusions. Misleading, incomprehensible, or incredible data visualization can jeopardize people’s trust, goodwill, or faith in research and advocacy on vital human rights issues. Its ethical responsibility to create visualizations to give a correct and faithful representation of data and subjects. Data visualization plays several important roles in it: It helps create informative illustrations of the data, recapitulating a large amount of quantitative information on a diagram; It helps formulate new or supports existing hypotheses from quantitative data; It guides a statistical analysis of data and checks its validity. Some useful visualization methods are: Statistical graphics and infographics Geographical information systems (GIS) Graph visualization or network maps Data cartography 6.2 Importance of Ethics in Visualization [@ethical_infographics] Alberto Cairo addresses the ethical ‘why’ of data visualization in this article, while still grounding the discussion in a straightforward analysis of what to do and what not to do. He emphasizes that the effectiveness of the communicative display is as important as the information itself. This makes intuitive sense because useful information is rendered utterly useless if no one can understand it. Cairo sees data visualization as a harmonization of journalism and engineering. From these two disciplines, he takes the journalist ethos of truth-telling and honesty and combines this with an engineering focus on efficacy and efficiency. The result is a data visualization that contains accurate and relevant information which is clearly and concisely conveyed. Cairo describes himself as a “rule utilitarian” and uses this to explain why it is ethical or, in his words, “morally right,” to create graphics in this way. Here, it very useful to review his post on the blog introducing the article. Essentially, the goal is to create the most good while doing the least harm. As such, conveying truthful and honest relevant information increases a person’s understanding. Increased understanding and knowledge positively correlates with personal well-being. The information presented must be accurate and relevant. Cairo briefly addresses guidelines for this which are applicable in all information gathering fields: beware of selection bias when choosing preexisting datasets, validate the data, and include important context. False or irrelevant information doesn’t improve anyone’s decision-making capacity, so it cannot enhance well-being. Even if the information is both accurate and relevant, moral engineering pitfalls may remain. To avoid the unethical trap of inscrutable (or misleading) graphics, Cairo exhorts us to take an evidence-based approach when possible. The purpose of the graphic dictates the form it takes; aesthetic preferences should never override clarity. Again, since the ethical purpose is to improve well-being through understanding, a graphic which is confusing or misleading is unethical, regardless of intent, since it actually creates misunderstanding for the audience. While it can be a bit jarring to think of a poorly designed graphics as “morally wrong,” it is essential to think of the unintended consequences of visuals which have a powerful impact on their viewers. Cairo sees data visualization as harmonization of journalism and engineering. From these two disciplines, he takes the journalist ethos of truth-telling and combines this with an engineering focus on efficacy and efficiency. The result is a data visualization that contains accurate and relevant information which is apparently and concisely conveyed. Cairo describes himself as a “rule utilitarian” and uses this to explain why it is “morally right” to create graphics in this way. Here, it is useful to review his blog post introducing the article. Mostly, the goal is to create the most good while doing the least harm. As such, conveying honest and relevant information increases a person’s understanding. Increased understanding and knowledge positively correlates with personal well-being. The information presented must be accurate and relevant. Cairo briefly addresses guidelines that are applicable in all information gathering fields: beware of selection bias when choosing preexisting datasets, validate the data, and include essential context. False or irrelevant information does not improve anyone’s decision-making capacity, so it cannot enhance well-being. Even if the information is both accurate and relevant, moral pitfalls may remain. To avoid the unethical trap of inscrutable or misleading graphics, Cairo exhorts us to take an evidence-based approach when possible. The purpose of the graphic dictates the form it takes; aesthetic preferences should never override clarity. Again, since the moral purpose is to improve well-being through understanding, a graphic which is confusing or misleading is unethical, regardless of intent, since it creates misunderstanding for the audience. While it can be a bit jarring to think of a poorly designed graphics as “morally wrong,” it is essential to think of the unintended consequences of visuals which have a powerful impact on their viewers. The fundamental objective of data visualization is to provide an efficient graphical display for summarizing and reasoning about quantitative information. Moreover, during the last decades, political science has accumulated a large corpus of various kinds of data, which makes it gradually become a more quantitative scientific field and requires using quantitative information in the analysis and reasoning. Alberto Cairo addresses the ethical ‘why’ of data visualization in this article, while still grounding the discussion in a straightforward analysis of what to do and what not to do. He emphasizes that the effectiveness of the communicative display is as important as the information itself. This makes intuitive sense because useful information is rendered utterly useless if no one can understand it. Cairo sees data visualization as a harmonization of journalism and engineering. From these two disciplines, he takes the journalist ethos of truth-telling and honesty and combines this with an engineering focus on efficacy and efficiency. The result is a data visualization that contains accurate and relevant information which is clearly and concisely conveyed. Cairo describes himself as a “rule utilitarian” and uses this to explain why it is ethical or, in his words, “morally right,” to create graphics in this way. Here, it very useful to review his post on the blog introducing the article. Essentially, the goal is to create the most good while doing the least harm. As such, conveying truthful and honest relevant information increases a person’s understanding. Increased understanding and knowledge positively correlates with personal well-being. The information presented must be accurate and relevant. Cairo briefly addresses guidelines for this which are applicable in all information gathering fields: beware of selection bias when choosing preexisting datasets, validate the data, and include important context. False or irrelevant information doesn’t improve anyone’s decision-making capacity, so it cannot enhance well-being. Even if the information is both accurate and relevant, moral engineering pitfalls may remain. To avoid the unethical trap of inscrutable (or misleading) graphics, Cairo exhorts us to take an evidenced-based approach when possible. The purpose of the graphic dictates the form it takes; aesthetic preferences should never override clarity. Again, since the ethical purpose is to improve well-being through understanding, a graphic which is confusing or misleading is unethical, regardless of intent, since it actually creates misunderstanding for the audience. While it can be a bit jarring to think of a poorly designed graphic as “morally wrong”, it is important to think of the unintended consequences of visuals which have a powerful impact on their viewers. Data visualization plays several critical roles in it: helps create informative illustrations of the data, recapitulating a significant amount of quantitative information on a diagram. helps formulate new or supporting existing hypotheses from quantitative data. guides a statistical analysis of data and checks its validity. 6.3 Implications of (Good/Bad) Data Visualization Raw data is often meaningless, or their meaning is not easily understood. When people face a broad set of measurements, they are unable or unwilling to spend the time required to process it. Technological advances of the Digital Age contribute to an ever-growing pool of “big data” and our ability to collect this type of information becomes more comfortable and more accessible. Thus filtering, visualization, and interpretation of data become increasingly important. We should understand how best to derive meaning from data, but first, we should understand why its presentation in graphical format is so compelling. While the ideal purpose of data visualization is to facilitate understanding of data, visualization can also be used to mislead. Some of the primary methods of doing so are omitting baselines, axis manipulation, omitting data, and ignoring graphing convention. Omitting baselines is used to imply a more significant difference between two categories, such as in poll results comparing political parties. Axis manipulation by increasing the highest value on the y-axis affects the visibility of a slope, making data with an otherwise visible trend appear flat. Omitting selected data points or narrowing the window of a graph is used to hide an overall trend, such as a graph of stock only showing a current trend and hiding previous bubbles. Graphs can also be designed to subvert convention so that at first glance the graph is conveying the opposite message, for example, by using the reader’s associations of colors and temperature to create a graph where hot is blue and cold is red. Raw data is often meaningless or their meaning is not easily understood. When people face a large set of measurements, they are unable or unwilling to spend the time required to process it. Technological advances of the Digital Age contribute to an ever-growing pool of “big data” and our ability to collect this type of information becomes easier. Thus filtering, visualization, and interpretation of data becomes increasingly important. We should understand how to best derive meaning from data, but first we should understand why its presentation in graphical format is so powerful. While the ideal purpose of data visualization is to facilitate understanding of data, visualization can also be used to mislead. Some of the main methods of doing so are omitting baselines, axis manipulation, omitting data, and ignoring graphing convention. Omitting baselines is used to imply a greater difference between two categories, such as in poll results comparing political parties. Axis manipulation by increasing the highest value on the y-axis affects the visibility of a slope, making data with an otherwise visible trend appear flat. Omitting selected data points or narrowing the window of a graph is used to hide an overall trend, such as a graph of a stock only showing a current trend and hiding previous bubbles. Graphs can also be designed to subvert convention so that at first glance the graph is conveying the opposite message, for example, by using the reader’s associations of colors and temperature to create a graph where hot is blue and cold is red. Principle Description 1. Easy Recall People can process images quicker than words. When data is transformed into images, the readability and cognition of the content greatly improves. While people can only remember just 10% of what they hear and 20% of what they read, retention jumps up to 80% for visual information with interaction. 2. Providing Window for Perspective With infographics, you can pack a lot of information into a small space. Colors, shape, movement, the contrast in scale and weight, and even sound can be used to denote different aspects of the data allowing for multi-layered understanding [@image_good]. 3. Enable Qualitative Analysis Color, shape, sounds, and size can make evident relationships within data very intuitive. When data points are represented as images or components of an entire scene, readers are able to see the big picture and understand how the information fits within a larger context. 4. Increase in User Participation Interactive infographics can substantially increase the amount of time someone will spend with the content. Because of their impact, infographics are widely used nowadays. A quick Google will produce a huge array of great examples — as well as poor ones. Because while people recognize the value of information graphic design, and a number of tools are available today that make the creation of them possible for the layman, it doesn’t mean that they’re all successful or even necessary. 6.4 General Guidelines for Ethical Visuals [@ethics_code] Data visualization is an up-and-coming field that currently does not have many established regulations. This makes it easy to manipulate readers without technically reporting false information. However, certain standards should be followed in order to generate meaningful and accurate visuals. The process can be broken down into three steps, each with its own set of guiding rules. 6.4.1 Data Collection The first step in any project is gathering the data. This is relatively simple and does not offer much of an opportunity to introduce confusion. The one thing to remember is to always get data from a reliable source. The data provides the foundation for the entire project and must, therefore, be trustworthy and verifiable. 6.4.2 Data Analysis This is the stage where the discoveries are made and it provides the first opportunity to manipulate the story for good or bad. There is usually a lot of data cleaning to do before creating a visual representation, but all manipulations should make sense. The code should be shared so anyone can follow the entire process. It is also important to explicitly state any assumptions taken, though these should be kept to a minimum. Here, it is important to look at what the source data actually shows. It is the ethical responsibility of presenters for careful analysis of the data and finds true stories from them. As the amount of data grows, it becomes harder to catch up with it. Therefore, data strategy becomes the necessary part of the success in applying data to the business. So, how does data visualization become an important tool in your strategic kit? First, it helps you cleanse your data. Second, it allows you to identify and extract meaningful information from it. Finally, data visualization tools enable continuous real-time monitoring of how your strategy and now data-driven decisions influence performance and business outcomes. In other words, these tools visualize not only the data, but also the results, and help correct and optimize strategy on the go. 6.4.3 Design Once a story is found, it must be presented in an honest way. This is where deceptive techniques could be tempting to make a stronger argument. An experienced individual will know how to spot these deceptions and disregard any findings. This ultimately hurts the credibility of the author and anyone else involved in the publication. Visualization should not be used to intentionally hide or confuse the truth. It should not seek to mislead the uninformed. Visualization has great power, and as they say, with great power comes great responsibility. 6.5 Definitions of Data Deception and Graphic Integrity Data visualization is a powerful communication tool to support arguments with numbers in a way that is accessible and engaging. It is becoming more and more popular to communicate and support arguments nowadays. More people than ever before are making their own charts and infographics, which is presenting a unique problem. Despite the availability of some great charting resources and resources online to create and design amazing data products, we are witnessing an influx of poorly-designed, misleading or downright deceptive data visualizations [@decept_study],[@rose_tint]. So what does data deception mean? Data deception, defined by School of Law at the New York University, is “a graphical depiction of information, designed with or without an intent to deceive, that may create a belief about the message and/or its components, which varies from the actual message.” Deceptive, misleading, or distorted graphs are those that intentionally or unintentionally skew the data, and result in a representation of incorrect conclusions. Edward Tufte already introduced the concept of graphical integrity in his book and presented six principles of graphic integrity. Here are the principles of the book: The representation of numbers, as physically measured on the surface of the graphic itself, should be directly proportional to the numerical quantities measured. Clear, detailed, and thorough labeling should be used to defeat graphical distortion and ambiguity. Write out explanations of the data on the graphic itself. Label important events in the data. In time-series displays of money, deﬂated and standardized units of monetary measurement are nearly always better than nominal units. The number of information-carrying (variable) dimensions depicted should not exceed the number of dimensions in the data. Show data variation, not design variation. Graphics must not quote data out of context. There are some ways in which distorted graphs can be created [@evil_axes],[@mislead_graph_ex]: Tool Description Improper scaling of y-axis This is one of the classic misleading graphs. Instead of scale starting from zero or a baseline, the y-axis is scaled conveniently to highlight the differences among bins. Improper labeling of graphs Lack of labels makes the graph hard to interpret for the reader and leads to wrong conclusions. Paired graphs on different scale It is not a fair comparison if two elements are plotted side-by-side, on a different scale and compared. This makes one graph look better than the other, even when it is not. Dual axis with different scales If we are plotting two elements on the same graph with different scales, it is assumed that both axes are on the same scale even if the axes are properly labeled. Incomplete data Short-term graphs are made to manipulate the trend, which will not be seen otherwise. Time-series data are cut intentionally to show a trend within a particular period to create a more favorable visual impression. 6.6 Visual Lies [@visual-lies] This focuses on a few methods that data visualizers utilize to mislead users about research findings. For each method, the author has highlighted the signifiers that are manipulated to promote an unrealistic understanding of the visualized data. The author has concentrated on examples of three areas to create deceptive data visualization: size, segmentation, and graph type. 6.6.1 Size Size signifies quantity, volume or degree of variables within a data. In the first figure, the y-axis from the graph to the right is cut when transcribed onto the graph on the left. Here, both the graphs show the same data but the one on the left represents the data in a misleading fashion because of the way the axis is cut, and the result is that interest rates have increased drastically from 2008 to 2012 – a misinterpretation that is avoided in the graph on the right.[@misleading_data] 6.6.2 Quantity Quantity measures size. When depicting points on a scatter plot, the author suggests that it is helpful to manipulate the size of the points to represent differing values of a variable that is not represented on the x and y axes. The following graph shows quantity as two completely different measures. One chart uses quantity as area and other uses it as radius. The result is that the differences in quantity between points on such a scatter plot would appear more dramatic than they should.[@study_asks] 6.6.3 Segmentation Figure shows an example of segmentation with a deceptive instance of binning given in the legend on the left. Segmentation can be used to show category, parts, domains or ranges within a chart. The author states that correct use of segmentation can be a powerful tool to enhance understanding, but can be deceptive if used incorrectly. This example shows how binning can be misleading; in the left figure, binning is not done appropriately, and it is therefore difficult to come up with actual values of the data. Figure 3: 6.6.4 Graph Two graphs that are often misrepresented are pie-charts and maps. In the following figure, the author explains that pie-charts cannot be compared accurately to one another. When striving for an accurate portrayal of values, they should be avoided. The author further states that it would be difficult to understand the pie-charts had the numbers not been given. Alberto Cairo addresses into the ethical ‘why’ of data visualization in this article, while still grounding the discussion in a straightforward analysis of what to do and what not to do. He emphasizes that the effectiveness of the communicative display is as important as the information itself. This makes intuitive sense because useful information is rendered utterly useless if no one can understand it. The author also asserts that when showing spatial data analysis, always show population density when visualizing values that are person-dependent. On a heat map where color signifies quantity, the author suggests that a user will be drawn to the colors that a legend indicates as most extreme. In following figure, areas that are darkest are simply the most population-dense regions of the United States. Without accounting for population density, the newly created map may look the same as hundreds of maps bearing a striking resemblance to the figure, which are falsely considered informative and are regularly shared across social media sites. The above pointers are helpful when analyzing a deceptive version of a data product. However, data visualizers need to carefully draw the line between creating misleading graphs that tell a different story and developing deceptive versions that intend to exaggerate. This should be applied in our projects and can also be used to enhance our understanding of data visualization products. Misleading graphs are sometimes deliberately misleading and sometimes, it’s just a case of people not understanding the data behind the graph they create [@andale_2014]. But some real life misleading graphs go above and beyond the classic types. Some are intended to mislead, others are intended to shock. The “classic” types of misleading graphs include cases such as: 6.6.5 The Missing Baseline For example, the vertical scale is too big or too small, skips numbers, or does not start at zero. For example, in the graph below, you might be thinking that the graph on the right shows that The Times makes double the sales of The Daily Telegraph. However, a closer look at the scale reveals that although The Times does make more sales, it is only beating the competition by about 10%. 6.6.6 The graph is not labeled properly A graph may have the correct figures but still mislead its audience. This one used a BIG HEADLINE that suggests to its audience that 5.3% of children get spinal cord injuries, which is a pretty scary statistic for parents. But the real figure is about .0000003% (based on 2000 injuries per year out of a population of around 74,000,000). And for the figure 1 used in this article, “Misleading Graphs: Displaying a Change in One Variable Using Area or Volume” [@scaling_issues], the label for the smaller triangle in this graph says $26.4 while the label for the larger triangle says $114.6. $114.6 is 4.34 times $26.4. It certainly looks to me as if more than 4.34 smaller triangles will fit in the larger triangle. It is the altitudes of the triangles that are proportional to the numbers in the labels. 6.6.7 Data is left out Including only a part of the data is also an easy opportunity to mislead. The following graph uses temperatures of only the first half of the year to prove it was rising dramatically. For more examples and inspirations on misleading or deceptive graphs refer the following articles: Bar charts without zero &amp; evenly spaced tick marks for uneven intervals: [@whats_wrong] Graphs not drawn to scale:[@scaling_issues] 6.6.8 Treating correlation as causation Even if the labels and data in your graph are correct, the conclusion is not necessarily logically correct. A correlation between X and Y does not automatically indicate that the change in one variable is caused by the change in the values of the other one, i.e. correlation does not imply causation. Viewers should bear in mind that such visuals only present the correlation between ice cream sold and murders, not than causation. Figure 6.1: A strange correlation between ice cream sales and murders (Source: [@harlin-coorelation]) Another trick for creating misleading graphs is an axis change: Changing the y-axis maximum affects how the information in the graph is perceived. A higher maximum will make the graph appear less volatile or steep than a lower maximum. The axis can also be altered to deceive by changing the ratio of a graph’s dimensions, as demonstrated in the below graphs. While not technically wrong, improper extraction, tactic omitting data or including only a certain chunck of data is certainly misleading. This is more common in graphs that have time as one of their axes. Visualizations should be simple and easy to remember , but at the same time they should contain the essence of responsible visualization. To make final results pure, ethical procedures need to be practiced throughout all the steps of visualization. In the data visualization terms, we call it truncated graph. A truncated graph (also known as a torn graph) has a y-axis that does not start at 0. These graphs can create the impression of important change where there is relatively little change.Truncated graphs are useful in illustrating small differences.[16] Graphs may also be truncated to save space. Commercial software such as MS Excel tend to truncate graphs by default if the values are all within a narrow range. Truncating graphs makes a small difference look like a huge one, thereby changing the readers’ judgement A example of using good data in a misleading graph to fool readers comes from Fox News. [@DataMiningVsViz] 6.6.9 Ethical Challenges in Data Visualization Matt Stempeck’s article recaps a brainstorming session concerning data visualization ethics, and provides a fairly comprehensive list of considerations for data visualizers to use as a guide to evaluate how ethical their data products actually are. From replicability of a data visual, to persuasiveness and ambiguity in the data, this article challenges data visualizers to assess how to ethically present data. The discussion on perspective is an interesting one; it asks how data visualizers might show different perspectives on the same data. Clearly from the “deceptive versions” we have created for Vox’s gun violence article’s visualizations, the same data can be used to show vastly different perspectives, or make extremely contrasting claims. This may counteract common opinion of data, since most people perhaps believe there is an inherent truth to the data, but the data visualizer is in control of what the audience sees; the person creating the visualization cultivates a perspective to argue the claim. The data is at the heart of this argument, but how the data visualizer presents it to the audience may or may not include the whole story or the most truthful story. Furthermore, while this challenge to show different perspectives proposed by the article clearly should be undertaken by data visualizers for the ethical good; when the goal of a data visualizer is to persuade his/her audience to accept the visualizer’s perspective, being fair and thorough in considering the other side of the argument may contradict the data visualizer’s objective. Of course, the challenge posed by the tug-of-war between ethics and utility remains central in many sciences, including the data sciences, and it makes the discussion of finding a balance between the two all the more important. [@dataviz_for_good] 6.7 Data Visualization: A Tool for Social Change [@Socialchange] When we talk about social change, one field where visualization can impact in meaningful ways is in understanding and generating discussions around cities. With the development of a city, various issues like new demographic changes, economic, environmental and social problems also grow. Visualization can play a important role in creating an understanding of how the cities and societies work ,debating the problems that cities face and engaging citizens to create their dream cities. Recently, as part of Habitat III side event , LlactaLAB - Sustainable Cities Research Group, presented a Project called Live Infographics. It was an interactive methodology that put citizens and experts opinions about the New Urban Agenda on one platform to help generate a ‘horizontal governance’. The different opinions were materialized with a dynamic map to visualize the generated data. The primary objective of the project is to generate citizen-led data collection and to enable governments to build a better understanding of public sentiment, engaging people in the process. A great Urban Data Visualization ought to have the capacity to start “Sociological Imagination”. It should provoke individuals to consider and wrangle on how their individual choices, issues, struggles, and in general their daily lives, are a extension of society, and how their choices collectively create particular results, or how their opinions make public think. As urban areas develop and build up ,various diverse issues rise and develop: disparity, isolation, loss of biodiversity and environmental quality, among others. These issues are perplexing, and finding the correct solutions implies uniting strategy producers, academics, designers, and citizens. Visualizations, if done right, can help begin significant discussions between these diverse areas and help handle the issues that emerge as the world becomes ever more urbanized 6.8 Misinformation can be beautiful too [@harford-misinformation] Camouflage usually means blending in. That wasn’t an option for the submarine-dodging battleships of a century ago, which advertised their presence against an ever-changing sea and sky with bow waves and smokestacks. So, dazzle camouflage was born, an abstract riot of squiggles and harlequin patterns. It wasn’t hard to spot a dazzle ship but the challenge for the periscope operator was to quickly judge a ship’s speed and direction before firing a torpedo on a ponderous intercept. Dazzle camouflage was intended to provoke misjudgments, and there is some evidence that it worked. Now let’s talk about data visualisation, the latest fashion in numerate journalism, albeit one that harks back to the likes of Florence Nightingale. She was not only the most famous nurse in history but the creator of a beautiful visualisation technique, the “Coxcomb diagram”, and the first woman to be elected as a member of the Royal Statistical Society. Source: [@aya-time-series] Data visualisation creates powerful, elegant images from complex data. It’s like good prose: a pleasure to experience and a force for good in the right hands, but also seductive and potentially deceptive. Because we have less experience of data visualisation than of rhetoric, we are naive, and allow ourselves to be dazzled. Too much data visualisation is the statistical equivalent of dazzle camouflage: striking looks grab our attention but either fail to convey useful information or actively misdirect us. For a relatively harmless example, consider The New Yorker’s recent online subway map of inequality. “New York has a problem with inequality,” we are told. Then we are invited to click on different subway maps to see a cross-sectional graph, showing us the peaks and troughs of median income along different subway lines. The result is gorgeous but far less informative than a map would have been. It is a piece of art pretending to be a piece of statistical analysis. A more famous example is David McCandless’s unforgettable animation “Debtris”, in which large blocks fall slowly against an eight-bit soundtrack in homage to the addictive computer game Tetris. Their size indicates their dollar value. “$60bn: estimated cost of Iraq war in 2003” is followed by “$3000bn: estimated total cost of Iraq war”, and then Walmart’s revenue, the UN’s budget, the cost of the financial crisis, and much else. The animation is pure dazzle camouflage. Statistical apples are compared with statistical oranges throughout. The Iraq comparison, for instance, is not one of “then versus now” as it first appears - but one of what the US Department of Defense once thought it would spend versus a broader estimate, including a financial value on the lives of dead soldiers, and over a trillion dollars of “macroeconomic costs”. The war was a disaster- No need for a statistical bait-and-switch to make that case. Information can be beautiful, McCandless tells us. Unfortunately misinformation can be beautiful too. Or, as statistical guru Michael Blastland puts it, “We are in danger of making the same statistical mistakes that we’ve always made - only prettier.” Those beautiful Coxcomb diagrams are no exception. They show the causes of mortality in the Crimean war, and make a powerful case that better hygiene saved lives. But Hugh Small, a biographer of Nightingale, argues that she chose the Coxcomb diagram in order to make exactly this case. A simple bar chart would have been clearer: too clear for Nightingale’s purposes, because it suggested that winter was as much of a killer as poor hygiene was. Nightingale’s presentation of data was masterful. It was also designed not to inform but to persuade. When we look at modern data visualisations, we should remember that. "],
["conclusion.html", "Chapter 7 Conclusion", " Chapter 7 Conclusion Reflection, Key Learnings, Outlook Key Lessons so far everyone must have learned or going forward need to learn is, that for a good Data Visualization: Don’t Be Too Cute Trying to use all the software’s features can lead to complex and confusing graphics. If any person finds a new hammer the tendency is to look at everything like a nail, even if it is a screw. Key point: Don’t lose yourself in your tool or a new theory you discover. Keep to good design principles and keep it simple (as we earlier said when discussing about Patterns). +Don’t provide More Data Then You Need Don’t include more data in a visualization than needed to tell the story. There is often a tendency to provide a visualization with multi-drill downs, filters, and tables. This is fine if we are providing a way to do ad-hoc analysis, but if we have a visual telling a single story, we must make sure the data included helps move the story along without letting the view get lost. +Have More Data to show What-Ifs A great way to look at visualization is to use filters to provide what-if views. Having filters for different scenarios, various options and different time slices provide the user a way to review and discover various perspectives on your data. Just make sure the user does not have to work too hard to get there and that they do not get lost in the data. Keep it simple. +Share What You Have Found A visualization can be an effective influencer if used in a correct way and at the correct time. "],
["references-1.html", "References", " References "]
]
