[
["index.html", "A Reader on Data Visualization Chapter 1 Preface 1.1 References 1.2 Images 1.3 Basic Guidelines", " A Reader on Data Visualization MSIS 2629 Spring 2018 2018-05-21 Chapter 1 Preface This is a collaborative writing project as part of the course MSIS 2629 “Data Visualization” at Santa Clara University. The purpose of the class reader is to collaboratively engage with and reflect on data visualizations, to establish a solid theoretical background, and to collect useful practices and showcases. More information on the background of this project is available in the syllabus. The following text serves explains how we organize ourselves. 1.1 References EVERY references must be included in the book.bib file. This file uses the BibTeX notation (Learn how to use BibTeX here.). Most literature search engines allow you to export the reference information in BibTeX. For websites we use the following minimal notation (you may add further information - usually the more the better is a good strategy): @misc{great_viz, author = {{A great visualizer}}, year = {1982}, title = {A ficticious web page title}, howpublished = {\\url{http://great_viz_org/}}, note = {Accessed: 2018-04-26} } Particularly important is the note field. Websites change frequently, so links will break. If we do this correctly, [@great_viz] will produce (visualizer 1982). 1.2 Images Images should not be loaded from external website because the links may change. Instead download a version of the image and create a reference that contains the link to the image. For example the following image is a deceptive visualization (the bars do start at zero). An Example of a deceptive visualization Source: (Halper 2012) referenced in (Andalde 2014) The citation for the image looks like this. @misc{halper_2012, author={Halper, Daniel}, year={2012}, title = {Over 100 Million Now Receiving Federal Welfare}, url={https://www.weeklystandard.com/daniel-halper/over-100-million-now-receiving-federal-welfare}, note = {Accessed: 2018-04-26} } You have probably found this image through a different website that explains the visualization. For example the following website explains some problematic aspects of this visualization: @misc{andale_2014, author={Andalde, Stephanie}, year={2014}, title = {Misleading Graphs: Real Life Examples}, url={http://www.statisticshowto.com/misleading-graphs/}, note = {Accessed: 2018-04-26} } 1.3 Basic Guidelines Figures and tables with captions will be placed in figure and table environments, respectively.–&gt; par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 1.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 1.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 1.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 1.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2018) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],
["introduction.html", "Chapter 2 Introduction 2.1 What is Data Visualization? 2.2 Why is Data Visualization Important? 2.3 A Brief History of Data Visualization 2.4 Key Figures in the History of Data Visualization 2.5 Contemporary Visualists", " Chapter 2 Introduction 2.1 What is Data Visualization? Data Visualization helps reveal insights and patterns that are not immediately visible in the raw data. Data visualization refers to representing data in a visual context to help people understand the significance of that data. A way so that information, numbers and measurements makes sense is a form of art – the art of data visualization. Graphs do that for us. According to Friedman (2008) (Friedman 2008) the “main goal of data visualization is to communicate information clearly and effectively through graphical means. It doesn’t mean that data visualization needs to look boring to be functional or extremely sophisticated to look beautiful. To convey ideas effectively, both aesthetic form and functionality need to go hand in hand, providing insights into a rather sparse and complex data set by communicating its key-aspects in a more intuitive way.” Information visualization, the art of representing data in a way that it is easy to understand and manipulate, can help us make sense of information and thus make it useful. From business decision making to simple route navigation – there is a huge (and growing) need for data to be presented so that it delivers value. This article is a brief introduction to information visualization. It explains briefly how information visualization helps to make sense of data as well as find relationships between data and confirm ideas. Some examples and common uses of information visualization are discussed below (???). 2.2 Why is Data Visualization Important? Today more than ever, data visualization represents a simple, user-friendly approach to understanding data and making business decisions quickly. Here are some references on why it is important today: 2.2.1 Chris Pittenturf’s article on the importance of data visualization to businesses The article (Pittenturf 2018), written by Chris Pittenturf, VP-Data &amp; Analytics, Palace Sports &amp; Entertainment, explores data visualization and its importance to businesses today. The article begins with a definition of data visualization in simple terms and goes on to explain how a good data visualization should be visually engaging to the reader. Chris goes on to explain the basic criteria that a data visualization should satisfy, to be an effective visualization. These criteria and their brief meanings are as follows: Informative: The visualization should be able to convey the desired information from the data to the reader. Efficient: The visualization should not be ambiguous. Appealing: The visualization should be captivating and visually pleasing. (Optional) Interactive and Predictive: The visualizations can contain variables and filters with which the users may interact in order to predict results of different scenarios. Pittenturf goes on to give various day-to-day examples where visualization gives a better understanding of the data. One extremely simple example used by Pittenturf is that of an energy bill. Pittenturf states that as a consumer, when we receive an energy bill, we normally look at the graph in the bill first before proceeding to read the text in the bill. Pittenturf states that consumers are more likely to analyze and understand the visualizations before reading further along. The article ends with Pittenturf emphasizing the importance of data visualizations in our businesses as well as in our daily lives.It gives a simple, short and crisp understanding of what data visualization is and how it is relevant to everyone. Data visualization is an aid to get a better understanding of the complex insights that any business data provides. Most of the data used by the businesses is highly unstructured and these businesses can get a better understanding of their businesses by visualizing their data. 2.2.2 David McCandless’s TED talk on data visualization Visuals help us understand concepts that would otherwise be difficult to contextualize—for example, expenditures or valuations of extremely large amounts of money are represented in the billion dollar-o-gram by color-coded, relatively-sized boxes. Furthermore, it allows synthesis of a breadth of information to be delivered in a small, easily-digestible, aesthetically pleasing way. Visuals serve as a sort of map for a vast landscape of information—they direct your eyes to the important places and details. And the eye, as McCandless notes, is uniquely suited among our senses to process large amounts of information and detect patterns. The billion dollar-o-gram is extremely readable and rather pretty, but it seems a bit dubious to compare the predicted Iraq War cost to the “mushroomed” actual cost of Iraq and Afghanistan wars, since its purpose seems only to conflate two wars for dramatic effect (McCandless 2010). Beyond its ability to make information from several different sources and in large amounts more quickly and easily understood, data visualization can also reveal smaller interesting patterns—allowing us to play the “data detective” as McCandless calls it. In other words, as we have already discussed, data visualization can not only be extremely effective in a declarative manner, but can also be used as an exploratory tool (McCandless 2010). McCandless also postulates that we all have a latent “design literacy” that is being developed every day as we are constantly bombarded with visuals, and that our minds and our eyes are taking in this information and processing it so that we all have an intuitive sense of design, and have actually begun to demand a visual aspect to our information. This is an interesting perspective, since everyone does seem to have a sense of visual aspects—space, color, etc., but of course the time-honored adage tells us that beauty is in the eye of the beholder. So while it might be whimsical to claim that we are all designers, there is still, of course, great value in learning formal principles of design (McCandless 2010). 2.3 A Brief History of Data Visualization “The only new thing in the world is the history you don’t know.” — Harry S Truman 2.3.1 Data Visualization: modern product? It is common to think of statistical graphics and data visualization as relatively modern developments in statistics, but in fact, the graphic representation of quantitative information has deep roots. These roots reach into the histories of the earliest map-making and visual depiction, and later into thematic cartography, statistics and statistical graphics, medicine, and other fields. Developments in technologies (printing, reproduction) mathematical theory and practice, and empirical observation and recording, enabled the wider use of graphics and new advances in form and content. This paper provides an overview of the intellectual history of data visualization from medieval to modern times, as well as describes and illustrates some significant advances along the way.(Friendly 2006). 2.3.2 Milestones Tour (Friendly 2006) Phase Description Pre-17th Century: Early Maps and Diagrams Data visualization has come a long way. Prior to the 17th century, data visualization already existed. Though displayed in other format such as maps, the content is much similar to today’s visualizations, which mostly presented geologic, economic, and medical data. The earliest seeds of visualization arose in geometric diagrams, in tables of the positions of stars and other celestial bodies, and in the making of maps to aid in navigation and exploration. 1600-1699: Measurement and Theory Among the most important problems of the 17th century were those concerned with physical measurement of time, distance, and space for astronomy, surveying, map making, navigation and territorial expansion. This century also saw considerable new growth in theory as well as the dawn of practical application. 1700-1799: New Graphic Forms With some rudiments of statistical theory, data of interest and importance, and the idea of graphic representation somewhat established, the 18th century witnessed the expansion of these aspects to new domains and new graphic forms. 1800-1850: Beginnings of Modern Graphics With the foundation provided by the previous innovations of design and technique, the first half of the 19th century witnessed explosive growth in statistical graphics and thematic mapping at a rate which would not be equaled until modern times. 1850–1900: The Golden Age of Statistical Graphics By the mid-1800s, all the conditions for the rapid growth of visualization had generated a “perfect storm” for data graphics. Official state statistical offices were established throughout Europe, in recognition of the growing importance of numerical information for social planning,industrialization, commerce, and transportation. 1900-1950: The Modern Dark Ages If the late 1800s were the “golden age” of statistical graphics and thematic cartography, the early 1900s can be called the “modern dark ages” of visualization. There were few graphical innovations, and, by the mid-1930s, the enthusiasm for visualization which characterized the late 1800s had been supplanted by the rise of quantification and formal, often statistical, models in the social sciences. 1950–1975: Rebirth of Data Disualization Still under the influence of the formal and numerical zeitgeist from the mid-1930s on, data visualization began to rise from dormancy in the mid 1960s. 1975–present: High-D, Interactive and Dynamic Data Visualization During the last quarter of the 20th century, data visualization has blossomed into a mature, vibrant and multidisciplinary area of research, as seen in this handbook, and software tools for a wide range of visualization methods and data types are available for every computer. 2.4 Key Figures in the History of Data Visualization The history of data visualization is full of incredible stories marked by major events, led by a few key players. The article (Infogram 2016) introduces some of the amazing men and women who paved the way by combining art, science, and statistics.And one of them is Charles Joseph Minard, whose most famous work is the map of Napoleon’s Russian campaign of 1812 which could be used as a data product for Data Visualization. Below we have some figures names with their famous works, and other stories in the article (Infogram 2016). 2.4.1 William Playfair (1759–1823) William Playfair is considered the father of statistical graphics, having invented the line and bar chart we use so often today. He is also credited with having created the area and pie chart. Playfair was a Scottish engineer and political economist who published “The Commercial and Political Atlas”&quot; in 1786. This book featured a variety of graphs including the image below. In this famous example, he compares exports from England with imports into England from Denmark and Norway from 1700 to 1780. 2.4.2 John Snow (1813–1858) In 1854, a cholera epidemic spread quickly through Soho in London. The Broad Street area had seen over 600 dead, and the surviving residents and business owners had largely fled the terrible disease. Physician John Snow plotted the locations of cholera deaths on a map. The surviving maps of his work show a method of tallying the death counts, drawn as lines parallel to the street, at the appropriate addresses. Snow’s research revealed a pattern. He saw a clear concentration around the water pump on Broad Street, which helped find the cause of the infection. 2.4.3 Charles Joseph Minard (1781–1870) Charles Joseph Minard was a French civil engineer famous for his representation of numerical data on maps. His most famous work is the map of Napoleon’s Russian campaign of 1812 illustrating the dramatic loss of his army over the advance on Moscow and the following retreat. The map displays how many soldiers are still marching and how many have already died at different points in the army’s march. Drawn in 1869, many consider it the best statistical graphic ever created. It represents the earliest beginnings of data journalism. This classic lithograph dates back to 1869, displaying the number of men in Napoleon’s 1812 Russian army, their movements, and the temperatures they encountered along their way. It’s been called one of the “best statistical drawings ever created.” The work is an important reminder that the fundamentals of data visualization lie in a nuanced understanding of the many dimensions of data. Tools like D3.js and HTML are no good without a firm grasp of your dataset and sharp communication skills. 2.5 Contemporary Visualists 2.5.1 Hans Rosling Hans Rosling took his interest in Global Health and developed stunning visualizations about it using statistical methods and data from the UN. He was a noted TED speaker and one of his most interesting TED talks is “Asia’s Rise: How and When” (Rosling 2009). In this, Hans shows trends of the Western countries vs Developing countries like India and China and makes predictions using stunning visualizations like the Bubble chart. In this video, he also predicts the exact date on which India and China will move ahead of USA as strong economic forces. Hans was the co-founder and developer of the foundation “Gapminder”(Ruan et al. 2017) which develops tools to help the people make sense of global data. One of the most important goals of Gapminder foundation is to end ignorance in the world by developing fact-based visualizations to show how the world really is. 2.5.2 David McCandless David McCandless is a British data-journalist and his blog “Information is Beautiful” (McCandless 2018) hosts some of the most visually stunning graphs, charts, and maps on a wide range of topics like science, food, dogs and countries. One such chart, “International Number Ones: Because every country is good at something (according to data),” is a captivating work that displays something at which each country is the best. (McCandless 2016) Some of the interesting findings are as follows: Country ** No.1 in ** Canada Doughnuts USA Spam Emails India Bananas Norway Pizza Eaters Togo Unhappiness Colombia Happiness The visualizations on this website are updated and revised whenever new data is available. The original version of the above-mentioned graph can be seen here: (???) References "],
["fundamentals.html", "Chapter 3 Fundamentals 3.1 Storytelling 3.2 Gestalt Principles 3.3 Three Rules to Follow in order to Develop Intuitive Dashboards 3.4 Design Principles 3.5 Data Visualization Tools 3.6 Research Results &amp; What’s Next", " Chapter 3 Fundamentals Step Name Description 1 Perform Data Discovery and Determine The Story Before this step it is easy to underestimate the effort level it takes to pull the best insights from the data. Data manipulation products like Tableau, Domo, Pentaho, IBM’s Many Eyes, and R, among others, make insight extraction that much easier to gain understanding of data using a visual medium. The key is to start with a simple portion of your data and to start pulling basic insights to visualize and correlate with each other. This process leads towards a compound series of questions, which helps provide an overall vision to the end product. We see the effect during our discovery process, which leads to unforeseen avenues for data intelligence. 2 Data Infrastructure Setup Data infrastructures can be simple or complex depending what the end goal is. Many clients prefer to go the route of complete data integration in order to centralize their data repositories. Technologies such as Hadoop have helped by unifying disparate data sources, but other options such as data cloud environments can help produce API’s for future product deployments. Why is this important? Accessibility of data is an important foundation not only within the context of dashboards, but also the possibility of branching out to other products. 3 Product Design &amp; Development Wireframing, prototyping, and application development are the main engines to transform an idea into a final product. Products can range from static presentations/reports to full interactive applications. Mobile, tablet, TV, and workstation platforms can all be mediums to help deliver the final product. The secret to a great end product is how well the data story is conceptualized. If the story is weak then the end product will also suffer. 4 QA &amp; Product Release The best part of any project is to get it finalized and released for all to see. All data gets verified for accuracy, functionality testing (if applicable), application flow (if applicable), design testing, and remaining items are all completed. The end result is an engaging visual product for all intended audiences to see and use. In other words, visualization is the initial filter for the quality of data streams. Combining data from various sources, visualization tools perform preliminary standardization, shape data in a unified way and create easy-to-verify visual objects. As a result, these tools become indispensable for data cleansing and vetting and help companies prepare quality assets to derive valuable insights. 3.1 Storytelling Storytelling is an essential part of data visualization. It is extremely important to effectively communicate information through the visualization. Stikeleather’s article (2013) discussed the way in which a visual designer tells a story with a visualization. Find the compelling narrative Think about the audience (e.g., novice, generalist, managerial, export, executive) Be objective and offer balance Don’t censor Data visualization will not always unleash a ready-made story on its own. There are no rules, no ‘protocol’ that will guarantee us a story. Instead, it makes more sense to look for ‘insights,’ which can be artfully woven into stories in the hands of a good journalist. Here is a process that may be followed for finding insights to tell a story: (XXX XXXX) References (???) (Anderson 2017) (“5 Data Visualization Tips” XXXX) (Jeffrey D. Camm 2017) 3.1.1 Explore Loading any data set into a spreadsheet can also be a form of visualization as the data becomes visible in a table. Hence the focus should not be whether we need data visualization or not but should be on which form of data visualization is best for the situation. 3.1.2 5 Second Rule Research shows that the average modern attention span for viewing anything online is less than 5 seconds, so if you can’t grab attention within 5 minutes, you’ve likely lost your viewer. Include clear titles and instructions, and tell people succinctly what the visualization shows and how to interact with it. 3.1.3 Design and layout matter The design and layout should facilitate ease of understanding to convey your message to the viewer. Artists use design principles as the foundation of any visual work. If you want to take your data visualization from an everyday dashboard to a compelling data story, incorporate graphic designer Melissa Anderson’s principles of design: balance, emphasis, movement, pattern, repetition, proportion, rhythm, variety, and unity, discussed in more detail in the design principles section (Anderson 2017). 3.1.4 Keep it simple Keep charts simple and easy to interpret. Instead of overloading viewers’ brains with lots of information, keep only necessary elements in the chart and help the audience understand quickly what is going on. 3.1.5 Pretty doesn’t mean effective There is a misconception that aesthetically pleasing visualization is more effective. To draw attention, sometimes we want them to be pretty and eye-catching. But if it fails to communicate the data properly, you’ll lose your audience’s interest as quickly as you gained it. 3.1.6 Use color purposely and effectively Use of color may be prettier and attractive but can be distracting too. Thus, the color should be used only if it assists in conveying your message. Criteria Description Color for Numerical Scales Color for numerical scales should be used with caution. The way you interpret a shade depends on the colors around it and sometimes it can lead to false conclusions. Leverage Color Associations When we say strawberries we associate red color with it. If we can leverage the how people associate different colors for different things, we will not even need a legend to interpret things. Color can be used to leverage long-term memory very quickly. Use Bright Colors to Highlight To attract attention to a certain part of data, bright colors can be used. Alarm colors draw the eye quickly to areas that need attention and help get that message across. 3.1.7 Maps Use of maps can be tricky. Geographical data doesn’t imply a map. Maps can be useful for application where proximity matters, but for straight “what is higher” type comparisons, they’re not very effective as large regions will draw attention easier than smaller regions due to more concentrated color. 3.2 Gestalt Principles Data is simply a collection of many individual elements (i.e., observations, typically represented as rows in a data table). In data viz, our goal is usually to group these elements together in a meaningful way to highlight patterns and anomalies. Described this way, it makes sense that Gestalt Principles are a good set of guidelines to assemble different elements into groups. Criteria Description Proximity White space can be used to group elements together and separate others Similarity Objects that look similar are instinctively grouped together in our minds Enclosure Helps distinguish between groups Symmetry Objects should not be out of balance, or missing, or wrong. If an object is asymmetrical, the viewer will waste time trying to find the problem instead of concentrating on the instruction. Closure We tend to complete shapes and paths even if part of them is missing Continuity We tend to continue shapes beyond their ending points (similar to closure) Connection Helps group elements together Figure and ground We typically notice only one of several main visual aspects of a graph; what we do notice becomes the figure, and everything else becomes the “background”. This one is especially interesting because it is not as obvious as some of the others, but is really important in matching a data viz design to its purpose. (FusionCharts 2012) 3.2.1 Analyze and Interpret Once the data is visualized, the next step is to learn something from the picture that is created. Questions that can be asked based on the picture can be: What can be seen in this image? Is it what that was expected? Are there any interesting patterns? What does this mean in the context of the data? Sometimes we might end up with visualization that, in spite of its beauty, might seem to tell that nothing of interest can be found from data. But there is almost always something that we can learn from any visualization, however trivial. 3.2.2 Document Your Insights and Steps If you think of this process as a journey through the dataset, the documentation is your travel diary. It will tell you where you have traveled to, what you have seen there and how you made your decisions for your next steps. You can even start your documentation before taking your first look at the data. In most cases when we start to work with a previously unseen dataset, we are already full of expectations and assumptions about the data. Usually, there is a reason why we are interested in that dataset that we are looking at. It’s a good idea to start the documentation by writing down these initial thoughts. This helps us to identify our bias and reduces the risk of misinterpretation of the data by just finding what we originally wanted to find. I really think that the documentation is the most important step of the process, and it is also the one we’re most likely to tend to skip. As you will see in the example below, the described process involves a lot of plotting and data wrangling. Looking at a set of 15 charts you created might be very confusing, especially after some time has passed. In fact, those charts are only valuable (to you or any other person you want to communicate your findings) if presented in the context in which they have been created. Hence you should take the time to make some notes on things like: Why have I created this chart? What have I done to the data to create it? What does this chart tell me? 3.2.3 Transform Data Naturally, with the insights that you have gathered from the last visualization, you might have an idea of what you want to see next. You might have found some interesting pattern in the dataset which you now want to inspect in more detail. Possible transformations are: Transformation Description Zooming This allows us to have look at a certain detail in the visualization Aggregation To combine many data points into a single group Filtering This helps us to (temporarily) remove data points that are not in our major focus Outlier removal This allows us to get rid of single points that are not representative of99% of the dataset. Let’s consider that you have visualized a graph and what came out of this was nothing but a mess of nodes connected through hundreds of edges (a very common result when visualizing so-called densely connected networks), one common transformation step would be to filter some of the edges. If, for instance, the edges represent money flows from donor countries to recipient countries we could remove all flows below a certain amount (XXX, n.d.). 3.2.4 Examples of Best Practices in Visual Analysis Referenced below is a free pdf with some examples of best practices in visual analysis. It discusses the most effective charts for various kinds of analysis. It is a helpful and relevant resource for data science students interested in presenting analyses using simple and effective visualizations that tell the complete story. Some of the key areas the author highlights are visualizing trends over time, comparison and ranking, correlation, distribution, geographical data etc. The author gives examples of how simple graphs can also be made more effective simply by adding a few more elements or making simple adjustments. This is a great starting point for creating effective charts and we may use these principles also when we start doing advanced analytics. 3.3 Three Rules to Follow in order to Develop Intuitive Dashboards Often a designer can become too concerned with coming up with a visual that is too intricate and overly complicated. A dashboard should be appealing but also easy to understand. Following these rules will lead to the effective presentation of the data (???). 3.3.1 The dashboard should read left to right Because we read from top to bottom and left to right, a reader’s eyes will naturally look in the upper left of a page. The content should therefore flow like words in a book. It is important to note that the information at the top of the page does not always have to be the most important. Annual data is usually more important to a business but daily or weekly data could be used more often for day to day work. This should be kept in mind when designing a dashboard as dashboards are often used as a quick convenient way to look up data. 3.3.2 Group related information together Grouping related data together is an intuitive way to help the flow of the visual. It does not make sense for a user to have to search in different areas to find the information they need. 3.3.3 Find relationships between seemingly unrelated areas and display visuals together to show the relationship. Grouping unrelated data seems contradictory to the second rule, but the important thing is to tell a story not previously observed. Data analytics is all about finding stories the data are trying to tell. Once they are discovered, the stories need to be presented in an effective manner. Grouping unrelated data together makes it easier to see how they change together. 3.4 Design Principles 3.4.1 Melissa Anderson’s Principles of Design (Anderson 2017) Criteria Description Balance A design is said to be balanced if key visual elements such as color, shape, texture, and negative space are uniformly distributed. Balance doesn’t mean that each side of the visualization needs perfect symmetry, but it is important to have the elements of the dashboard/visualization distributed evenly. And it is important to remember the non-data elements, such as a logo, title, caption, etc. that can affect the balance of the display. Variety Variety in color, shape, and chart-type draws and keeps users engaged with data. Including more variety can increase information retention by the viewer. But when there is too much variety, important details can be overlooked. Variety may affect balance, but when done correctly, variety can help increase the recall of information. However if overdone, too much variety can feel cluttered and blur together the images and data in the mind of the viewer. Emphasis Draw viewers’ attention towards important data by using key visual elements. Emphasis is the component that is most related to when reading through the nine principles of design. It is the key to be conscious of what is drawing the viewers attention to the art. When thinking about the art design of data visualization it is also very important to remain keen on the main point of your story and how the entire visualization is either drawing the viewer to that point of emphasis or how they are being distracted or drawn elsewhere. Movement Ideally movement should mimic the way people usually read, starting at the top of the page, moving across it, and then down. Movement can also be created by using complementary colors to pull the user’s attention across the page. Pattern patterns are ideal for displaying similar sets of information, or for sets of data that equal in value. Disrupting the pattern can also be effective in drawing viewers’ attention; it naturally draws curiosity. Repetition Relationships between sets of data can be communicated by repeating chart types, shapes, or colors. Proportion Proportion can be subtle but it can go a long way to enhancing a viewer’s experience and understanding of the data. The danger of proportion though is that it can be easy to deceive people subconsciously.Naturally images will have a greater impact on how our brains perceive the dashboard or visualization. For example, someone can change the scale of a graph or images to inflate their results and even if they write the numbers next to it, the shortcut many people will take is to interpret the data based on the image. This is why it is important we take care to accurately reflect proportion in our data visualization and remain critical of how others use proportion in their visualization. If a person is portrayed next to a house, the house is going to look bigger. In data visualization, the proportion can indicate the importance of data sets, along with the actual relationship between numbers. Rhythm A design has proper rhythm when the design elements create the movement that is pleasing to the eye. If the design is not able to do so, rearranging visual elements may help. Unity Unity across design will happen naturally if all other design principles are implemented. 3.4.2 Tufte’s Design Principles of Graphical Excellence A graph should be impressive and can obtain audience’s attention. How can we achieve this? We must consider several aspects: efficiency, complexity, structure, density and beauty. We also should consider the audience whether they will be confused about the design. 3.4.2.1 Principle 1: Maximizing the data-ink ratio, within reason. Data-ink is the non-erasable core of a graphic, the non-redundant ink arranged in response to variation in the numbers represented. It is also the proportion of graphic’s ink devoted to the non-redundant display of data-information. \\[{Data \\ Ink \\ Ratio} = \\frac{{Data \\ Ink}}{{Total \\ Ink}}\\] This basic idea follows three principles: Erase non-data-ink, within reason. Erase redundant data-ink, within reason. Always revise and edit. Examples: 1.Erase non-data-ink and redundant data-ink. (source:(Tufte 2001)) Erase non-data-ink and redundant data-ink. (source: (Plotly 2017)) (source: (Plotly 2017)) Always revise and edit. (source:(Tufte 2001)) The graphs will be better for more information per unit of space and per unit of ink is displayed. Graphics are almost always going to improve as they go through editing ,revision, and testing against differernt design options. Try to figure out whehter the audience looking at the new designs be confused? Nothing is lost to those puzzled by the frame of dashes,and something isgained by those who do understand. We can also assume that if you understand the statistical graphics, most other readers will, too because it is a frequent mistake in thinking about statistical graphics to underestimate the audience. Some of the new designs may appear odd, but this is probably because we have not seen them before. 3.4.2.2 Principle 2: Mobilize every graphical element, perhaps several times over, to show the data. The danger of multifunctioning elements is that they tend to generate graphical puzzles, with encodings that can only be broken by their inventor.Thus design techniques for enhancing graphical clarity in the face of complexity must be developed along with multifunctioning elements. In other words, we should try to make all present graphical elements data encoding elements. We must make every graphical element effective. Example: (source:(Tufte 2001)) 3.4.2.3 Principle 3: Maximize data density and the size of the data matrix, within reason. High performation graphics should be designed with special care. As volume of data increases, data measures must shrink (smaller dots for scatters,thinner lines for busy time-series). \\[{Data \\ Density} = \\frac{{Entries \\ in \\ the \\ Data \\ Matrix}}{{Area \\ of \\ Chart}}\\] 3.4.3 Composition of design principles 3.4.3.1 Escape flatland – small multiples, parallel sequencing. Data is multivariate. Doesn’t necessarily mean 3D projection. How can we enhance mulitvariate data on inherently 2D surfaces? Example for small multiples. (source:(Tufte 2001)) Example for parallel sequencing (source:(Tufte 2001)) 3.4.3.2 Macro/Micro: Provide the user with both views (overview and detail). Carefully designed view can show a macro structure (overview) as well as micro structure (detail) in one space. Example: (source:(Tufte 2001)) 3.4.3.3 Utilize Layering &amp; Separation. Supported by Gestalt laws (The principles of grouping): Grouping with colors Using Color to separate 1+1 = 3 (clutter) Example: (source:(Tufte 2001)) 3.4.3.4 Utilize narratives of space and time. Tell a story of position and chronology through visual elements. Example: (source: (Periscope 2018)) (source: (Periscope 2018)) 3.4.4 Adapting your story to a different set of audiences Jonathon Corum is a graphics designer for The New York Times and he provided a very informative talk to a strictly scientific audience on how to create and design visualizations that explain material originally created for a certain audience, i.e. the scientific community, but now is to be related to a different audience, (in his case, the readership of the Times or maybe the public at large). The talk is filled with examples and break downs of how he has moved from his base content to the final product, all of which are illuminating examples by themselves. There is also great power in the broader themes that he is trying to convey. First, of course is knowing the audience that you are producing the work for, but even in this step, do not lose sight of the ultimate goal of conveying understanding, of explaining a concept. You are searching for a visual idea in your content that can be communicated to your audience. Some of the main highlights to help you make this connection with your audience involve: 3.4.4.1 Focusing the attention What can be removed? Realize that consistency can help eliminate unnecessary distractions. There may be a trade off between losing information but conveying the ultimate meaning more clearly. Label important things rather than relying on a legend, which requires the viewer to hold on to too much information at once. 3.4.4.2 Involving your audience Give them opportunities to connect their own general knowledge on the topic. Use real world comparisons or examples to help build and relate context. Encourage comparisons and make this easy for the viewer to process and see. 3.4.4.3 Explaining why Providing context, adding time sequence details, showing movement, change and mechanism will all guide your audience in connecting the dots and understanding the significance of what you are trying to communicate. 3.4.5 Three Rules to Follow in order to Develop Intuitive Dashboards: Often a designer can become too concerned with coming up with a visual that is too intricate and overly complicated. A dashboard should be appealing but also easy to understand. Following these rules will lead to effective presentation of the data (???). 3.4.5.1 The dashboard should read left to right Because we read from top to bottom and left to right, a reader’s eyes will naturally look in the upper left of a page. The content should therefore flow like words in a book. It is important to note that the information at the top of the page does not always have to be the most important. Annual data is usually more important to a business but daily or weekly data could be used more often for day to day work. This should be kept in mind when designing a dashboard as dashboards are often used as a quick convenient way to look up data. 3.4.5.2 Group related information together Grouping related data together is an intuitive way to help the flow of the visual. It does not make sense for a user to have to search in different areas to find the information they need. 3.4.5.3 Find relationships between seemingly unrelated areas and display visuals together to show the relationship Grouping unrelated data seems contradictory to the second rule, but the important thing is to tell a story not previously observed. Data analytics is all about finding stories the data are trying to tell. Once they are discovered, the stories need to be presented in an effective manner. Grouping unrelated data together makes it easier to see how they change together. 3.4.6 What I learned recreating one chart using 24 tools Lisa Rost’s article “What I learned recreating one chart using 24 tools” describes lessons learned from recreating one chart using many different data visualization tools (Rost 2016). The author used apps Excel, Plotly, Easycharts, Google Sheets, Lyra, Highcharts, Tableau, Polestar, Quadrigram, Illustrator, RAW, and NodeBox, as well as charting libraries ggvis, Bokeh, Highcharts, ggplot2, Processing, NVD3, Seaborn, Vega, D3, matplotlib, Vega-Lite, and R. She links her github page on the project which details the data set she used, containing the health expectancy in years as well as GDP per capita and population for about 200 countries in the year 2015, as well has her process and results of visualizing the data using each tool. However, in the article, she focuses on the main takeaways from the exercise, which was especially interesting in the context of our class discussion on different types of tools and their respective strengths. She also provides her own graphics to help illustrate her lessons learned. 3.4.6.1 There Are No Perfect Tools, Just Good Tools for People with Certain Goals Since data visualization is necessary in many spheres, from science to journalism, data visualization projects will often have quite disparate objectives, and the people working on them will have different requirements. And as the author aptly points out, it is impossible for one tool to satisfy the needs of every data visualizer; so there will necessarily be tools better suited to specific situations. For example, does the user need a tool for exploratory visualization of the data, or does the user seek to create graphs and charts to show the public or a specific audience something? The author also notes that the flexibility of a tool is a sticking point as well—if you need to change your data while developing a data visualization, certain apps like Illustrator will not be ideal because changing the data even slightly requires you to build the graph again from scratch. Another thing to think about is the type of chart you are trying to create—is a basic, canned bar or line graph all you need (in which case something like Excel will do the trick), or does your project necessitate a more innovative or custom chart (like something possible in D3.js)? Interactivity is another big question—only certain tools will make this possible. 3.4.6.2 There Are No Perfect Tools, Just Good Tools for People with Certain Mindsets This section of the article is all about the difference in people’s preferences and opinions; from the people who build the tools to the users, everyone thinks differently. Therefore, certain tools will be inherently more intuitive to use for different people. 3.4.6.3 We Still Live in an ‘Apps Are for the Easy Stuff, Code Is for the Good Stuff’ World”** Basically, writing code can be scary for anyone without a coding background, but it provides more flexibility, and, as mentioned in class, code is perfectly reproducible. On the other hand, apps are much more user-friendly for the less computer science-savvy. 3.4.6.4 Every Tool Forces You Down a Path Rost quotes her former NPR Visuals teammate for the final lesson header, pointing out that tools themselves influence the development of a data visualization with their respective features, strengths, and limitations. 3.4.7 Typography and Data Visualization This article discusses less common applications of typography in data visualization. While data components such as quantitative or categorical data are commonly represented by visual features like colors, sizes or shapes, utilization of boldface, font variation, and other typographic elements in data visualization are less prevalent. Highlighted in the article are preattentive visual attributes. Preattentive attributes are those that perceptual psychologists have determined to be easily recognized by the human brain irrespective of how many items are displayed. Therefore, “preattentive visual attributes are desirable in data visualization as they can demand attention only when a target is present, can be difficult to ignore, and are virtually unaffected by load.” Examples of preattentive attributes are size/area, hue, and curvature. This brings us to the disparate situation of the popularity of visual aspects like color and size and typographic aspects such as font variation, capitalization and bold. The authors present several possible reasons for this, beginning with the preattentiveness of visual attributes like size and hue.However, some typographic attributes such as line width or size, intensity, or font weight (a combination of the two) are considered preattentive as well. Furthermore, these visual attributes are inherently more viscerally powerful, and they are easy to code in a variety of programming languages. Technology has also perhaps previously limited the use of typographic attributes, for only recently have fine details such as serifs, italics, etc. been made readily visible to the audiences of data visualizations by technological advances. Lastly, the authors remark that it is possible the lack of variety of typographic elements used in data visualizations is due to the limited knowledge of computer scientists and other individuals pursuing data visualization in how to apply these elements effectively. While the first few proposed explanations make sense from personal experience with technology and exposure to data visualizations and design in general, the hypothesis that lack of knowledge of typographic elements in data visualization seems more plausible if it was being applied to a small group of people rather than all of the data visualization design community. I would say that it is more likely that the use of typographic elements in data visualization is less popular because there are fewer instances in which it can be used appropriately, or a status quo bias—if current visual attributes are received well, the prevailing attitude may be not to fix what is not broken. However, the authors also point out that despite the dearth of typographic attributes in data visualization, other spheres like typography, cartography, mathematics, chemistry, and programming “have a rich history with type and font attributes that informs the scope of the parameter space.” The authors continue by pointing out some tips for using typographic attributes to encode different data types, since certain attributes may be suited to particular purposes. For example, font weight (size and intensity) is ideal for representing quantitative or ordered data, and font type (shape) is better suited to denote categories in the data. Furthermore, as in typography and cartography, use of typographic attributes in data visualization raises concerns of legibility, the ability to understand both individual characters and commonalities that identify a font family, and readability, the ability to read lines and blocks of words. Often, interactivity of a visualization will not only improve functionality, but also provide a solution to readability issues by providing a means to zoom in on small text. There are a few examples of unusual/innovative use of typography for data visualization in the article, not all of which I agree are made more effective by the interesting utilization of typographic attributes, but the “Who Survived the Titanic” visualization’s use of typographic attributes allowed it to not only answer macro-questions very quickly, such as if women and children were actually first to be evacuated across classes, but also to provide answers to micro-questions, like whether or not the Astors survived. It used common visual elements like color and area to indicate whether or not a person survived and number/proportion of people, as well as typographic aspects like italic and simple text replacement to indicate gender and the passengers names. The authors round out the article by addressing the most common criticisms of typography in data visualization, the foremost one being whether or not text should even be considered an element of data visualization, since visualization connotes preattentive visual encoding of information, and text or sequential information necessitates more investment of attention to understand. Another criticism is that textual representations are not as visually appealing even when used effectively. However, the authors counter that “this criticism indicates both the strength and weakness of type? that while text may not be suited for adding style or drama to a visualization, it can be particularly powerful in situations where a finer level of detail is needed, without sacrificing representation of higher level patterns. Lastly, a label length problem is common when using text in visualizations; differing lengths of names or labels may skew perception so that longer labels seem more important than shorter labels. This problem was encountered in the Titanic visualization with the varying lengths representations of passengers’ names, and was corrected by only including a given name and a surname, the length of which could only vary so much. 3.4.8 Data visualization in Business (Lazarevich 2018) According to an Experian report, 95% of U.S. organizations say that they use data to power business opportunities, and another 84 percent believe data is an integral part of forming a business strategy. Visualization helps data impact business in following ways: 3.4.8.1 Cleaning The simplest way to explain the importance of visualization is to look at visualization as the means to making sense of data. Even the most basic, widely-used data visualization tools that combine simple pie charts and bar graphs help people comprehend large amounts of information fast and easily, compared to paper reports and spreadsheets. In other words, visualization is the initial filter for the quality of data streams. Combining data from various sources, visualization tools perform preliminary standardization, shape data in a unified way and create easy-to-verify visual objects. As a result, these tools become indispensable for data cleansing and vetting and help companies prepare quality assets to derive valuable insights. 3.4.8.2 Extracting Known versatile tools for data visualization and analytics – Elastic Stack, Tableau, Highcharts, and more complex database solutions like Hadoop, Amazon AWS and Teradata, have wide applications in business, from monitoring performance to improving customer experience on mobile tools. New generation of data visualization based on AR and VR technology, however, provides formerly unfeasible advantages in terms of identifying patterns and drawing insights from various data streams. Building 3D data visualization spaces, companies can create an intuitive environment that helps data scientists grasp and analyze more data streams at the same time, observe data points from multiple dimensions, identify previously unavailable dependencies and manipulate data by naturally moving objects, zooming, and focusing on more granulated areas. Moreover, these tools allow us to expand the capabilities of data visualization by creating collaborative 3D environments for teams. As a result, new technology helps extract more valuable insights from the same volume of data. 3.4.8.3 Strategizing As the amount of data grows, it becomes harder to catch up with it. Therefore, data strategy becomes the necessary part of the success in applying data to business. Then how data visualization become an important tool in your strategic kit? First, it helps you cleanse your data. Secondly, it allows you to identify and extract meaningful information from it. Finally, data visualization tools enable continuous real-time monitoring of how your strategy and now data-driven decisions influence performance and business outcomes. In other words, these tools visualize not only the data, but also the results, and help correct and optimize strategy on the go. Data visualization is one of the initial steps made to derive value from data. It’s also one of the most important steps, as it determines how efficiently analysts can work with data assets, what insights they are able to extract and how their data strategy will develop over time. Therefore, the quality and capabilities of data visualization directly influence how data impacts your business strategy and what benefits data applications can bring to the companies and their industries. 3.5 Data Visualization Tools Due to the rise of big data analytics, there has been an increased need for data visualization tools to help understand the data. Besides Tableau, there are several other software tools one can use for data visualization like Sisense, Plotly, FusionCharts, Highcharts, Datawrapper, and Qlikview. This article is from Forbes and has a brief, clear introduction about these 7 powerful software options for data visualization. This could be helpful for future reference because for different purposes I may need to use different tools. Each option has its advantages and disadvantages and this article helps highlight them. Tool Description Tableau The most popular in the group and has many users. It is simple to use, making it easy to learn and can handle large data sets. Tableau can handle big data thanks to integration with database handling applications such as MySQL, Hadoop, and Amazon AWS. Qlikview The the main competitor to Tableau and is also quite popular. Qlikview is customizable and has a wide range of features which can be a double-edged sword. These features take more time to learn and get acquainted with. However, once one gets past the learning curve, they have a powerful tool at their disposal. FusionCharts The distinctive aspect of FusionCharts is that graphics do not have to be created from scratch. Users can start with a template and insert their own data from their project. Highcharts: It proudly claims to be used by 72% of the 100 biggest companies in the world. It is a simple tool that does not require specialized training and quickly generates the desired output. Unlike some tools, Highcharts focuses on cross-browser support, allowing for greater access and use. Datawrapper: It is making a name for itself in the media industry. It has a simple user interface making it easy to generate charts and embed into reports. Plotly: It can create more sophisticated visuals thanks to integration with programming languages such as Python and R. The danger is creating something more complicated than necessary. The whole point of data visualization is to quickly and clearly convey information. Sisense: It can bring together multiple sources of data for easier access. It can even work with large data sets. Sisense makes it easy to share finished products across departments, ensuring everyone can get the information they need. 3.5.1 Data Mining vs.Data Visualization In Data Mining, there are different processes involve carrying out the data mining process such as data extraction, data management, data transformations, data pre-processing, etc. In Data Visualization, the primary goal is to convey the information efficiently and clearly without any deviations or complexities in the form of statistical graphs, information graphs, and plots. Also, the author listed the top 7 comparisons between data mining and data visualization, and 12 key differences between data mining and data visualization. After reading the article, you will have a very clear understanding of what are data mining and data visualization and the characters for those two techniques. 3.5.2 Interactive Data Visualization Interactive or Dynamic data visualization delivers today’s complex sea of data in a graphically compelling and an easy-to-understand way. It enables direct actions on a plot to change elements and link between multiple plots. It enables users to accomplish traditional data exploration tasks by making charts interactive(???). Interactive Data Visualization Software has the following benefits: Absorb information in constructive ways: With the volume and velocity of data created everyday, dynamic data viz enables enhanced process optimization, insight discovery and decision making. Visualize relationships and patterns: Helps in better understanding of correlations among operational data and business performance. Identify and act on emerging trends faster: Helps decision makers to grasp shifts in behaviors and trends across multiple data sets much more quickly. Manipulate and interact directly with data: Enables users to engage data more frequently. Foster a new business language : Ability to tell a story through data that instantly relates the performance of a business and its assets. 3.5.3 D3.js D3.js stands for Data Driven Document, a JS library for interactive Big Data visualization in literally ANY way required real-time(Cabot Technology Solution 2017). This is not a tool, mind you, so a user should have a solid understanding of JavaScript to work with the data and present it in a humanly-understandable form. To say more, this library renders the data into SVG and HTML5 formats, so older browsers like IE7 and 8 cannot leverage D3.js capabilities. The data gathered from disparate sources like huge-scale data sets is bind in real-time with DOM to produce interactive animations ( 2D and 3D alike) in an extremely rapid way. The D3 architecture allows the users to intensively reuse the codes across a variety of add-ons and plug-ins. Some of the key advantages are: It is dynamic, free and open source and very flexible with all web technologies, the ability to handle big data and the functional style allows to reuse the codes. The Hitchhiker’ Guide to d3.js is a wonderful guide for self-teaching d3.js. This guide is meant to prepare readers mentally as well as give readers some fruitful directions to pursue. There is a lot to learn besides the d3.js API, both technical knowledge around web standards like HTML, SVG, CSS and JavaScript as well as communication concepts and data visualization principles. Chances are you know something about some of those things, so this guide will attempt to give you good starting points for the things you want to learn more about. It starts from the insights of learning d3.js by showing interviews with those top visualization practitioners. Then the author gives key concepts and useful features for learning visualization like d3-shape, d3 selection, d3-collection, ds-hierarchy, ds-zoom as well as d3-force. My favorite part of this guide is it lists a lot of useful resources links for learning d3.js. For example, it recommends d3 API Reference, 2000+ d3 case studies and tutorials for d3. I did my exploratory analysis version of group project on d3. And I found this guide helpful during the progress. It also includes some meetup groups here in the bay area. So, maybe we can meet data friends through the group. 3.5.4 Tableau Tableau is amid the market leaders for the Big Data visualization, especially efficient for delivering interactive data visualization for the results derived from Big Data operations, deep learning algorithms and multiple types of AI-driven apps (AbsentData 2018). Tableau can be integrated with Amazon AWS, MySQL, Hadoop, Teradata and SAP, making this solution a versatile tool for creating detailed graphs and intuitive data representation. This way the C-suite and middle-chain managers are able to make grounded decisions based on informative and easily-readable Tableau graphs. Tableau is business intelligence (BI) and analytics platform created for the purposes of helping people see, understand, and make decisions with data. It is the industry leader in interactive data visualization tools, offering a broad range of maps, charts, graphs, and more graphical data presentations. It is a painless option when cost is not a concern and you do not need advanced and complex analysis.The application is very handy for quickly visualizing trends in data, connecting to a variety of data sources, and mapping cities/regions and their associated data. The key advantages are: It provides non technical user the ability to build complex reports and dashboard with zero coding skills. Using drag-n-drop functionalities of Tableau, user can create a very interactive visuals within minutes. It can handle millions of rows of data with ease and users can make live to connections to different data sources like SQL etc. Tips for Tableau: Running totals Common Baseline Weighted averages Moving average Grouping by aggregates Different years comparison Appending excel sheets Bar chart totals Fixed axis when re-drawing charts Auto-fitting screen behavior depending on data selection (“Data Visualization Best Practices” 2017) (“The Extreme Presentation Method” XXXX) 3.5.5 Building advanced analytics application with TabPy Imagine a scenario where we can just enter some x values in a dashboard form, and the visualization would predict the y variable! (Beran, n.d.) shows how to integrate and visualize data from Python in Tableau. This is especially relevant to all data science students, as this is one of the tools used for visualizing advanced analytics. The author here has given an example using data from Seattle’s police department’s 911 calls and he tries to identify criminal hotspots in the area.The author uses machine learning (spatial clustering) and creates a great interactive visualization, where you can click on the type of criminal activity and the graph will show various clusters. There are other examples and use cases that may be downloaded, and the scripts are also given by the author for anyone who is interested in trying it out. 3.5.6 R Shiny R Shiny enables us to produce interactive data visualizations with a minimum knowledge of HTML, CSS, or Java using a simple web application framework that runs under the R statistical platform (Castañón 2016). Standalone apps can be hosted on a webpage or embedded in R Markdown documents and dashboards can be built using R shiny. It combines the computational power of R with the interactivity of the modern web. The main advantages of using R Shiny are : Its flexibility of pulling in whatever package in R that you want to solve your problem, reaping the benefits of an open source ecosystem for R and JavaScript visualization libraries, thereby allowing to create highly custom applications and enabling timely, high quality interactive data experience without (or with much less) web development and without the limitations or cost of proprietary BI tools. 3.5.7 Jupyter 3.5.8 Google chart A free and powerful integration of all Google power. The tool is rendering the resulting charts to HTML5/SVG, so they are compatible with any browser. Support for VML ensures compatibility with older IE versions, and the charts can be ported to the latest releases of Android and iOS. What’s even more important, Google chart combines the data from multiple Google services like Google Maps. This results in producing interactive charts that absorb data real-time and can be controlled using an interactive dashboard. https://towardsdatascience.com/top-4-popular-big-data-visualization-tools-4ee945fe207d The tool is rendering the resulting charts to HTML5/SVG, so they are compatible with any browser. Support for VML ensures compatibility with older IE versions, and the charts can be ported to the latest releases of Android and iOS. What’s even more important, Google chart combines the data from multiple Google services like Google Maps. This results in producing interactive charts that absorb data real-time and can be controlled using an interactive dashboard. (“Top 4 Big Data Visualization Tools” 2018) 3.5.9 Corporate Scorecards and Data Visualization Corporate transparency, flat organizations, open book policies, etc. are terms executives and entrepreneurs learn about all the time (Boost Labs 2015). As the corporate world shifts towards a more open culture, the demand for open data and insights have increased dramatically. This shift has helped the overall corporate strategic planning and management process–easing the alignment of business activities towards a series of goals. Being transparent top down aligns the culture to sail towards the same North Star. The growth of corporate transparency is not only important internally, but externally as well. Corporate certifications like B Corporations certifications (B Corp), require companies to provide a transparent view on their social conscious efforts to the general public. Achieving the certification is one step of the process; the true goal is to show the world how and why the certification is truly deserved. 3.5.10 Data Augmentation There are ways to use data visualization at every level of an organization. These applications lets us quickly create insightful visualizations, in minutes. It allows users to visualize data and explore the vast domain interactively. Ref: (The Telegraph 2018) Some of them are mentioned below: (Rojasa, Quispea, and Villegas 2015) Because computer interfacing is changing every day, it is important for our clients to adapt the technology. The language of communicating data in 3D is explored to understand ways to take advantage of all dimensions in augmented reality and virtual reality to deliver information based on the user’s perspective, interest, and urgency. Creating a mechanism to become aware of the user’s intention by analyzing the gaze through reactive design, we achieved developing a complex system for demonstrating massive amount of data and organizing it in a spatial system. The user could walk through and explore the data and interact with different data visualizations. Moving through space is used to provide different levels of detail for specific data through Z axis. Analytical engineer Steluta Iordache states that virtual reality is changing the environment of data analysis. It has long been predicted that augmented reality (AR) and virtual reality (VR) will, sooner rather than later, dive head first into the mainstream of public consciousness. Now, expectations are beginning to meet reality, and as tech giants such as Facebook, Samsung, and Google place heavy investments in these sectors, this seems inevitable. However, placing the headsets and gaming to one side (most experts believe AR and VR will most dynamically disrupt the gaming industry), these nascent technologies can be used by corporate organizations, too. By using proper visualization, it is possible to simplify understanding of a problem and discover a solution more easily. Recently, we have seen data integrated in the real world and users have been able to interact with that data, which is not possible with traditional methods such as plots and charts. We believe AR and VR can build the presentation of the data and show more information at the same time, as well as allow the viewer to explore the data by interacting with it. However, when we analyze data it can be difficult to see the big picture while also having access to finer details. So the question is: how can AR and VR be used to understand complex data by interacting with it within a virtual environment? You can find the answer here(Michael Phillips 2017) 3.6 Research Results &amp; What’s Next With the development, studies and new tools applied in data visualization, more people understand it matters (???) . But given its youth and interdisciplinary nature, research methods and training in the field of data visualization are still developing. So, we asked ourselves: what steps might help accelerate the development of the field? Based on a group brainstorm and discussion, this article shares some of the proposals of ongoing discussion and experiment with new approaches (???): Adapting the Publication and Review Process: As the article states, “both ‘good’ and ‘bad’ reviews could serve as valuable guides,” so providing reviewer guidelines could be helpful for fledgling practitioners in the field. Promoting Discussion and Accretion: Discussion of research papers actively occurs at conferences, on social media, and within research groups. Much of this discussion is either ephemeral or non-public. So ongoing discussion might explicitly transition to the online forum. Research Methods Training: Developing a core curriculum for data visualization research might help both cases, guiding students and instructors alike. For example, recognizing that empirical methods were critical to multiple areas of computer science, Stanford CS faculty organized a new course on Designing Computer Science Experiments. Also, online resources could be reinforced with a catalog of learning resources, ranging from tutorials and self-guided study to online courses. Useful examples include Jake Wobbrock’s Practical Statistics for HCI and Pierre Dragicevic’s resources for reforming statistical practice. References "],
["case-studies.html", "Chapter 4 Case Studies 4.1 Geographic Visualizations 4.2 Time-Based Visualizations 4.3 Animated Data Visualization 4.4 Demographics 4.5 Uncategorized", " Chapter 4 Case Studies Case studies contain valuable information about development records. The examination and evaluation of case studies helps show that new designs are just as usable as existing techniques, demonstrating that the field is suitable for future development. This chapter contains some useful case studies. Many of the case studies below come from the following articles: Source Description (Nathan Yau 2015a) This source presents picks the top 10 best data visualizations of 2015. For each pick, the author displays the project plot and also describes his reasoning for choosing that chart as an exemplary visualization. This article is useful for getting a basic understanding of what characteristics a good visualization should include. (Kayla Darling 2017) The author has chosen fifteen of the best infographics and data visualizations from 2016 and explained the reasoning behind these choices. The following six examples are from the articles: (Crooks 2017) 16 Captivating Data Visualization Examples (Stadd 2015) 15 Data Visualizations That Will Blow Your Mind: “If a picture is worth a thousand words, a data visualization is worth at least a million. As inspiration for your own work with data, check out these 15 data visualizations that will wow you. Taken together, this roundup is an at-a-glance representation of the range of uses data analysis has, from pop culture to public good.” (???) 15 Data Visualizations That Explain Trump, the White Oscars and Other Crazy Current Events (???) Vizwiz is a blog about Tableau-based data visualization. Case studies about how to improve your visualizations written by Andy Kriebel, a famous Tableau Zen Master. I would like to recommend this blog because it is not only practical but also full of insights. My favorite part of this blog is the “Makeover Monday,” which develops a new visualization based on an original one. This blog also includes great tips for and examples of Tableau. Visualization is like art; it speaks where words fail. There are phenomena like the Syrian war, the number flights during Thanksgiving in the USA, the understanding of depths for developing a perspective about the range of the issue, the controversy of ‘#OscarsSoWhite’, etc. on which we can write endless paragraphs, but which might still fail to convince readers. The links show some intricate visualizations of some of these important and relevant topics–visualizations that speak volumes and are much more persuasive than an essay, with a tiny fraction of the text. The usefulness of data visualizations is not just limited to business and analytics; almost anything in the world can be explained by visualizations. Wars, rescue operations, social issues etc. can be visualized to get a clear idea of all the details of the issues. 4.1 Geographic Visualizations 4.1.1 Spies in the Skies (Aldhous and Seife 2016) referenced in (Kayla Darling 2017) The map is filled with red and blue lines (representing FBI and DHS aircraft, respectively) which illustrate the flight paths of the planes. When planes circle an area more than once, the circles become darker. The circles change in accordance to day and time, and individual cities can be typed into a search bar to see the flight patterns over them. The visualization rather creatively looks almost like a hand-drawn map. While presenting a normally uncomfortable topic, this allows individuals to check things for themselves, hopefully providing some peace of mind. New York Flight Patterns 4.1.2 Two Centuries of U.S. Immigration (???) referenced in (Kayla Darling 2017) The interactive map shows the rate of immigration into the U.S. from other countries over the last 200 years in 10-year segments. Colored dots represent 10,000 people coming from the specified country. Countries then light up when they have one of the highest rates of migration. What makes this a good visualization is that it is engaging and easy to read and interpret. The movement of the dots draws the reader’s attention while the brightly lit countries make it easy to pick out the highest total migrations. US Immigration 4.1.3 Uber: Crafting Data-Driven Maps (Klimczak 2016) Map visualization is very important for companies like Uber that need to track metrics using geo-space points. In this article, the designer from Uber talks about the challenges of designing such visualizations and the possible solutions. While a lot of the problems are related to the large scale of the data, there are some insights on scatter plots and hex bins, adding trip lines and making custom tools to help make decisions. The visualization in this article is beneficial for developing geospatial graphics. 4.1.4 Every Satellite Orbiting Earth By David Yanofsky and Tim Fernholz, Published:Nov17,2014 Reference: (Yanofsky and Fernholz 2015) This interactive graph, built using a database from the Union of Concerned Scientists, displays the trajectories of the 1,300 active satellites currently orbiting the Earth. Each satellite is represented by a circular icon, color-coded by country and sized according to launch mass. 4.1.5 An Interactive Visualization of NYC Street Trees (Zapata 2014) Using data from NYC Open Data, this interactive visualization shows the variety and quantity of street trees planted across the five New York City boroughs. 4.1.6 U.S. Migration Patterns The New York Times data team mapped out Americans’ moving patterns from 1900 to present, and the results are fascinating to interact with. You can see where people living in each state were born, and where people are moving to and from. (Gregor Aisch, Gebeloff, and Quealy 2014) 4.1.7 Selfie City (Manovich et al. 2014) Selfie City, a detailed multi-component visual exploration of 3,200 selfies from five major cities around the world, offers a close look at the demographics and trends of selfies. The team behind the project collected and filtered the data using Instagram and Mechanical Turk. Explore the differences between selfies snapped in New York and Berlin for example, as well as those between men and women across the world. 4.2 Time-Based Visualizations 4.2.1 How People Like You Spend Their Time (Yau 2016) referenced in (Kayla Darling 2017) This visual lists several categories such as “personal care” and “work” along one side of a graph with a line illustrating the amount of time the average person in a certain demographic spends on each subject. Entering different statistics at the top, such as changing gender or age, causes the lines to shift to feature that demographic. The simplicity of this visualization helps the information get across and avoids bogging down the statistics. Sometimes, less is more. 4.3 Animated Data Visualization 4.3.1 A Day in the Life of Americans (Nathan Yau 2015b) The page linked above includes a great example of an animated data visualization showing the time people spend on daily activities throughout the day. The plot is simple and easy to interpret, but it also includes a good number of variables including time, activity type, number of people doing each activity, and the order in which activities are done. One of the plot’s biggest strengths is that by using one dot to represent each person in the study and using animation, we can actually drill down to the level of an individual and follow him or her throughout the day. The accumulation of dots for each particular activity also gives us an aggregate-level view of the same data, so we get both individual and aggregate insights. A drawback of the plot is that it is hard for our eyes to keep track of 1000 simultaneously moving dots. The author of the post addresses this by creating subsequent plots with stationary lines at key times of the day. This represents people’s movements from one activity to another without overwhelming the reader. Overall, this is an engaging, informative, and fun animated plot that has relevance and tells a story. 4.4 Demographics 4.4.1 The American Workday NPR tapped into American Time Use Survey data to ascertain the share of workers in a wide range of industries who are at work at any given time. The chart overlays the traditional 9 AM-5 PM standard over the graph for a reference point, helping the audience draw interesting conclusions. 4.4.2 An Aging Nation: Projected Number of Children and Older Adults (United States Census Bureau 2018) Aging population is always a hot topic in social economics and politics. I collected several different data visualizations that show the aging population in the world. This one includes a bar chart and a line graph to demonstrate the aging population compared with population of children. The good things about this visualization are that it is simple to see and compare, employs color to differentiate the categories, and highlights the intersection point. 4.4.3 From Pyramid to Pillar: A Century of Change, Population of the U.S. (???) This is a population pyramid. “A population pyramid is a pair of back-to to histograms for each sex that displays the distribution of a population in all age groups and in gender.” It is a good candidate to visualizing changes in population distributions (sex, age, year). The shape of a pyramid is also used to represent other characteristics of a population. To illustrate, A pyramid with a very wide base and a narrow top section suggests a population with both high fertility and death rates. It is a useful tool for making sence of census data. (“An Aging Population” XXXX) offers an animated pyramid. This is an animated and multiple-population pyramid. It used to compare different patterns across countries. One additional benefit for the interactive population pyramid is that it shows the shape changes by year, which is useful for continuous time-series comparison. A similar project with R code is here. 4.4.4 A Guide to Who is Fighting Whom in Syria 4.4.5 Young voters, class and turnout: how Britain voted in 2017 (Holder, Barr, and Kommenda 2017) This article’s goal is to convey the change in party votes in the 2017 UK general election compared to votes in 2015. The change in party votes was shown with regards to three demographic factors: age, class, and ethnicity. For each factor, there are four graphs (one per political party), each illustrated in the party’s standard color. The change in percent of votes is shown as an arrow where the arrow’s shaft is the length of the difference from 2015 to 2017 while the x-axis is the demographic factor split into different bins. What makes this a good visualization is that it is very easy to read and interpret. The color-coding of the arrows and party name makes it easy to pick out the different parties and the arrow lengths highlight just how large of a change happened. For example, in the Age section, it is easy to see the pattern between the Labour party gaining many voters ages 18 to 44 and the Conservative party gaining voters ages 45 and up. UK Party Votes by Age 4.4.6 Simpson’s Paradox http://vudlab.com/simpsons/ The Visualizing Urban Data Idealab (VUDlab) out of the University of California-Berkeley put together this visual representation of data that disproves the claim in a 1973 suit that charged the school with sex discrimination. Though the graduate schools had accepted 44% of male applicants but only 35% of female applicants, researchers later uncovered that if the data were properly pooled, there was actually a small but statistically significant bias in favor of women. This is called a Simpson’s Paradox. 4.4.7 Millennial Generation Diversity The millennial generation is bigger, more diverse than boomers (Kurtz and Yellin 2018). CNNMoney’s interactive chart showing the size and diversity of the millennial generation compared to baby boomers was built using U.S. Census Data. It turns dry numbers into an intriguing story, illustrating the racial makeup of different age groups from 1913 to present. 4.5 Uncategorized 4.5.1 Connecting the Dots Behind the Election This article by the New York Times lists several different candidates and creates compelling visuals that link their campaigns to previous ones (Aisch and Yourish 2015)(Kayla Darling 2017). Each visual contains several different sized dots that represent a specific campaign, administration, or other governmental organization related to the candidate’s current campaign, which are then connected by arrows. Hovering over a specific dot highlights the connections between the groups. The visual is a great way to summarize what would otherwise require a long slog through years of information into an easily accessible, easily viewable format so that voters can figure out where the candidates’ experiences lie. Clinton 2016 Campaign Staff Source: (Aisch and Yourish 2015) referenced in (Kayla Darling 2017) 4.5.2 Malaria For example, an author re-designed “The Seasonality of Confirmed Malaria Cases in Zambia Southern Province” by pointing out what works well and what could be improved and also explains his goals for the new visualization (ref: http://www.vizwiz.com/2018/04/malaria.html)(Drummey 2016) 4.5.3 Green Honey (Lee 2016) referenced in (Kayla Darling 2017) The visualization spans a webpage. As you scroll down, the text changes, as do many colored dots that move over the white background. The dots are used to represent not only each colors’ hue, but the numbers that fall into each category—for example, what colors are the most popular “base” colors for English and Chinese. The continuous flow of this visualization helps bring it together, allowing users to scroll through the information at their own pace, but also creating a seamless, creative work. 4.5.4 Linguistic Concepts (Alm, Meyers, and Prud’hommeaux 2017) This case study is about usage of linguistic concepts; it discusses how the data is being used and how visual graphics are used to deliver the main insights. It presents an educational tool that integrates computational linguistics resources for use in non-technical undergraduate language science courses. By using the tool in conjunction with case studies, it provides opportunities for students to gain an understanding of linguistic concepts and analysis through the lens of realistic problems in feasible ways. Reference: (Alm, Meyers, and Prud’hommeaux 2017) 4.5.5 Is it Better to Rent or Buy? reference: (Bostock, Carter, and Tse 2014) The calculator includes several sloping charts. Each chart includes a factor that will affect how much you’ll have to pay, such as the individual cost of your home and your mortgage rates. A movable scale along the bottom of each chart allows you to enter different data, such as changing the “cost of rent per month” on the side. This can be useful in price comparision: if you can find a similar house to rent for that much per month or less, it’s more cost effective to just rent the home. This visualization is incredibly thorough and a useful tool for homeowners of any age and status. 4.5.6 What’s really warming the world? (Roston and Migliozzi 2015) referenced in (Keating and Kirk 2015) This case study begins by clearly explaining necessary background information and the analytic questions it seeks to answer. Next it analyzes each factor separately using both verbal explanations and dynamic graphics to compare the observed temperature movements, and then categorizes related factors into “natural factors” or “human factors”. After that, it combines all the dynamic graphics into one, which makes the results easier and more straightforward to compare. Lastly, the authors provide more detailed explanations with data set sources to support their results. Overall, this case study is straightforward, easy to understand, but also informative. 4.5.7 Hans Rosling’s 200 Countries, 200 Years, 4 Minutes Global health data expert Hans Rosling’s famous statistical documentary The Joy of Stats aired on BBC in 2010, but it’s still turning heads. In the remarkable segment “200 Countries, 200 Years, 4 Minutes,” Rosling uses augmented reality to explore public health data in 200 countries over 200 years using 120,000 numbers, in just four minutes (Hans Rosling 2010). 4.5.8 A Guide to Who is Fighting Whom in Syria One of the charts shown in the link (Keating and Kirk 2015), the visualization of ‘A Guide to Who is Fighting Whom in Syria’ is an interesting graphic to study. The visualization and its report can be seen at (???). Who is Fighting Whom in Syria This visualization helps elucidate an extremely complicated topic like the Syrian War. It consists of 3 different emojis in three different colors, with each (color+facial expression) combination showing the ties and conflicts between the various groups involved in the Syrian War. When you click on each of the emoji, a small dialogue box pops up that explains the relationships between the various countries and rebel groups involved in the war. This is not only easy to understand, but it is also pleasing to the eyes. Green emoji shows ‘Friendly’ relationship Red emoji shows the ‘Enemies’ relationship Yellow emoji shows ‘Complicated’ relationship 4.5.9 Adding up the White Oscars Winners (???) referenced in (???) A visualization of all previous winners of the Best Actor/Actress Oscar winners can be seen here (???) in an article by Bloomberg. From the attributes of past Ocsars winners, the authors have developed a set of attributes that they believe will continue to be prevalent in future Oscar winners. It is extremely interesting to see how the article shows the features of the Best Actress, Actor, movies, etc. in a simple and captivating visual. The visualization is interactive and we can click on each attribute like ‘Hair Color’, ‘Eye Color’, etc. to see the features of the actors and actresses who are likely to win the Oscars. Best Actor and Best Actress Source: (???) referenced in (???) Similarly, the visualization gives also information about the different aspects of movies that are more likely to win, like ‘Length,’ ‘Month,’ ‘Budget,’ etc. Best Picture 4.5.10 Kissmetrics blog: visualization of metrics (Patel 2018) Kissmetrics blog is a place where people talk about analytics, marketing, and testing through narratives and visualization of metrics. Metrics are important in the real world, especially when developing/promoting products. Visualization of metrics is also essential so that stakeholders can monitor performance, identify problems and deep dive into potential issues. A good example from the Kissmetrics blog is about Facebook’s organic reach. One important point discussed in the blog is whether the Facebook’s organic reach is decreasing drastically. The general trend shows that there is a huge decline in Facebook’s page organic reach. The following graphs show that the engagement is increasing; that is, while the quantity of content is decreasing, the quantity is increasing. This resonates with what we have learned at class in terms of how different perspectives of interpreting data can lead to different conclusions. 4.5.11 How the Recession Reshaped the Economy, in 255 Charts The first large graph contains 255 lines to show how the number of jobs has changed for every industry in America, using color to highlight the lines and let viewers see the specifics for each industry. By hovering over a line, viewers can the detailed information of that industry’s job trend. Keeping this extra data hidden until needed makes it easier for readers to absorb the bigger picture from this huge data visualization. Below the overall chart are subsets categorized by job sector and sub-industries. Readers can choose the industry or sector they are interested in and, like in the first graph, view the more detailed information by hovering over a line. (Ashkenas and Parlapiano 2014) 4.5.12 Music Timeline https://research.google.com/bigpicture/music/ Google’s Music Timeline illustrates a variety of music genres waxing and waning in popularity from 2010 to present day, based on how many Google Play Music users have an artist or album in their library, and other data such as album release dates. 4.5.13 State of the Union 2014 Minute by Minute on Twitter http://twitter.github.io/interactive/sotu2014/#p1 Twitter’s data team assembled an impressive interactive data hub that depicts how Twitter users across the globe reacted to each paragraph of President Obama’s 2014 State of the Union address. You can slice and dice the data by topic hash tag (for example, #budget, #defense, or #education) and state, resulting in a pretty powerful visualization. 4.5.14 Goldilocks Exoplanets https://news.nationalgeographic.com/news/2014/04/140417-exoplanet-interactive/ Using data from the Planetary Habitability Laboratory at the University of Puerto Rico, the interactive graph plots planetary mass, atmospheric pressure, and temperature to determine what exoplanets might be home, or have been home at one point, to living beings. 4.5.15 Washington Wizards’ Shooting Stars (Lindeman and Gamio 2014) This detailed data visualization demonstrates D.C.’s basketball team’s shooting success during the 2013 season. Using statistics released by the NBA, the visualization allows viewers to examine data for each of 15 players. For example, viewersare able to see how successful each player was at a variety of types of shots from a range of spots on the court, compared to others in the league. 4.5.16 Global Carbon Emissions (World Resources Institute 2014) https://www.theguardian.com/environment/ng-interactive/2014/dec/01/carbon-emissions-past-present-and-future-interactive This data visualization, based on data from the World Resource Institute’s Climate Analysis Indicators Tool and the Intergovernmental Panel on Climate Change, shows how national CO₂ emissions have transformed over the last 150 years and what the future might hold. It also allows the audience to explore emissions by country for a range of different scenarios. 4.5.17 Britain’s diet in data This is a good example about how to present a large amount of comprehensive data - distributed across different categories and measured in different metrics - in a simple yet effective manner, while still maintaining interest and aesthetics. The data product attempts to show how the average Briton’s diet has changed over the last 4 decades for the better (Institute 2016). It does this by displaying simple trend lines that show that more harmful and rich foods are being consumed less and the healthier and leaner foods are being consumed more. It further breaks down every major food category into tens of its constituent products, and in both the overview and deep-dive versions, provides further levers to massage more meaning out of the data. It also shows how the contribution of different foods to the typical diet has changed over the years. Here, we can toggle the year to see exactly how much of each food was consumed, again with another deep-dive into the constituents of every major food group. Source: (???) referenced in (Institute 2016) Such a visualization is ideal for the layman wanting to walk away with a basic but accurate understanding of the dietary changes, and also provides plenty for the more discerning viewer who might have more time and inclination to dissect and parse through the graphs. It is difficult to use the same data product to cater to both types of viewers in such a satisfactory capacity, which is what makes this particular data product so impressive and effective. It satisfies the principles of graphical excellence as stated by Edward Tufte (Tufte 2013) Graphical excellence is that which gives to the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space. 4.5.18 Visualization of big data security: a case study on the KDD99 cup data set This paper utilized a visualization algorithm together with big data analysis in order to gain better insights into the KDD99 dataset: Abstract Cybersecurity has been thrust into the limelight in the modern technological era because of an array of attacks often bypassing untrained intrusion detection systems (IDSs). Therefore, deciphering better methods for identifying attack types to train IDSs more effectively has become a field of great interest. Key cyber-attack insights exist in big data; however, an efficient approach is required to determine strong attack types to train IDSs to become more effective in key areas. Despite the rising growth in IDS research, there is a lack of studies involving big data visualization, which is key. The KDD99 dataset has served as a strong benchmark since 1999; therefore, we utilized this data set in our experiment. In this study, we utilized hash algorithm, a weight table, and sampling method to deal with the inherent problems caused by analyzing big data: volume, variety, and velocity. By utilizing a visualization algorithm, we were able to gain insights into the KDD99 data set with a clear identification of “normal” clusters and described distinct clusters of effective attacks. To read the full paper, please follow the reference link: (???) 4.5.19 How Data Visualization is Helping in Healthcare Decision Making?link Healthcare service providers increasingly investigate different visual and interactive methods in creating and examining large graphs and charts, interactive visualizations, and 2D/3D visualization of discrete event simulation (DES) to comprehend complex and large datasets, recognize connections and trends, model and simulate healthcare events, and communicate and interpret the findings. Expected results include more efficient and effective clinical performance monitoring and improvement, patient flow modeling and management, better patient care quality, security and effectiveness, better support for clinical costing and resource coordination, better-planned development and competitive advantage. Traditional visualization strategies often require significant processing time, which restrains high-throughput analysis. Interactive visualization frameworks maintain a closed loop between the user and the system and, thus, need to be very fast. Building such a framework requires the development of new visualization methods, and there exists the need to design new and effective interaction techniques which are being developed by researchers. Informatics for Integrating Biology and the Bedside (i2b2), an initiative sponsored by the NIH Roadmap National Centers for Biomedical Computing is another such program that provides a query tool that supplies aggregate counts and basic analyses of patient populations from clinical data warehouses (CDWs). i2b2 (i2b2 to Tableau) is effective at estimating patient cohort sizes and has an extendable design where modules with additional features can be developed. Other tools such as R, Python etc also helping healthcare a lot. Today, data visualization solutions can be found everywhere in healthcare systems from hospital operations monitoring and patient profiling to demand projection and capacity planning. Moreover, health informatics databases and networks have amplified benefits with information visualization as it dramatically expands the capacity of patients, clinicians, and public health policy makers to make better decisions. 4.5.20 Tableau: Viz of the Day Tableau has a gallery called Viz of the Day that displays great data visualization examples created by Tableau. It is a great opportunity to see how others are using many different kinds of data to create informative yet fun data visuals. Source data is also attached, so recreation of the visualization is possible as well. Describe Artists with Emoji. Using the data from Spotify, the author listed the 10 most distinctive emoji used in the playlists related to popular artists. The table being used in this visual is very straightforward to link artist to the emojis and is very easy to compare among artists. When you hover over the emoji, further information is presented. References "],
["patterns.html", "Chapter 5 Patterns 5.1 Using Shapes as Filters in Tableau When Your Fields Are Measures 5.2 Outlier Detection 5.3 Genetic Network Reconstruction 5.4 Tips to Improve Data Visualization 5.5 Building Advanced Analytics Application with TabPy 5.6 Pick the Right Chart Type 5.7 Why pie chart is bad: a comparison with the bar chart 5.8 Chose the right baseline in data visualization 5.9 Using design patterns to find greater meaning in your data 5.10 Chart types 5.11 5 Tips to improve Data Visualization 5.12 Word Cloud 5.13 An example to back some of our theories on ‘how to tell stories using data visualization’ / ‘exploratory data visualization’ 5.14 Reusable Data Visualization Code in R 5.15 Data Mining and Data Visualization", " Chapter 5 Patterns 5.1 Using Shapes as Filters in Tableau When Your Fields Are Measures Reference: (???) This article is useful to analyze and redesign the different graphs presented in the article “America’s unique gun violence problem, explained in 17 maps and charts” (Lopez 2018).This article introduces the methodologies on how to use shapes as filters in Tableau when your fields Are Measures. Basically, it teaches you how to load custom shapes as action filters and use them for showing different graphs with those filters, which can make your visualization more interesting and interactive. You can also download the tableau file for practice. Case studies document the development record of a project. They provide the user with an insight into what occurred and relevant details of the process. A person can gain valuable knowledge that can be reused in their own projects and improve his or her own methodologies simply by learning from what others have done. This article explains how data visualization can enhance awareness of the data available and its importance in business decisions. The author explains a situation where poor data visualization led to bad decisions and the negative impact of these decisions. 5.2 Outlier Detection (Arribas-Gil and Romo 2014) We can use data visualization for outlier detection in a data set. Different methods for outlier detection in functional data have been developed during the years. Several of these methods rely on different notions of functional depth, robust principal components, or random projections of infinite-dimensional data into R. Some distributional approaches have also been considered (Gervini, 2009). In functional data analysis, we observe curves defined over a given real interval and shape outliers may be defined as those curves that exhibit a different shape from the rest of the sample. Other types of outliers include: Type 1: Global outliers (also called “point anomalies”): A data point is considered a global outlier if its value is far outside the entirety of the data set in which it is found. Type 2: Contextual (conditional) outliers: A data point is considered a contextual outlier if its value significantly deviates from the rest the data points in the same context. Note that this means that same value may not be considered an outlier if it occurred in a different context. If we limit our discussion to time series data, the “context” is almost always temporal, because time series data are records of a specific quantity over time. Contextual outliers are common in time series data. Type 3: Collective outliers: A subset of data points within a data set is considered anomalous if those values as a collection deviate significantly from the entire data set, but the values of the individual data points are not themselves anomalous in either a contextual or global sense. In time series data, one way this can manifest is as normal peaks and valleys occurring outside of a time frame when that seasonal sequence is normal or as a combination of time series data that is in an outlier as a group. Ref:(Arribas-Gil and Romo 2014). Below is a simple example. Outlier treatment is important because it can drastically bias/change the fit estimates and predictions. Illustration: # Inject outliers into data. cars1 &lt;- cars[1:30, ] # original data cars_outliers &lt;- data.frame(speed=c(19,19,20,20,20), dist=c(190, 186, 210, 220, 218)) # introduce outliers. cars2 &lt;- rbind(cars1, cars_outliers) # data with outliers. # Plot of data with outliers. par(mfrow=c(1, 2)) plot(cars2$speed, cars2$dist, xlim=c(0, 28), ylim=c(0, 230), main=&quot;With Outliers&quot;, xlab=&quot;speed&quot;, ylab=&quot;dist&quot;, pch=&quot;*&quot;, col=&quot;red&quot;, cex=2) plot(cars2$dist,cars2$speed) # Plot of original data without outliers. Note the change in slope (angle) of best fit line. plot(cars1$speed, cars1$dist, xlim=c(0, 28), ylim=c(0, 230), main=&quot;Outliers removed \\n A much better fit!&quot;, xlab=&quot;speed&quot;, ylab=&quot;dist&quot;, pch=&quot;*&quot;, col=&quot;red&quot;, cex=2) Detection of Outliers is performed using: Univariate Approach Multivariate Approach Multivariate Model Approach 5.3 Genetic Network Reconstruction Data visualization techniques are used to reconstruct genetic networks from genomics data. Reconstructed genetic networks are predicted interactions among genes of interest and these interactions are inferred from genomics data, microarray data or DNA sequences. Genomics data are generally contaminated and high-dimensional. It is important to examine and clean data carefully to attain meaningful inferences. Thus, visualization tools that are used in the preprocessing of data associated with genetic network reconstruction are also reviewed and chosen wisely. 5.4 Tips to Improve Data Visualization (French 2017) (Steier et al. 2012) 5.4.1 Comparison Include a zero baseline if possible. Although a line chart does not have to start at a zero baseline, it should be included if it gives more context for comparison. If relatively small fluctuations in data are meaningful (e.g., in stock market data), you may truncate the scale to showcase these variances; Always choose the most efficient visualization; Watch your placement You may have two nice stacked bar charts that are meant to let your reader compare points, but if they’re placed too far apart to “get” the comparison, you’ve already lost; Tell the whole story. Maybe you had a 30% sales increase in Q4. Exciting! But what’s more exciting? Showing that you’ve actually had a 100% sales increase since Q1. 5.4.2 Copy Don’t over explain if the copy already mentions a fact, the subhead, callout, and chart header don’t have to reiterate it; Keep chart and graph headers simple and to the point. There’s no need to get clever, verbose, or pun-tastic. Keep any descriptive text above the chart brief and directly related to the chart underneath. Remember: Focus on the quickest path to comprehension; Use callouts wisely Callouts are not there to fill space. They should be used intentionally to highlight relevant information or provide additional context; Don’t use distracting fonts or elements Sometimes you do need to emphasize a point. If so, only use bold or italic text to emphasize a point—and don’t use them both at the same time. 5.4.3 Color Use a single color to represent the same type of data; Watch out for positive and negative numbers Don’t use red for positive numbers or green for negative numbers. Those color associations are so strong it will automatically flip the meaning in the viewer’s mind; Make sure there is sufficient contrast between colors; Avoid patterns Stripes and polka dots sound fun, but they can be incredibly distracting. If you are trying to differentiate, say, on a map, use different saturation of the same color. On that note, only use solid-colored lines (not dashes); Select colors appropriately; Don’t use more than 6 colors in a single layout. 5.4.4 Ordering Order data intuitively There should be a logical hierarchy. Order categories alphabetically, sequentially, or by value; Order consistently; Order evenly Use natural increments on your axes (0, 5, 10, 15, 20) instead of awkward or uneven increments (0, 3, 5, 16, 50). 5.4.5 Audience perspective Let the users lead; Know your audience, designers should consider the way users prefer to understand information, even in choosing basic analytic approaches. For users to feel comfortable adopting and sharing insights from analytics, they must be able to explain and defend the data. 5.4.6 Use layers to tell a story While style is one form of customization, layering unique data sets on a single visualization can tell a richer narrative and connect users to the data without getting too crowded. On a map, this can be as simple as zooming in and out, but it can also involve drill-downs (choosing a data point and expanding it to show more detail), links and other shortcuts. 5.4.7 Keep it simple Analytic results shouldn’t be presented to 10 decimal places when the user doesn’t need that level of precision to make a decision or understand a concept. Effective visual interfaces avoid 3-D effects or ornate gauge designs (a.k.a. “chart junk”) when simple numbers, maps or graphs will do. 5.5 Building Advanced Analytics Application with TabPy (Beran, n.d.) Imagine a scenario where we can just enter some x values in a dashboard form, and the visualization would predict the y variable!!! Here is a link that shows how to integrate and visualize data from Python in Tableau. This is especially relevant to all data science students, as this is one of the tools used for visualizing advanced analytics. The author here has given an example using data from Seattle’s police department’s 911 calls and he tries to identify criminal hotspots in the area. The author uses machine learning (spatial clustering) and creates a great interactive visualization, where you can click on the type of criminal activity and the graph will show various clusters. There are other examples and use cases that may be downloaded, and the scripts are also given by the author to anyone who is interested in trying it out. 5.6 Pick the Right Chart Type Data visualization is a combination of art and science. When it comes to the artistic aspect, there are no correct answers for doing the visualization. There are many ways to present the data. However, when making sense of facts, numbers, and measurement, the better understanding is promoted by a logical path to follow. To determine the best type of chart is hard for those new to data visualization. Most people learn it by referring to other people’s work without understanding the underlying logic, so they don’t have the theory in their mind to make the judgment. When we are choosing the type of chart, we need to answer some questions: How many features would you like to show in a chart? How many data points do you want to display for each variable? Will you display time serious data or among items or groups. After answering these questions, you should able to get a better imagination of your ideal graph. The simple guidance for using the different type of chart is line charts for tracking trends over time, bar charts to compare quantities, scatter plots for a joint variation of two data items, bubble charts showing joint variation of three data items, and pie charts to compare parts of a whole. 5.7 Why pie chart is bad: a comparison with the bar chart Using pie chart is usually considered as a bad idea when it comes to data visualization. But why? Here, we explore some cons of using the pie chart to convey information and compare its effectiveness to bar chart (Hickey 2013) (Henry 2017) (Quach 2016). Some information may look nearly identical in pie chart. But if the data is presented with bar charts, the story is different. See figure ?? and ?? for examples. Source: (Hickey 2013) Source: (Hickey 2013) It is difficult to compare the slices of a circle to figure out the distinctions in size between each pie slice, especially when there are a lot of categories. See figure ?? for example. (Source: (Hickey 2013)) A Pie chart is easy to be manipulated (e.g. using a 3D pie chart). See figure ?? for example. Source: (Hickey 2013) A Pie chart may be useful when comparing 2 different categories with different amounts of information. Specifically, it does a better job to distinguish two parts with a 25:75 split or one that is not 50:50 as people are sensitive to a right angle or a dividing line that is not straight. But this could be simply done by showing two numbers! See figure ?? and ?? for examples. (Source: (Henry 2017)) (Source: (Henry 2017)) 5.8 Chose the right baseline in data visualization The baseline is very important to data visualization. If the baseline is different, the meaning will change a lot. Now here is a case study to show the importance of baseline and how to use it in different ways. Here I use the same method for a new data set to . (missing…?) # Create the data. a &lt;-rep(c(2010,2011,2012,2013,2014,2015),each = 4) b &lt;- seq(1:24) c &lt;- c(64.9,65.33,71.67,79.17,68.78,69.83,78.61,92.68,89.28,90.43,97.96,106.96,100.66,107.53,117.06,119.21,110.05,97.42,93.62,97.99,80,88.74,102.06,83) data &lt;- as.data.frame(cbind(a,b,c)) colnames(data) &lt;-c(&quot;year&quot;,&quot;quater&quot;,&quot;sales&quot;) Regular quarterly sales. We can see sales decreased a lot around 2014. The baseline here is historical sales. # Regular time series for sales par(cex.axis=0.7) data.ts &lt;- ts(data$sales, start=c(2010, 1), frequency=4) plot(data.ts, xlab=&quot;&quot;, ylab=&quot;&quot;, main=&quot;sales per quater&quot;, las=1, bty=&quot;n&quot;) Quarterly and yearly change sales. The baseline here is zero and look at the percentage changes. # Quaterly change curr &lt;- as.numeric(data$sales[-1]) prev &lt;- as.numeric(data$sales[1:(length(data$sales)-1)]) quaChange &lt;- 100 * round( (curr-prev) / prev, 2 ) barCols &lt;- sapply(quaChange, function(x) { if (x &lt; 0) { return(&quot;#2cbd25&quot;) } else { return(&quot;gray&quot;) } }) barplot(quaChange, border=NA, space=0, las=1, col=barCols, main=&quot;% sales change, quaterly&quot;) # Year-over-year change curr &lt;- as.numeric(data$sales[-(1:4)]) prev &lt;- as.numeric(data$sales[1:(length(data$sales)-4)]) annChange &lt;- 100 * round( (curr-prev) / prev, 2 ) barCols &lt;- sapply(annChange, function(x) { if (x &lt; 0) { return(&quot;#2cbd25&quot;) } else { return(&quot;gray&quot;) } }) barplot(annChange, border=NA, space=0, las=1, col=barCols, main=&quot;% sales change, annual&quot;) From this plot, it is very clear that the magnitude of drops in sales for some quarters. The sales difference compare to now. The baseline here is the current sales. # Relative to current 2015 curr &lt;- as.numeric(data$sales[length(data$sales)]) salesDiff &lt;- as.numeric(data$sales) - curr barCols.diff &lt;- sapply(salesDiff, function(x) { if (x &lt; 0) { return(&quot;gray&quot;) } else { return(&quot;black&quot;) } } ) barplot(salesDiff, border=NA, space=0, las=1, col=barCols.diff, main=&quot;Sales difference from last quater 2015&quot;) Sales difference compared to the first quarter. ** The baseline here is the first quater sales.** # Relative to first quater ori &lt;- as.numeric(data$sales[1]) salesDiff &lt;- as.numeric(data$sales) - ori barCols.diff &lt;- sapply(salesDiff, function(x) { if (x &lt; 0) { return(&quot;gray&quot;) } else { return(&quot;black&quot;) } } ) barplot(salesDiff, border=NA, space=0, las=1, col=barCols.diff, main=&quot;Sales difference from first quater 2010&quot;) The difference between quarter sales and mean. ** The baseline is mean now.** # difference from the mean mean &lt;- mean(as.numeric(data$sales)) salesDiff &lt;- as.numeric(data$sales) - mean barCols.diff &lt;- sapply(salesDiff, function(x) { if (x &lt; 0) { return(&quot;gray&quot;) } else { return(&quot;black&quot;) } } ) barplot(salesDiff, border=NA, space=0, las=1, col=barCols.diff, main=&quot;Sales difference from mean&quot;) So before we start to plot, we should decide the baseline we want to use. Different baseline will lead to totally different graphs. reference: (Yau 2013) 5.9 Using design patterns to find greater meaning in your data Visualizations that show comparisons, connections, and conclusions offer analytical clarity. Patterns based on function can help you see differences and similarities more clearly, understand relationships and behaviors more intimately, and predict future results with a greater level of certainty. When these patterns are presented as visualizations, they help you 1) see comparisons, 2) make connections, and 3) draw conclusions from your data sets. The major functions can be described as: 5.9.1 Comparisons As shown in Figure 1, the bar chart with sparkline enables you to review the data at two different levels: a high-level assessment of the short-term three-month returns is represented with the bar chart, while the sparkline (the line chart below the bar) provides the details of the historical returns. Quickly and concisely, the sparkline shows you the path that has led up to the most recent returns. You can then assess that a narrow path provides consistent returns across the years while a wide path provides varied returns. Side-by-side comparisons of funds organized into two columns—% Returns and % Ahead of Benchmark—enables peer comparisons and fund-specific benchmark comparisons. Hence, you can see that not only has Global Large Cap Core provided positive returns, it has also provided the best and most consistent returns when compared to the benchmark. 5.9.2 Connections The string of charts in Figure 2 shows 10-year to year-to-date (YTD) performance returns, which can be interpreted as individual charts or a group of category charts. Similar to sounds waves, the symmetrical area charts grow equidistant from the source (the zero line) at each time interval to accentuate the returns even further. Here, the y-axis is shown in percentage. Instead of using the zero line to indicate positive or negative returns, it uses color to denote if the category returns are positive (black) or negative (red). For example, Multi-Cap Russell 3000 Growth produced 20% positive returns within the one-year time period and is shown with color fill in both directions from the zero line to purposefully duplicate the large gains and specifically uses black color fill to indicate the returns are positive. As evident from the name, the symmetrical chart doubles the returns to emphasize the amount of color fill. What else can you derive from organizing the information in a spectrum of negative to positive returns? Based on this organization, three groups of categories have resulted in straight losses (red), heavy gains (black), or a mix of gains and losses across a decade of returns. The string of charts makes it easier for you to see these three groups of categories to assess their distribution. Just like sound waves, each chart is a sound bite that streams the returns for each category with a “scream” announcing a huge gain (e.g., Multi-Cap Russel 3000 Growth) or loss (e.g., Mid-Cap Russel Mid Cap Growth). In some cases (e.g., Large Cap S&amp;P 500), the chart quietly announces mixed returns to adequately demand less attention. Next, you might wonder how you would have fared if you had invested in certain funds. You might ask: if I had purchased this fund five years ago, what would my return be? And what about the YTD returns? Since market timing is key to investment choices, the following presentation of hypothetical investments represents a range of results. 5.9.3 Conclusions In Figure 3, varied performance results become clear with a layered approach to show five potential entry points (10-year, 5-year, 3-year, 1-year, YTD) into an investment. For example, the International Large Cap Core fund provided 27% YTD returns, which contrast the negative returns you would have received had you invested in the fund 1, 5, or 10 years ago. Here, conclusions are derived based on known inputs with a divided review of positive or negative outcomes (shown on the y-axis). The line weights help to identify each entry point and show the range of differences between the entry points. Accordingly so, resulting returns are shown with simplified curves that connect the inputs and outputs. In this case, the chart has been customized to show an instance in which the user has opted to see the YTD return values as percentages listed to the right of each resulting output.(???) 5.10 Chart types Let’s review the most commonly used chart types and explain what circumstance should better use typical chart and the pros and cons of each type of chart. Before introducing different types of charts, you can use the following website to familiar with different types of charts (Catalogue 2018). ### Time Series Data Reference: (Ayalasomayajula XXXX) What are some of the most common data visualizations seen in newspapers, textbooks, and corporate annual reports? Graphs showing a country’s GDP growth trends or charts capturing a company’s sales growth in the last 4 quarters would be high up on the list. Essentially, these are visualizations that track time series data – the performance of an indicator over a period of time – also known as temporal visualizations. Temporal visualizations are one of the simplest, quickest ways to represent important time series data. There are 7 handy temporal visualization styles for your time series data. 5.10.1 Line Graph A line graph is the simplest way to represent time series data. It is intuitive, easy to create, and helps the viewer get a quick sense of how something has changed over time. 5.10.2 Stacked Area Chart Stacked area charts are area charts similar to a line chart. In an area chart, multiple variables are “stacked” on top of each other, and the area below each line is colored to represent each variable. Stacked area charts are useful to show how both a cumulative total and individual components of that total changed over time. The order in which we stack the variables is crucial because there can sometimes be a difference in the actual plot versus human perception. The figure below is a stacked area chart showing time series data: (Source: (Ayalasomayajula XXXX)) 5.10.3 Bar Charts represent data as horizontal or vertical bars. The length of each bar is proportional to the value of the variable at that point in time. A bar chart is the right choice for you when you wish to look at how the variable moved over time or when you wish to compare variables versus each other. Grouped or stacked bar charts help you combine both these purposes in one chart while keeping your visualization simple and intuitive. The chart plots the value vertically whereas we perceive the value to be at right angles to the general direction of the chart. For instance, in the figure below, a bar graph would be a cleaner alternative. (Source: (Ayalasomayajula XXXX)) For instance, this grouped bar chart in this interactive visualization of a number of deaths by disease type in India not only lets you compare the deaths due to diarrhea, malaria, and acute respiratory disease across time, but also lets you compare the number of deaths by these three diseases in a given year. By switching to the stacked bar chart view, you get an intuitive sense of the proportion of deaths caused by each disease. We can use two different bar charts to represent time series data. 5.10.4 Column Charts This should be the most popular chart type. This chart is good to do a comparison between different values when specific values are important. TBD Still have hard time to choose? There are many resources on-line can help you do the decision. For example, Dr. Andre Abela creates a chart selection diagram that is helpful to pick the right chart depends on the data type. The link of website is]** (Source: (Ayalasomayajula XXXX)) (Source: (Ayalasomayajula XXXX)) To avoid clutter and confusion, make sure to not use more than 3 variables in a stacked or group bar chart. It is also a good practice to use consistent bold colors and leave appropriate space between two bars in a bar chart. Also, check out our blog on 5 common mistakes that lead to bad data visualization to learn why the base axis for your bar charts should start from zero. 5.10.5 Gantt Chart Gantt charts are a popular project management tool since they present a concise snapshot of various tasks spread across various phases of the project. You can show additional information such as the correlation between individual tasks, resources used in each task, overlapping resources, etc., by the use of colors and placement of bars in a Gantt chart. is a horizontal bar chart showing work completed in a certain period of time with respect to the time allocated for that particular task. It is named after the American engineer and management consultant Henry Gantt who extensively used this framework for project management. Assume you’re planning the logistics for a dance concert. There are lots of activities to be completed, some of which will take place simultaneously while some can be done only after another activity has been completed. For instance, the choreographers, soundtrack, and dancers need to be finalized before the choreography can begin. However, the costumes, props, and stage decor can be planned at the same time as the choreography. With careful preparation, Gantt charts can help you plan for complex, long-term projects that are likely to undergo several revisions and have various resource and task dependencies. Gantt charts are a popular project management tool since they present a concise snapshot of various tasks spread across various phases of the project. You can show additional information such as the correlation between individual tasks, resources used in each task, overlapping resources, etc., by the use of colors and placement of bars in a Gantt chart. 5.10.6 Stream Graph Stream graphs are great to represent and compare time series data for multiple variables. Stream graphs are, thus, apt for large data sets. Remember that choice of colors is very important, especially when there are lots of variables. Variables that do not have significantly high values might tend to get drowned out in the visualization if the colors are not chosen well. (Source: (Ayalasomayajula XXXX))is essentially a stacked area graph, but displaced around a central horizontal axis. The stream graph looks like flowing liquid, hence the name. They are great to represent and compare time series data for multiple variables. Stream graphs are, thus, apt for large data sets. Remember that choice of colors is very important, especially when there are lots of variables. Variables that do not have significantly high values might tend to get drowned out in the visualization if the colors are not chosen well. A stream graph showing a randomly chosen listener’s last.fm music-listening habits over time. 5.10.7 Heat Map Heat maps are perfect for a two-tiered time frame – for instance, 7 days of the week spread across 52 weeks in the year, or 24 hours in a day spread across 30 days of the month, and so on. The limitation, though, is that only one variable can be visualized in a heat map. Comparison between two or more variables is very difficult to represent. (Source: (Ayalasomayajula XXXX)) Geo-spatial visualizations often use heat maps since they quickly help identify “Hot spots” or regions of high concentrations of a given variable. When adapted to temporal visualizations, heat maps can help us explore two levels of time in a 2D array. Heat maps are perfect for a two-tiered time frame – for instance, 7 days of the week spread across 52 weeks in the year, or 24 hours in a day spread across 30 days of the month, and so on. The limitation, though, is that only one variable can be visualized in a heat map. Comparison between two or more variables is very difficult to represent. This heat map visualizes birthdays for babies born in the United States between 1973 and 1999. The vertical axis represents the 31 days in a month while the horizontal axis represents the 12 months in a year. This chart quickly helps us identify that a large number of babies were born in the later half of July, August, and September. (Source: (Ayalasomayajula XXXX)) 5.10.8 Polar Area Diagram Think beyond the straight line! Sometimes, time series data can be cyclical – a season in a year, time of the day, and so on. Polar area diagrams help represent the cyclical nature time series data cleanly. A polar diagram looks like a traditional pie chart, but the sectors differ from each other not by the size of their angles but by how far they extend out from the center of the circle. Polar area diagrams are useful for representing seasonal or cyclical time series data, such as climate or seasonal crop data. Multiple variables can be neatly stacked in the various sectors of the pie. It is crucial to clarify whether the variable is proportional to the area or radius of the sector. It is a good practice to have the area of the sectors proportional to the value being represented. In that case, the radius should be proportional to the square root of the value of the variable (since area of a circle is proportional to the square of the radius). This popular polar area diagram created by Florence Nightingale shows causes of mortality among British troops in the Crimean War. Each color in the diagram represents a different cause of death. (Check out the the text legend for more details.) (Ayalasomayajula XXXX) (“Avoiding Common Mistakes with Time Series” 2015) This article explains how time series data visualization can sometimes be deceptive. It first takes an example of two random time series data and plots them on a graph which gives an impression that the two are strongly correlated. But if we do some statistical testing the two do not show any relationship, this is an example of “correlation does not necessary mean causation”. In another set of examples author has taken trending two random time series data and shown how even statistical tests can give a wrong interpretation. The article then explains using visualization how a general trended time series can be different than a more controlled and measured trending time series. 5.11 5 Tips to improve Data Visualization 5.11.1 Comparison Include a zero baseline if possible. Although a line chart does not have to start at a zero baseline, it should be included if it gives more context for comparison. If relatively small fluctuations in data are meaningful (e.g., in stock market data), you may truncate the scale to showcase these variances; Always choose the most efficient visualization; Watch your placement You may have two nice stacked bar charts that are meant to let your reader compare points, but if they’re placed too far apart to “get” the comparison, you’ve already lost; Tell the whole story. Maybe you had a 30% sales increase in Q4. Exciting! But what’s more exciting? Showing that you’ve actually had a 100% sales increase since Q1. 5.11.2 Copy Don’t over explain. If the copy already mentions a fact, the subhead, callout, and chart header don’t have to reiterate it; Keep chart and graph headers simple and to the point There’s no need to get clever, verbose, or pun-tastic. Keep any descriptive text above the chart brief and directly related to the chart underneath. Remember: Focus on the quickest path to comprehension; Use callouts wisely Callouts are not there to fill space. They should be used intentionally to highlight relevant information or provide additional context; Don’t use distracting fonts or elements Sometimes you do need to emphasize a point. If so, only use bold or italic text to emphasize a point—and don’t use them both at the same time. 5.11.3 Color Use a single color to represent the same type of data; Watch out for positive and negative numbers. Don’t use red for positive numbers or green for negative numbers. Those color associations are so strong it will automatically flip the meaning in the viewer’s mind; Make sure there is sufficient contrast between colors; Avoid patterns Stripes and polka dots sound fun, but they can be incredibly distracting. If you are trying to differentiate, say, on a map, use different saturation of the same color. On that note, only use solid-colored lines (not dashes); Select colors appropriately; Don’t use more than 6 colors in a single layout. 5.11.4 Ordering Order data intuitively should have a logical hierarchy. Order categories alphabetically, sequentially, or by value; Order consistently; Order evenly Use natural increments on your axes (0, 5, 10, 15, 20) instead of awkward or uneven increments (0, 3, 5, 16, 50). 5.11.5 Audience perspective Let the users lead; Know your audience. Designers should consider the way users prefer to understand information, even in choosing basic analytic approaches. For users to feel comfortable adopting and sharing insights from analytics, they must be able to explain and defend the data. 5.11.6 Use layers to tell a story While style is one form of customization, layering unique data sets on a single visualization can tell a richer narrative and connect users to the data without getting too crowded. On a map, this can be as simple as zooming in and out, but it can also involve drill-downs (choosing a data point and expanding it to show more detail), links and other shortcuts. 5.11.7 Keep it simple Keep it as simple as possible!Analytic results shouldn’t be presented to 10 decimal places when the user doesn’t need that level of precision to make a decision or understand a concept. Effective visual interfaces avoid 3-D effects or ornate gauge designs (a.k.a. “chart junk”) when simple numbers, maps or graphs will do. +reference: (French 2017) +reference: (Steier et al. 2012) 5.12 Word Cloud A Word Cloud or Tag Cloud is a visual representation of text data in the form of tags, which are typically single words whose importance is visualized by way of their size and color. It displays how frequently words appear in a given body of text, by making the size of each word proportional to its frequency. Word clouds can add clarity during text analysis in order to effectively communicate your data results.It is an effective tool for Q researchers, marketers, Non-profits, Human resources ,Educators, Politicians and journalists. ** Pros of Word Clouds ** It is easy to understand and make an impact. It can easily be shared. It is visually engaging than a table data. It is fast and reveals the essential. They delight and provide emotional connection. ** Cons of Word Clouds ** Emphasis based on length of the words. Words whose letters contain many ascenders and descenders may receive more attention. They’re not very accurate. A lot of data cleaning required before generating the word cloud. Context is lost. (McKee 2014) ** Ways of generating a word cloud ** R: The procedure of creating word clouds is very simple in R with text mining package (TM) and the word cloud generator package. The major steps involved are: text mining which involves text cleaning and transformation, building term-document matrix and generating word cloud (analysis 2018). Wordle: Wordle is a toy for generating “word clouds” from text that you provide.It is very popular, free and easy to use. You do need Java though Chrome. In Wordle, you generate word clouds from text you input. Clouds can be tweaked with different color schemes, layouts, and fonts. Images created from this tool can be saved and reused (Feinberg 2014). Other popular tools include ABCya, Tagul, Tag Crowd, CloudArt. 5.12.1 Calendar View (Reproducible code for reference) (Bostock 2018a) We have all seen the calendar views in the various data products that we worked on. Please find an open source code that I found, this will help you replicate and create your own calendar: (Bostock 2018b) This example demonstrates loading of CSV data, which is then quantized into a diverging color scale. The values are visualized as colored cells per day. Days are arranged into columns by week, then grouped by month and years. &lt;!DOCTYPE html&gt; &lt;body&gt; &lt;script src=&quot;https://d3js.org/d3.v4.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; var width = 960, height = 136, cellSize = 17; var formatPercent = d3.format(&quot;.1%&quot;); var color = d3.scaleQuantize() .domain([-0.05, 0.05]) .range([&quot;#a50026&quot;, &quot;#d73027&quot;, &quot;#f46d43&quot;, &quot;#fdae61&quot;, &quot;#fee08b&quot;, &quot;#ffffbf&quot;, &quot;#d9ef8b&quot;, &quot;#a6d96a&quot;, &quot;#66bd63&quot;, &quot;#1a9850&quot;, &quot;#006837&quot;]); var svg = d3.select(&quot;body&quot;) .selectAll(&quot;svg&quot;) .data(d3.range(1990, 2011)) .enter().append(&quot;svg&quot;) .attr(&quot;width&quot;, width) .attr(&quot;height&quot;, height) .append(&quot;g&quot;) .attr(&quot;transform&quot;, &quot;translate(&quot; + ((width - cellSize * 53) / 2) + &quot;,&quot; + (height - cellSize * 7 - 1) + &quot;)&quot;); svg.append(&quot;text&quot;) .attr(&quot;transform&quot;, &quot;translate(-6,&quot; + cellSize * 3.5 + &quot;)rotate(-90)&quot;) .attr(&quot;font-family&quot;, &quot;sans-serif&quot;) .attr(&quot;font-size&quot;, 10) .attr(&quot;text-anchor&quot;, &quot;middle&quot;) .text(function(d) { return d; }); var rect = svg.append(&quot;g&quot;) .attr(&quot;fill&quot;, &quot;none&quot;) .attr(&quot;stroke&quot;, &quot;#ccc&quot;) .selectAll(&quot;rect&quot;) .data(function(d) { return d3.timeDays(new Date(d, 0, 1), new Date(d + 1, 0, 1)); }) .enter().append(&quot;rect&quot;) .attr(&quot;width&quot;, cellSize) .attr(&quot;height&quot;, cellSize) .attr(&quot;x&quot;, function(d) { return d3.timeWeek.count(d3.timeYear(d), d) * cellSize; }) .attr(&quot;y&quot;, function(d) { return d.getDay() * cellSize; }) .datum(d3.timeFormat(&quot;%Y-%m-%d&quot;)); svg.append(&quot;g&quot;) .attr(&quot;fill&quot;, &quot;none&quot;) .attr(&quot;stroke&quot;, &quot;#000&quot;) .selectAll(&quot;path&quot;) .data(function(d) { return d3.timeMonths(new Date(d, 0, 1), new Date(d + 1, 0, 1)); }) .enter().append(&quot;path&quot;) .attr(&quot;d&quot;, pathMonth); d3.csv(&quot;dji.csv&quot;, function(error, csv) { if (error) throw error; var data = d3.nest() .key(function(d) { return d.Date; }) .rollup(function(d) { return (d[0].Close - d[0].Open) / d[0].Open; }) .object(csv); rect.filter(function(d) { return d in data; }) .attr(&quot;fill&quot;, function(d) { return color(data[d]); }) .append(&quot;title&quot;) .text(function(d) { return d + &quot;: &quot; + formatPercent(data[d]); }); }); function pathMonth(t0) { var t1 = new Date(t0.getFullYear(), t0.getMonth() + 1, 0), d0 = t0.getDay(), w0 = d3.timeWeek.count(d3.timeYear(t0), t0), d1 = t1.getDay(), w1 = d3.timeWeek.count(d3.timeYear(t1), t1); return &quot;M&quot; + (w0 + 1) * cellSize + &quot;,&quot; + d0 * cellSize + &quot;H&quot; + w0 * cellSize + &quot;V&quot; + 7 * cellSize + &quot;H&quot; + w1 * cellSize + &quot;V&quot; + (d1 + 1) * cellSize + &quot;H&quot; + (w1 + 1) * cellSize + &quot;V&quot; + 0 + &quot;H&quot; + (w0 + 1) * cellSize + &quot;Z&quot;; } &lt;/script&gt; 5.13 An example to back some of our theories on ‘how to tell stories using data visualization’ / ‘exploratory data visualization’ (???) MIT Media Lab in collaboration with Deloitte has created a new visualization tool, that aggregates US government open source data from various sources and mines information to generate trends and stories about cities, jobs, industries etc. to the common man. Just looking at any of the open data sources would give us an idea about the vastness (breadth and depth) of the available data. It is amazing to see how they have brought it all together on a single platform in a very easy to decipher format. What caught my attention here is the categorization of Information on the website that enables the following: Easy browsing of various categories of information available at a single glance An Easy search on any topic of interest and get deeper information on each Logical construction of information using data and visuals under each category Comparative Analysis of cities Variety of exploratory visualizations to learn from Most important - Stories that these data tell, e.g., Evolution of the American Worker, Poverty is bad for your health, Men still dominate in the highest paying industries, Opioid addiction damage and so many others. We think of a topic, and its possible it’s there! Value add to students, organizations, governments etc. is better understanding of your consumers, talent pool, jobs, climate, and what not, that just improves our decision-making ability manifold by spending just a few seconds on the website. And for this class, the best part is that the data is also available for download. So, we can easily download this data, replicate the visuals and try to redesign and tell our own stories with this data. There is also other similar websites, that has some good visualizations on census data: (???) Automatic visualization is a bad idea, generally speaking. Some (many?) might argue that automated visualization is a worthwhile pursuit. And I would agree that some parts of visualization certainly should be automatic, such as standard chart types and recurring geometries. Pieces of visualization, such as annotation and axis construction can be automatic. There are plenty of tools to make our lives easier. But full-on automation where insight fountains out from any dataset are farfetched at this point, because this requires automatic analysis. The analysis is context-specific and requires more than boilerplate statistics. The most interesting visualization is context-specific. In 2016, Arden Manning believed Workplace Automation making Data Visualization Smarter. According to him, the goal of data visualization tools was to make understanding data easier, but more often than not it doesn’t quite go to plan. We’ve all been there. The software is able to analyze huge amounts of data and incredible speeds, but how can it explain the results of that analysis? Today, the only means of doing this is with graphics. However, data visualization can’t explain data, leaving room for interpretation. The thought behind graphics makes sense – turn data into something easy to understand – but the reality is more complex, and we are left working late writing reports explaining how many trades were canceled and by what desks or why sales fell in August of 2015. Whenever I am stuck doing a repetitive task, I always think ‘why can’t we automate this’? And now, finally, technology has caught up. Narrative generation software can run as a plug-in to your dashboards. Tools like Savvy actually install on your server and allow every dashboard user to get a written summary anytime they want. This software is fully plugged and play, it takes seconds to install, and it’s easy to use. Today, it runs with Microsoft Excel, Qlik Sense 3.0, and is available as an API. In fact, the software even lets you copy and paste the text it generates so that you can use it in emails and reports explaining data. Yet again automation is making our working lives easier by automating repetitive tasks and allowing us to fully leverage existing data reserves. According to Alysson Ferreira, a UI Engineer, he published his idea of Data Visualization tools in 2017. In this new era of information, there’s an increasing need to understand the latest trends quickly and efficiently, which means there’s also a need for meaningful sources of trustworthy information. This is where data visualization comes in. Data visualization is the art of displaying information by combining the beauty of imagery with the conciseness of statistics, which allows us to organize complex data into convenient graphical representations. In simple terms, data visualization is the art of translating complex data into meaningful information. We can also find the topic of data visualization’s future on Quora. Amalie Sharma thought in future trend of data visualization are better tools, open for all, Increase in Interactivity/Animation and Portable Data. Plug in any data set into a magic box and it spits out a lovely visualization you can show all of your co-workers, friends, and family. That’s the promise of a lot of startups, but it doesn’t quite work that way. The goal of data visualization tools was to make understanding data easier, but more often than not it doesn’t quite go to plan. The problem is that graphics alone don’t fully explain data, and so we are inundated with queries: why did the numbers fall in whatever month? Data visualization can’t explain data, leaving room for interpretation. Although simple visualizations such as standard chart types (bar chart, line chart etc.) are already automated to a certain extend in Microsoft Office tools and other software available in the market, but full on automation where insight fountains out from any data set is far-fetched at this point, because this requires automatic analysis. The automated analysis here means that the tool or algorithm has to understand the context and also select the best visualization. The focus in today’s world has been on open source tools and technologies and these tools although being free for the most part require more effort to seamlessly integrate to the current visualization workflow. As mentioned in one of the articles about D3.js: D3.js is one of the first data visualization tools that comes to mind when talking about free, open-source alternatives. It’s a JavaScript-based library for creating web visualization and displays the results on the web page. However, with great power comes great responsibility. D3.js is extremely powerful and flexible, because it allows you to build amazing things with it, but as a trade-off, it’s not the easiest tool to use, so you might need to spend some time going through the helpful library documentation. At the end, it’s not only about the tool its more about what you are trying to do; what your professor, client, business or whatever needs. 5.14 Reusable Data Visualization Code in R (Prabhakaran 2017) This site includes full sets of R code to generate specific types of graphs in ggplot2. Plots in ggplot2 are created by using “layering”. There is a base plot and then other aspects of the plot such as aesthetics, titles ,and labels are added to using extra code. For those who favor Python for data viz, this layering approach in R is actually similar to the syntax in Python’s matplotlib library, in which set_style and specifying the axes labels and title are done separately from the code that generates the plot itself. To provide an example the “layering” mentioned above, here is a generic snippet of code for creating a scatterplot with ggplot2 and the mtcars data set in R base, using this website’s code as a template: library(ggplot2) theme_set(theme_bw()) #set background theme plot1 &lt;- ggplot(mtcars, aes(x = hp, y = mpg)) + geom_point(aes(col=factor(vs), size = 2)) + geom_smooth(method = &quot;loess&quot;, se = F) + xlim(c(0, 400)) + ylim(c(0, 40)) + labs(title = &quot;Horsepower vs. MPG&quot;, y = &quot;Miles Per Gallon&quot;, x = &quot;Horsepower&quot;) plot(plot1) #we have to actually call the plot() function on the plot object we created The ggplot2 package allows R users to go beyond the simple and often rudimentary-looking graphs in R and offers many ways of customizing data visualizations. In a way, the layering technique also makes it easier to remember the code to generate these plots, since geom functions for the layers remain constant and they are all included in a single line of code. 5.15 Data Mining and Data Visualization According to a paper in 2018, we can tell the difference of data mining from data visualizations. Here is a chart that helps us understand this better. BASIS FOR COMPARISON Data Mining Data Visualization Definition Searches and produces a suitable result from large data chunks Gives a simple overview of complex data Preference This is has different applications and preferred for web search engines Preferred for data forecasting and predictions Area Comes under data science Comes under the area of data science Platform Operated with web software systems or applications Supports and works better in complex data analyses and applications Generality New technology but underdeveloped More useful in real time data forecasting Algorithm Many algorithms exist in using data mining No need of using any algorithms Integration Runs on any web-enabled platform or with any applications Irrespective of hardware or software, it provides visual information In Data Mining, there are different processes involve carrying out the data mining process such as data extraction, data management, data transformations, data pre-processing, etc. In Data Visualization, the primary goal is to convey the information efficiently and clearly without any deviations or complexities in the form of statistical graphs, information graphs, and plots. Also, the author listed the top 7 comparisons between data mining and data visualization, and 12 key differences between data mining and data visualization. After reading the article, you will have a very clear understanding of what are data mining and data visualization and the characters for those two techniques. References "],
["ethics.html", "Chapter 6 Ethics 6.1 Ethical Theory and Practice from Journalism and Engineering 6.2 Importance of Ethics in Visualization 6.3 Implications of (Good/Bad) Data Visualization 6.4 General Guidelines for Ethical Visuals 6.5 Defintions of Data Deception and Graphic Integrity 6.6 Visual Lies", " Chapter 6 Ethics 6.1 Ethical Theory and Practice from Journalism and Engineering (Zinovyev 2011) Over the years, researchers and lawyers have come up with rules and practices for proper data collection and utilization, with particular attention on human subject research. Consent of the subjects to use their data, evaluation of any risk with use or collection of data, and protecting the anonymity of data are some of the rules that must be considered for ethical research methods. Under U.S. law, research institutions receiving federal funding must consider ethical aspects of their research. These rules continue to evolve. Data presented in charts can persuade viewers on the subject matter, even if viewers do not support the idea presented. This means that visualizations can also be used to deceive and there are many techniques for this leading viewers to wrong conclusions. Misleading, incomprehensible, or incredible data visualization can jeopardize people’s trust, goodwill, or faith in research and advocacy on vital human rights issues. Its ethical responsibility to create visualizations to give the correct and faithful representation of data and subjects. The basic objective of data visualization is to provide an efficient graphical display for summarizing and reasoning about quantitative information. And during the last decades, political science has accumulated a large corpus of various kinds of data, which gradually become a more scientific and requires using quantitative information in the analysis and reasoning. Under U.S. law, research institutions receiving federal funding must consider ethical aspects of their research. Over the years, researchers and lawyers have established rules and practices for proper data collection and utilization, with particular attention to human subject research. Some of the most important of these rules for ethical research methods include consent of the subjects to use their data, evaluation of any risk with use or collection of data, and protecting anonymity of data. However, these rules continue to evolve. Data presented in charts can persuade viewers on the subject matter, even if viewers do not support the idea presented. This means that visualizations can also be used to present misleading arguments and deceive viewers. Misleading, incomprehensible, or incredible data visualization can jeopardize people’s trust, goodwill, or faith in research and advocacy on vital human rights issues. There is no shortage of techniques for deception through data visualization, and researchers have an ethical responsibility to give correct and faithful representation of data and subjects. The basic objective of data visualization is to provide an efficient graphical display for summarizing and posing a claim about quantitative information. However, the value of data visualization is not limited to business and the hard sciences. During the last decades, political science has accumulated a large corpus of various kinds of data, and has gradually become a quantitative and scientific field that requires the use of quantitative information in analysis and reasoning. Data visualization plays several important roles: Obtaining the consent of the subjects to use their data, evaluating any risk with use or collection of data or protecting the anonymity of data are some of the rules that must be considered for ethical research methods. Under U.S.law for research institutions receiving federal funding, ethical aspects must be considered. These rules continue to evolve. Research has found that even if viewers do not support an idea, data presented in charts can persuade viewers on the subject matter. It means that visualization can also be used for deception and there are lot of techniques that can produce dangerous visualization. Techniques such as truncated axis (where the y-axis does not start at zero) or using the area to represent a quantity (for instance comparing the size of two adjacent circles) were found to lead to wrong conclusions. Misleading, incomprehensible, or incredible data visualization can jeopardize people’s trust, goodwill, or faith in research and advocacy on vital human rights issues. Its ethical responsibility to create visualizations to give a correct and faithful representation of data and subjects. Data visualization plays several important roles in it: it helps create informative illustrations of the data, recapitulating a large amount of quantitative information on a diagram; it helps formulate new or support existing hypotheses from quantitative data; it guides a statistical analysis of data and checks its validity. Some useful visualization methods are: Statistical graphics and infographics Geographical information systems (GIS) Graph visualization or network maps Data cartography 6.2 Importance of Ethics in Visualization (Cairo 2014) Alberto Cairo addresses the ethical ‘why’ of data visualization in this article, while still grounding the discussion in a straightforward analysis of what to do and what not to do. He emphasizes that the effectiveness of the communicative display is as important as the information itself. This makes intuitive sense because useful information is rendered utterly useless if no one can understand it. Cairo sees data visualization as a harmonization of journalism and engineering. From these two disciplines, he takes the journalist ethos of truth-telling and honesty and combines this with an engineering focus on efficacy and efficiency. The result is a data visualization that contains accurate and relevant information which is clearly and concisely conveyed. Cairo describes himself as a “rule utilitarian” and uses this to explain why it is ethical or, in his words, “morally right,” to create graphics in this way. Here, it very useful to review his post on the blog introducing the article. Essentially, the goal is to create the most good while doing the least harm. As such, conveying truthful and honest relevant information increases a person’s understanding. Increased understanding and knowledge positively correlates with personal well-being. The information presented must be accurate and relevant. Cairo briefly addresses guidelines for this which are applicable in all information gathering fields: beware of selection bias when choosing preexisting datasets, validate the data, and include important context. False or irrelevant information doesn’t improve anyone’s decision-making capacity, so it cannot enhance well-being. Even if the information is both accurate and relevant, moral engineering pitfalls may remain. To avoid the unethical trap of inscrutable (or misleading) graphics, Cairo exhorts us to take an evidenced-based approach when possible. The purpose of the graphic dictates the form it takes; aesthetic preferences should never override clarity. Again, since the ethical purpose is to improve well-being through understanding, a graphic which is confusing or misleading is unethical, regardless of intent, since it actually creates misunderstanding for the audience. While it can be a bit jarring to think of a poorly designed graphic as “morally wrong”, it is important to think of the unintended consequences of visuals which have a powerful impact on their viewers. Cairo sees data visualization as a harmonization of journalism and engineering. From these two disciplines, he takes the journalist ethos of truth-telling and combines this with an engineering focus on efficacy and efficiency. The result is a data visualization that contains accurate and relevant information which is clearly and concisely conveyed. Cairo describes himself as a “rule utilitarian” and uses this to explain why it is “morally right” to create graphics in this way. Here, it is useful to review his blogpost introducing the article. Essentially, the goal is to create the most good while doing the least harm. As such, conveying honest and relevant information increases a person’s understanding. Increased understanding and knowledge positively correlates with personal well-being. The information presented must be accurate and relevant. Cairo briefly addresses guidelines that are applicable in all information gathering fields: beware of selection bias when choosing preexisting datasets, validate the data, and include important context. False or irrelevant information doesn’t improve anyone’s decision-making capacity, so it cannot enhance well-being. Even if the information is both accurate and relevant, moral pitfalls may remain. To avoid the unethical trap of inscrutable or misleading graphics, Cairo exhorts us to take an evidenced-based approach when possible. The purpose of the graphic dictates the form it takes; aesthetic preferences should never override clarity. Again, since the ethical purpose is to improve well-being through understanding, a graphic which is confusing or misleading is unethical, regardless of intent, since it actually creates misunderstanding for the audience. While it can be a bit jarring to think of a poorly designed graphic as “morally wrong,” it is important to think of the unintended consequences of visuals which have a powerful impact on their viewers. The basic objective of data visualization is to provide an efficient graphical display for summarizing and reasoning about quantitative information. And during the last decades, political science has accumulated a large corpus of various kinds of data, which makes it gradually become a more quantitative scientific field and requires using quantitative information in the analysis and reasoning. Data visualization plays several important roles in it: 1) helps create informative illustrations of the data, recapitulating a large amount of quantitative information on a diagram; 2) helps formulate new or supporting existing hypotheses from quantitative data; 3) guides a statistical analysis of data and checks its validity. 6.3 Implications of (Good/Bad) Data Visualization Raw data is often meaningless or their meaning is not easily understood. When people face a large set of measurements, they are unable or unwilling to spend the time required to process it. Technological advances of the Digital Age contribute to an ever-growing pool of “big data” and our ability to collect this type of information becomes easier and easier. Thus filtering, visualization, and interpretation of data become increasingly important. Raw data is often meaningless or their meaning is not easily concluded. When people face a large set of measurements they are unable or unwilling to spend the time required to process it. Our modern living contributes to an ever-growing pool of “big data” and our ability to collect this type of information becomes easier and easier. Thus filtering, visualization, and interpretation of data become increasingly important. We should understand how best to derive meaning from data, but first we should understand why its presentation in graphical format is so powerful. While the ideal purpose of data visualization is to facilitate understanding of data, visualization can also be used to mislead. Some of the main methods of doing so are omitting baselines, axis manipulation, omitting data, and ignoring graphing convention. Omitting baselines is used to imply a greater difference between two categories, such as in poll results comparing political parties. Axis manipulation by increasing the highest value on the y-axis affects the visibility of a slope, making data with an otherwise visible trend appear flat. Omitting selected data points or narrowing the window of a graph is used to hide an overall trend, such as a graph of a stock only showing a current trend and hiding previous bubbles. Graphs can also be designed to subvert convention so that at first glance the graph is conveying the opposite message, for example, by using the reader’s associations of colors and temperature to create a graph where hot is blue and cold is red. Principle Description 1. Easy Recall People can process images more quickly than words. When data is transformed into images, the readability and cognition of the content greatly improve. While people can only remember just 10% of what they hear and 20% of what they read, retention jumps up to 80% when they for visual information with interaction. 2. Providing Window for Perspective With infographics you can pack a lot of information into a small space. Colors, shape, movement, the contrast in scale and weight, and even sound can be used to denote different aspects of the data allowing for multi-layered understanding (Mullis 2015). 3. Enable Qualitative Analysis Color, shape, sounds, and size can make evident relationships within data very intuitive. When data points are represented as images or components of an entire scene, readers are able to see the big picture and understand how the information fits within a larger context. 4. Increase in User Participation Interactive infographics can substantially increase the amount of time someone will spend with the content. Because of their impact, infographics are widely used nowadays. A quick google will produce a huge array of great examples — as well as poor ones. Because while people recognize the value of information graphic design, and a number of tools are available today that make the creation of them possible for the layperson, it doesn’t mean that they’re all successful or even necessary. 6.4 General Guidelines for Ethical Visuals (Skau 2012) Data visualization is an up-and-coming field that currently does not have many established regulations. This makes it easy to manipulate readers without technically reporting false information. However, certain standards should be followed in order to generate meaningful and accurate visuals. The process can be broken down into three steps, each with its own set of guiding rules. 6.4.1 Data Collection The first step in any project is gathering the data. This is relatively simple and does not offer much of an opportunity to introduce confusion. The one thing to remember is to always get data from a reliable source. The data provides the foundation for the entire project and must ,therefore, be trustworthy and verifiable. 6.4.2 Data Analysis This is the stage where the discoveries are made and provided the first opportunity to manipulate the story for good or bad. There is usually a lot of data cleaning to do before creating a visual representation, but all manipulation should make sense. Code should be shared so anyone can follow the entire process. It is also important to explicitly state any assumptions taken, though these should be kept to a minimum. Here it is important to look at what the source data actually shows its ethical responsibility of presenters for careful analysis of the data and find true stories from them. As the amount of data grows, it becomes harder to catch up with it. Therefore, data strategy becomes the necessary part of the success in applying data to the business. Then how data visualization become an important tool in your strategic kit? First, it helps you cleanse your data. Secondly, it allows you to identify and extract meaningful information from it. Finally, data visualization tools enable continuous real-time monitoring of how your strategy and now data-driven decisions influence performance and business outcomes. In other words, these tools visualize not only the data, but also the results, and help correct and optimize strategy on the go. 6.4.3 Design Once a story is found, it must be presented in an honest way. This is where deceptive techniques could be tempting to make a stronger argument. An experienced individual will know how to spot these deceptions and disregard any findings. This ultimately hurts the credibility of the author and anyone else involved in the publication. Visualization should not be used to intentionally hide or confuse the truth, it should not seek to mislead the uninformed. Visualization has great power, and as they say, with great power comes great responsibility. 6.5 Defintions of Data Deception and Graphic Integrity Data visualization is a powerful communication tool to support arguments with numbers in a way that is accessible and engaging. It is becoming more and more popular to communicate and support arguments nowadays. More people than ever before are making their own charts and infographics, which is presenting a unique problem. Despite the availability of some great charting resources and resources online to create and design amazing data products, we are witnessing an influx of poorly-designed misleading or downright deceptive data visualizations (???),(???). So what does data deception mean? Data deception, defined by School of Law at the New York University, is “a graphical depiction of information, designed with or without an intent to deceive, that may create a belief about the message and/or its components, which varies from the actual message.” Deceptive, misleading, or distorted graphs are those that intentionally or unintentionally skew the data, and result in a representation of incorrect conclusions. Edward Tufte already introduced the concept of graphical integrity in his book and presented six principles of graphic integrity. Here are the principles from the book: The representation of numbers, as physically measured on the surface of the graphic itself, should be directly proportional to the numerical quantities measured. Clear, detailed, and thorough labeling should be used to defeat graphical distortion and ambiguity. Write out explanations of the data on the graphic itself. Label important events in the data. In time-series displays of money, deﬂated and standardized units of monetary measurement are nearly always better than nominal units. The number of information-carrying (variable) dimensions depicted should not exceed the number of dimensions in the data. Show data variation, not design variation. Graphics must not quote data out of context. There are some ways in which distorted graphs can be created (Robertson 2018),(???): Tool Description Improper scaling of y-axis This is one of the classic misleading graphs. Instead of scale starting from zero or a baseline, y-axis is scaled conveniently to highlight the differences among bins. Improper labeling of graphs Lack of labels make the graph hard to interpret for the reader and lead to wrong conclusions. Paired graphs on different scale It is not a fair comparison if two elements are plotted side-by-side, on a different scale and compared. This makes one graph look better than the other, even when it is not. Dual axis with different scales If we are plotting two elements on the same graph with different scales, even if the axes are properly labeled, it is assumed that both axes are on the same scale. Incomplete data Short-term graphs are made to manipulate the trend, which will not be seen otherwise. Time-series data are cut intentionally to show a trend within a particular period to create a more favorable visual impression. 6.6 Visual Lies (Bishop 2017) focuses on a few methods that data visualizers utilize to mislead users about research findings. For each method, the author has highlighted the signifiers that are manipulated to promote an unrealistic understanding of the visualized data. The author has concentrated on examples of three areas to create deceptive data visualization: size, segmentation, and graph type. 6.6.1 Size Size signifies quantity, volume or degree of variables within a data. In first figure, the y-axis from the graph to the right is cut when transcribed onto the graph on the left. Here both the graphs show the same data but the one on the left represents the data in a misleading fashion because of the way the axis is cut, and the result is that interest rates have increased drastically from 2008 to 2012 – a misinterpretation that is avoided in the graph on the right. 6.6.2 Quantity Quantity is measures size. When depicting points on a scatter plot, the author suggests that it is helpful to manipulate the size the points to represent differing values of a variable that is not represented on the x and y axes. The following graph shows quantity as a two completely different measures. One chart uses quantity as area and other uses it as radius. The result is that the differences in quantity between points on such a scatter plot would appear more dramatic than they should be. 6.6.3 Segmentation Figure shows an example of segmentation with a deceptive instance of binning given in the legend on the left. Segmentation can be used to show category, parts, domains or ranges within a chart. The author states that correct use of segmentation can be a powerful tool to enhance understanding, but can be deceptive if used incorrectly. This example shows how binning can be misleading; in the left figure, binning is not done appropriately, and it is therefore difficult to come up with actual values of the data. Figure 3: 6.6.4 Graph Two graphs that are often misrepresented are pie-charts and maps. In the following figure, the author explains that pie-charts cannot be compared accurately to one another. When striving for an accurate portrayal of values, they should be avoided. The author further states that it would be difficult to understand the pie-charts had the numbers not been given. Alberto Cairo addresses into the ethical ‘why’ of data visualization in this article, while still grounding the discussion in a straightforward analysis of what to do and what not to do. He emphasizes that the effectiveness of the communicative display is as important as the information itself. This makes intuitive sense because useful information is rendered utterly useless if no one can understand it. The author also asserts that when showing spatial data analysis, always show population density when visualizing values that are person-dependent. On a heat map where color signifies quantity, The author suggests that a user will be drawn to the colors that a legend indicates are most extreme. In following figure, areas that are darkest are simply the most population-dense regions of the United States. Without accounting for population density, the newly created map may look the same as hundreds of maps bearing a striking resemblance to the figure, which are falsely considered informative and are regularly shared across social media sites. The above pointers are helpful when analyzing a deceptive version of a data product. However, data visualizers need to carefully draw the line between creating misleading graphs that tell a different story and developing deceptive versions that intend to exaggerate. This should be applied in our projects and can also be used to enhance our understanding of data visualization products. Misleading graphs are sometimes deliberately misleading and sometimes it’s just a case of people not understanding the data behind the graph they create (Andalde 2014). But some real life misleading graphs go above and beyond the classic types. Some are intended to mislead, others are intended to shock. The “classic” types of misleading graphs include cases where: 6.6.5 The Missing Baseline For example, the vertical scale is too big or too small, skips numbers, or does not start at zero. For example, in the graph below, you might be thinking that the graph on the right shows that The Times makes double the sales of The Daily Telegraph. However, a closer look at the scale reveals that although The Times does make more sales, it is only beating the competition by about 10%. 6.6.6 The graph is not labeled properly A graph may have the correct figures but still mislead its audience. This one used a BIG HEADLINE that suggests to its audience that 5.3% of children get spinal cord injuries, which is a pretty scary statistic for parents. But the real figure is about .0000003% (based on 2000 injuries per year out of a population of around 74,000,000). And for the figure 1 used in this article, “Misleading Graphs: Displaying a Change in One Variable Using Area or Volume” (Robbins 2012), the label for the smaller triangle in this graph says $26.4 while the label for the larger triangle says $114.6. $114.6 is 4.34 times $26.4. It certainly looks to me as if more than 4.34 smaller triangles will fit in the larger triangle. It is the altitudes of the triangles that are proportional to the numbers in the labels. 6.6.7 Data is left out Only including part of the data is also an easy opportunity to mislead. The following graph only uses temperatures of the first half of the year to prove it was rising dramatically. For more examples and inspirations on misleading or deceptive graphs refer the following articles: Bar charts without zero &amp; evenly spaced tick marks for uneven intervals: (Robbins 2011) Graphs not drawn to scale:(Robbins 2012) 6.6.8 Treating correlation as causation Even if the labels and data in your graph are correct, the conclusion is not necessarily logically correct. A correlation between X and Y does not automatically indicate that the change in one variable is caused by the change in the values of the other one, i.e. correlation does not imply causation. Viewers should bear in mind that such visuals only present the correlation between ice cream sold and murders, not than causation. Figure 6.1: A strange correlation between ice cream sales and murders (Source: (Harlin 2013)) Another trick for creating misleading graphs is an axis change: Changing the y-axis maximum affects how the information in the graph is perceived. A higher maximum will make the graph to appear less volatile or steep than a lower maximum. The axis can also be altered to deceive by changing the ratio of a graph’s dimensions, as demonstrated in the below graphs. While not technically wrong, improper extraction or tactic omitting data, when only a certain chunk of data is included, is certainly misleading. This is more common in graphs that have time as one of their axes. Visualizations should be simple and easy to remember ,but at the same time it should contain the essence of responsible visualization. The make final results pure, ethical procedures need to be practiced throughout all the steps of visualization. In the data visualization terms, we call it truncated graph. A truncated graph (also known as a torn graph) has a y-axis that does not start at 0. These graphs can create the impression of important change where there is relatively little change.Truncated graphs are useful in illustrating small differences.[16] Graphs may also be truncated to save space. Commercial software such as MS Excel will tend to truncate graphs by default if the values are all within a narrow range. Truncating graphs make the readers to change their judgement for something that is not significant looks like a huge difference. A example of using good data in a misleading graph to fool readers comes from Fox News. (“Data Mining Vs Data Visualization - Which One Is Better” 2018) References "],
["conclusion.html", "Chapter 7 Conclusion", " Chapter 7 Conclusion Reflection, Key Learnings, Outlook "],
["references-1.html", "References 7.1 More ways to improve your visualization design 7.2 Useful Links on Data Visualization Trends, Tutorials and Research Papers 7.3 Resources for Aspiring Data Visualists", " References 2.1 The History of Data Visualization Author: Dashboard Insight, Dashboard Insight, 2013 URL: http://www.dashboardinsight.com/news/news-articles/the-history-of-data-visualization.aspx 2.2 Current research: Deceptive visualizations Author: Infogram, 2016 URL:https://medium.com/@Infogram/study-asks-how-deceptive-are-deceptive-visualizations-8ff52fd81239 Author: Agata Kwapien in Data Visualization, 2015 URL: https://www.datapine.com/blog/misleading-data-visualization-examples/ 2.3 A Brief History of Data Visualization,York University. Auhtor: Michael Friendly, 2006 URL:http://www.datavis.ca/papers/hbook.pdf Summary: This paper provides an overview of the intellectual history of data visualization from medieval to modern times,describing and illustrating some significant advances along the way. 2.4 Data Visualization and the 9 Fundamental Design Principles Auhthor: Melissa Anderson, 2017 URL:https://www.idashboards.com/blog/2017/07/26/data-visualization-and-the-9-fundamental-design-principles/ 2.5 A Practitioner Guide to Best Practices in Data Visualization.Interfaces 47(6):473-488. Auhtor: Jeffrey D. Camm, Michael J. Fry, Jeffrey Shaffer, 2017 URL: https://doi.org/10.1287/inte.2017.0916 2.6 The 7 Best Data Visualization Tools In 2017 Author: Bernard Marr, 2017 URL: https://www.forbes.com/sites/bernardmarr/2017/07/20/the-7-best-data-visualization-tools-in-2017/#3a12b8ea6c30 2.7 The Data Visualisation Catalogue URL: https://datavizcatalogue.com 2.8 The Extreme Presentation(tm) Method Aurthor: Dr. Abela, 2015 URL: http://extremepresentation.typepad.com/blog/2015/01/announcing-the-slide-chooser.html 2.9 Data Visualization: How to Pick the Right Chart Type? Author: J��nis Gulbis, 2016 URL: https://eazybi.com/blog/data_visualization_and_chart_types/ 2.10 Data Visualization Best Practices Author: melindasantos, 2017 URL: http://paristech.com/blog/data-visualization-best-practices/ http://paristech.com/blog/data-visualization-best-practices/ http://extremepresentation.typepad.com/blog/2015/01/announcing-the-slide-chooser.html 2.11 3 simple rules for intuitive dashboard design Author: Happy Dashboarding, 2017 URL: https://www.klipfolio.com/blog/intuitive-dashboard-design 2.12 How deceptive are deceptive visualizations? Author: Pandey, A. V., Rall, K., Satterthwaite, M. L., Nov, O., &amp; Bertini, E. ,2015 2.13 An empirical analysis of common distortion techniques Author: Anshul Vikram Pandey, 2015 2.14 Factors in Computing Systems: Crossings (Vol. 2015-April, pp. 1469-1478). Association for Computing Machinery. DOI: 10.1145/2702123.2702608 (2) Tufte, E. R., and Graves-Morris, P. The visual display of quantitative information, vol. 2. Graphics press Cheshire, CT,1983. 2.15 Axes of evil: How to lie with graphs Author: ANDREA ROBERTSON URL: http://hypsypops.com/axes-evil-lie-graphs/ 2.16 Misleading Graphs: Real Life Examples Author: Stephanie, February 28th, 2016 URL: http://www.statisticshowto.com/misleading-graphs/ 2.17 Next Steps for Data Visualization Research Author: UW Interactive Data Lab, 2015 URL: https://medium.com/@uwdata/next-steps-for-data-visualization-research-3ef5e1a5e349 2.18 Using Typography to Expand the Design Space of Data Visualization. She Ji: The Journal of Design, Economics and Innovation, 2(1), pp 59-87. 2.19 Using Typography to Expand the Design Space of Data Visualization Banissi, Ebad, &amp; Brath, Richard. (2016). URL: https://www.sciencedirect.com/science/article/pii/S2405872616300107. 2.20 Using Data Visualization to Find Insights in Data URL: http://datajournalismhandbook.org/1.0/en/understanding_data_7.html 2.21 Building advanced analytics application with TabPy URL: https://www.tableau.com/about/blog/2017/1/building-advanced-analytics-applications-tabpy-64916 2.22 Some best practices for visualization: URL: http://www.dataplusscience.com/files/visual-analysis-guidebook.pdf ** 2.23 Avoiding Common Mistakes with Time Series Author: TOM FAWCETT,2015** URL: https://www.svds.com/avoiding-common-mistakes-with-time-series/ 4.1 The Baseline and Working with Time Series in R Author: Nathan Yau, 2013 URL: https://flowingdata.com/2013/11/26/the-baseline/ 4.2 Using design patterns to find greater meaning in your data Author: Julie RodriguezPiotr Kaczmarek May 11, 2016 URL: https://www.oreilly.com/ideas/using-design-patterns-to-find-greater-meaning-in-your-data 4.3 Design Iron Fist Author: Jarrod Drysdale URL: https://studiofellow.com/newsletter/ 4.4 The Creative Aid Handbook URL: https://issuu.com/koorookooroo/docs/kooroo_kooroo_creative_aid 7.1 More ways to improve your visualization design From online surveys to beefed-up analytics, we’re able to gather and analyze more data than ever before. But how do you turn your findings from a dense spreadsheet into something that really makes your point? Good information design is the key. There’s a wealth of free resources out there in the form of handy little design ebooks. Design’s Iron Fist — Jarrod Drysdale The free ebook, Design’s Iron Fist, is a collection of Drysdale’s previous work all wrapped up in one neat little package. Aside from practical tutorials and processes, this book also offers help on how to get into the mindset of being a truly great designer. The Creative Aid Handbook — Kooroo Kooroo Creativity doesn’t just happen overnight. It’s something that each and every designer has to work at on a day-to-day basis. If you find that your innovative juices are running dry, The Creative Aid Handbook could be the answer. The helpful guide looks at how you can boost your intellect, foster your well-being, and, most importantly, become more creative. Designbetter.co — InVision InVision released three fantastic design books that are available for free. Each book discusses various aspects of design like design process, management, and business. Moreover, some of the materials are available in audio format. 5.1 Importance of Ethics in Visualization: Data visualization in political and social sciences Author: Andrei Zinovyev, year: N/A URL: https://github.com/mschermann/data_viz_reader/files/1933699/Zinovyev_Data_Visualization.pdf * Type Classification Type Classification is a helpful beginner’s guide to typography. It should give you the foundations you need to not only start classifying various forms of type but also understanding when and how to use them to alarmingly great effect. It covers a history of each of the type forms and the basic facts you need know about them.(???) 5.2 Data Visualization in Political and Social Sciences: Data visualization in political and social sciences Author: Andrei Zinovyev, year: N/A URL: https://github.com/mschermann/data_viz_reader/files/1933699/Zinovyev_Data_Visualization.pdf 5.3 Data Visualization in Business: How Data Visualization Impacts Your Business Strategy, Author: Katherine Lazarevich, 2018 URL: https://www.iotforall.com/data-visualization-strategy-for-business/ 5.4 Implications of (Good/Bad) Data Visualization: How Writers Use Misleading Graphs to Manipulate You Author: Ryan McCready, 2017 URL: https://venngage.com/blog/misleading-graphs/ 5.5 General Guidelines to Ethical Visuals: A Code of Ethics for Data Visualization Professionals Author: Drew Skau, 2012 URL: https://visual.ly/blog/a-code-of-ethics-for-data-visualization-professionals/ 1. Expert Data Visualization Tips for Grabbing Readers’ Attention Author: Payman Taei,2017 URL: https://towardsdatascience.com/3-expert-data-visualization-tips-for-grabbing-readers-attention-206d8c4621bf 7.2 Useful Links on Data Visualization Trends, Tutorials and Research Papers (Catalogue 2018) - You can find different types of plots used in data visualization at Data Catalogue. (Kosara 2018a) - Robert Kosara’s website which contains recent developments happening in visualization and are likely to have an impact. (Research 2018) - About Robert Kosara and his research papers. (Kosara 2018b) - Robert Kosara’s twitter handle. (FlowingData 2018) - Website which offers courses, tutorials and happenings in viz. (Infogram 2018) - An infogram helps a user making different types of plots and learning the art of visualization. Engaging infographics, reports, charts, dashboards and maps can be easily created in minutes with it. 7.3 Resources for Aspiring Data Visualists 7.3.1 Tableau Community The following groups or communities help you to explore Tableau further (Tableau Software 2018a): * It will help us enhance our learning * Get answers for most of your doubts In tableau * Post new questions and crowd source answers * Attend events, seminars and join conferences conducted locally/ globally * Give back to the community once you become an expert in that field There are very active Tableau Social Media Groups (Tableau Software 2018b): Tableau Enthusiasts: LinkedIn Group (19K members) Tableau Software Fans &amp; Friends: LinkedIn Group (45k members) 7.3.2 Blogs Here is a list of the top 10 blogs that Tableau itself suggests following (Tableau Software 2018c): Storytelling with Data Information is Beautiful Flowing Data Visualizing Data Junk Charts The Pudding The Atlas Graphic Detail US Census;FEMA Tableau Blog 2. Choose best colors for cartography visualization in a professional manner Author: Cynthia Brewer, Mark Harrower and The Pennsylvania State University URL: http://colorbrewer.org "]
]
