[
["index.html", "A Reader on Data Visualization Chapter 1 Preface 1.1 References 1.2 Images 1.3 Basic Guidelines:", " A Reader on Data Visualization MSIS 2629 Spring 2018 2018-05-14 Chapter 1 Preface This is a collaborative writing project as part of the course MSIS 2629 “Data Visualization” at Santa Clara University. The purpose of the class reader is to collaboratively engage with and reflect on data visualizations, to establish a solid theoretical background, and to collect useful practices and showcases. More information on the background of this project is available in the syllabus. The following text serves explains how we organize ourselves. 1.1 References EVERY references must be included in the book.bib file. This file uses the bibtex notation (Learn how to use bibtex here.). Most literature search engines allow you to export the reference information in Bibtex. For websites we use the following minimal notation (you may add further information - usually the more the better is a good strategy): @misc{great_viz, author = {{A great visualizer}}, year = {1982}, title = {A ficticious web page title}, howpublished = {\\url{http://great_viz_org/}}, note = {Accessed: 2018-04-26} } Particularly important is the note field. Websites change frequently, so links will break. If we do this correctly, [@great_viz] will produce (visualizer 1982). 1.2 Images Images should not be loaded from external website because the links may change. Instead download a version of the image and create a reference that contains the link to the image. For example the following image is a deceptive visualization (the bars do start at zero). An Example of a deceptive visualization Source: (Halper 2012) referenced in (Andalde 2014) The citation for the image looks like this. @misc{halper_2012, author={Halper, Daniel}, year={2012}, title = {Over 100 Million Now Receiving Federal Welfare}, url={https://www.weeklystandard.com/daniel-halper/over-100-million-now-receiving-federal-welfare}, note = {Accessed: 2018-04-26} } You have probably found this image through a different website that explains the visualization. For example the following website explains some problematic aspects of this visualization: @misc{andale_2014, author={Andalde, Stephanie}, year={2014}, title = {Misleading Graphs: Real Life Examples}, url={http://www.statisticshowto.com/misleading-graphs/}, note = {Accessed: 2018-04-26} } 1.3 Basic Guidelines: Figures and tables with captions will be placed in figure and table environments, respectively.–&gt; par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 1.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 1.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 1.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 1.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2018) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],
["introduction.html", "Chapter 2 Introduction 2.1 What is Data Visualization? 2.2 Why is Data Visualization Important? 2.3 Key Figures in the History of Data Visualization 2.4 Useful Links on Data Visualization Trends, Tutorials and Research Papers", " Chapter 2 Introduction 2.1 What is Data Visualization? Data visualization refers to representing data in a visual context to help people understand the significance of that data. A way so that information, numbers, and measurements makes sense is a form of art – the art of data visualization. Graphs do that for us. According to Friedman (2008) (???) the “main goal of data visualization is to communicate information clearly and effectively through graphical means. It doesn’t mean that data visualization needs to look boring to be functional or extremely sophisticated to look beautiful. To convey ideas effectively, both aesthetic form and functionality need to go hand in hand, providing insights into a rather sparse and complex data set by communicating its key-aspects in a more intuitive way.” Information visualization, the art of representing data in a way that it is easy to understand and to manipulate, can help us make sense of information and thus make it useful in our lives. From business decision making to simple route navigation – there’s a huge (and growing) need for data to be presented so that it delivers value. This article is a brief introduction to information visualization. It explains briefly how information visualization helps to make sense of data, how it helps to find relationships between data and confirm ideas. Some examples and common uses of information visualization is discussed below (???). 2.2 Why is Data Visualization Important? Today more than ever, data visualization represents a simple, user-friendly approach to understand data and make business decisions quickly. Here are some articles on why it is important today. 2.2.1 Chris Pittenturf’s article on the importance of data visualization to businesses The article (Pittenturf 2018), written by Chris Pittenturf, VP-Data &amp; Analytics, Palace Sports &amp; Entertainment, talks about what data visualization is and its importance to the businesses today. The article begins with a definition of data visualization in simple terms and goes on to explain how a good data visualization should be visually engaging to the reader. Chris goes on to explain the basic criterias that a data visualization should satisfy to be an effective visualization. These criterias and their brief meanings are as follows: Informative: The visualization should be able to convey the information of the data to the reader Efficient: The visualization should not be ambiguous. Appealing: The visualization should be captivating and visually pleasing. (Optional) Interactive and Predictive: The visualizations can contain variables and filters for the users to interact with the visualizations in order to predict results of different scenarios. Pittenturf goes on to give various day-to-day examples where visualization gives a better understanding of the data. One extremely simple example used by Pittenturf is that of an energy bill. Pittenturf states that as a consumer, when we receive an energy bill, we normally look at the graph in the bill first before proceeding to read the text in the bill. Pittenturf states that consumers are more likely to analyze and understand the visualizations before reading further along. The article ends with Pittenturf emphasizing the importance of data visualizations in our businesses as well as in our daily lives.It gives a simple, short and crisp understanding of what data visualization is and how it is relevant to everyone. Data visualization is an aid to get a better understanding of the complex insights that any business data provides. Most of the data used by the businesses is highly unstructured and these businesses can get a better understanding of their businesses by visualizing their data. 2.2.2 David McCandless’s TED talk on data visualization Visuals help us understand concepts that would otherwise be difficult to contextualize—for example, expenditures or valuations of extremely large amounts of money are represented in the billion dollar-o-gram by color-coded, relatively-sized boxes. Furthermore, it allows synthesis of a breadth of information to be delivered in a small, easily-digestible, aesthetically pleasing way. Visuals serve as a sort of map for a vast landscape of information—they direct your eyes to the important places and details. And the eye, as McCandless notes, is uniquely suited among our senses to process large amounts of information and detect patterns. The billion dollar-o-gram is extremely readable and rather pretty, but it seems a bit dubious to compare the predicted Iraq War cost to the “mushroomed” actual cost of Iraq and Afghanistan wars, since its purpose seems only to conflate two wars for dramatic effect (McCandless 2010). Beyond its ability to make information from several different sources and in large amounts more quickly and easily understood, data visualization can also reveal smaller interesting patterns—allowing us to play the “data detective” as McCandless calls it. In other words, as we have already discussed, data visualization can not only be extremely effective in a declarative manner, but can also be used as an exploratory tool (McCandless 2010). McCandless also postulates that we all have a latent “design literacy” that is being developed every day as we are constantly bombarded with visuals, and that our minds and our eyes are taking in this information and processing it so that we all have an intuitive sense of design, and have actually begun to demand a visual aspect to our information. This is an interesting perspective, since everyone does seem to have a sense of visual aspects—space, color, etc., but of course the time-honored adage tells us that beauty is in the eye of the beholder. So while it might be whimsical to claim that we are all designers, there is still, of course, great value in learning formal principles of design (McCandless 2010). 2.3 Key Figures in the History of Data Visualization The history of data visualization is full of incredible stories marked by major events, led by a few key players. This article introduces some of the amazing men and women who paved the way by combining art, science, and statistics.And one of them is Charles Joseph Minard, whose most famous work is the map of Napoleon’s Russian campaign of 1812 displayed in our class. Below we have some figures names with their famous works, and you can find other stories in the article (???). 2.3.1 William Playfair (1759–1823) William Playfair is considered the father of statistical graphics, having invented the line and bar chart we use so often today. He is also credited with having created the area and pie chart. Playfair was a Scottish engineer and political economist who published The Commercial and Political Atlas in 1786. This book featured a variety of graphs including the image below. In this famous example, he compares exports from England with imports into England from Denmark and Norway from 1700 to 1780. 2.3.2 John Snow (1813–1858) In 1854, a cholera epidemic spread quickly through Soho in London. The Broad Street area had seen over 600 dead, and the remaining residents and business owners had largely fled the terrible disease. Physician John Snow plotted the locations of cholera deaths on a map. The surviving maps of his work show a method of tallying the death counts, drawn as lines parallel to the street, at the appropriate addresses. Snow’s research revealed a pattern. He saw a clear concentration around the water pump on Broad Street, helping to find the cause of the infection. 2.3.3 Charles Joseph Minard (1781–1870) Charles Joseph Minard was a French civil engineer famous for his representation of numerical data on maps. His most famous work is the map of Napoleon’s Russian campaign of 1812 displaying the dramatic loss of his army over the advance on Moscow and the following retreat. You can see how many soldiers are still marching and how many died. Drawn in 1869, it is described by many as the best statistical graphic ever drawn. It represents the earliest beginnings of data journalism. 2.4 Useful Links on Data Visualization Trends, Tutorials and Research Papers (???) - You can find different types of plots used in data visualization at Data Catalogue. (???) - Robert Kosara’s website which contains recent developments happening in visualization and are likely to have an impact. (???) - About Robert Kosara and his reserach papers. (???) - Robert Kosara’s twitter handle. (???) - Website which offers courses, tutorials and happenings in viz. (???) - An infogram helps a user making different types of plots and learning the art of visualization. Engaging infographics, reports, charts, dashboards and maps can be easily created in minutes with it. References "],
["fundamentals.html", "Chapter 3 Fundamentals 3.1 A Brief History of Data Visualization 3.2 Practitioners Guide to Best Practices in Data Visualization 3.3 Fundamental Components of Design 3.4 Data Visualization Tools 3.5 What I learned recreating one chart using 24 tools 3.6 Data Visualization in Business 3.7 Pick the Right Chart Type 3.8 Contemporary Research Results &amp; What’s Next 3.9 12. Using Data Visualization to find insights in data 3.10 Best practices for visualization 3.11 Story Telling with Data 3.12 Interactive Data Visualization 3.13 Tufte’s Design Principles of graphical excellence 3.14 Visual Data Communication 3.15 Gestalt Principles for Data Viz 3.16 Resources for Aspiring Data Visualists", " Chapter 3 Fundamentals 3.1 A Brief History of Data Visualization “The only new thing in the world is the history you don’t know.” — Harry S Truman This paper provides an overview of the intellectual history of data visualization from medieval to modern times, it describes and illustrates some significant advances along the way. It is common to think of statistical graphics and data visualization as relatively modern developments in statistics. In fact, the graphic representation of quantitative information has deep roots.These roots reach into the histories of the earliest map-making and visual depiction, and later into thematic cartography, statistics and statistical graphics, medicine, and other fields. Developments in technologies (printing, reproduction) mathematical theory and practice, and empirical observation and recording, enabled the wider use of graphics and new advances in form and content (???). Phase Description Pre-17th Century: Early maps and diagrams Data visualization has comes a long way. Prior to the 17th century, data visualization already exists. Though display in other format such as maps, the content are much similar to today’s visualization, which mostly presented geologic, economic, and medical data. The earliest seeds of visualization arose in geometric diagrams, in tables of the positions of stars and other celestial bodies, and in the making of maps to aid in navigation and exploration. 1600-1699: Measurement and theory Among the most important problems of the 17th century were those concerned with physical measurement of time, distance, and space for astronomy, surveying, map making, navigation and territorial expansion. This century also saw great new growth in theory and the dawn of practical application. 1700-1799: New graphic forms With some rudiments of statistical theory, data of interest and importance, and the idea of graphic representation at least somewhat established, the 18th century witnessed the expansion of these aspects to new domains and new graphic forms. 1800-1850: Beginnings of modern graphics With the fertilization provided by the previous innovations of design and technique, the first half of the 19th century witnessed explosive growth in statistical graphics and thematic mapping, at a rate which would not be equalled until modern times. 1850–1900: The Golden Age of statistical graphics By the mid-1800s, all the conditions for the rapid growth of visualization had been established a “perfect storm” for data graphics. Official state statistical offices were established throughout Europe, in recognition of the growing importance of numerical information for social planning,industrialization, commerce, and transportation. 1900-1950: The modern dark ages If the late 1800s were the “golden age” of statistical graphics and thematic cartography, the early 1900s can be called the “modern dark ages” of visualization. There were few graphical innovations, and, by the mid-1930s, the enthusiasm for visualization which characterized the late 1800s had been supplanted by the rise of quantification and formal, often statistical, models in the social sciences. 1950–1975: Re-birth of data visualization Still under the influence of the formal and numerical zeitgeist from the mid-1930s on, data visualization began to rise from dormancy in the mid 1960s. 1975–present: High-D, interactive and dynamic data visualization During the last quarter of the 20th century data visualization has blossomed into a mature, vibrant and multidisciplinary research area, as may be seen in this Handbook, and software tools for a wide range of visualization methods and data types are available for every desktop computer. 3.2 Practitioners Guide to Best Practices in Data Visualization These are the best practices of data visualization (J.Camm and Shaffer 2017). Anticipate in advance what kind of questions the viewers will ask and then focus your visualization with respect to those questions. Brain processes stimuli from our environment to process what is important in 2 ways: unconscious (System 1 represents uncontrolled functions such as facial expressions, reactions) and conscious (System 2 represents controlled function such as solving math problems). Data Visualization leverage attributes of System 1, which has can have quick and correct impact in a most efficient manner. Three best practices of data visualization are as follows: Phase Description Design and layout matter The design and layout should facilitate ease of understanding to convey your message to the viewer. Avoid Clutter Keep it simple. To implement this always keep into account the data-ink ratio, the ratio of ink required to convey the intended meaning to the total amount of ink used in the table or chart should be as close to 1 as possible. That means, avoid ink which do not add any information. Use color purposely and effectively Use of color may be prettier and attractive but can be distractive too. Thus, color should be used only if it assist in conveying your message. The above three principles are illustrated with the help of scenarios and examples which helps to comprehend the topic in more meaningful and practical way in the article. It also gives various advantages of using the above principles. And the above best practices could be applied to all the three types of analytics: descriptive, predictive, and prescriptive. 3.2.1 Three Rules to Follow in order to Develop Intuitive Dashboards: Often a designer can become too concerned with coming up with a visual that is too intricate and overly complicated. A dashboard should be appealing but also easy to understand. Following these rules will lead to effective presentation of the data (???). 1. The dashboard should read left to right Because we read from top to bottom and left to right, a reader’s eyes will naturally look in the upper left of a page. The content should therefore flow like words in a book. It is important to note that the information at the top of the page does not always have to be the most important. Annual data is usually more important to a business but daily or weekly data could be used more often for day to day work. This should be kept in mind when designing a dashboard as dashboards are often used as a quick convenient way to look up data. 2. Group related information together Grouping related data together is an intuitive way to help the flow of the visual. It does not make sense for a user to have to search in different areas to find the information they need. 3. Find relationships between seemingly unrelated areas and display visuals together to show the relationship. Grouping unrelated data seems contradictory to the second rule, but the important thing is to tell a story not previously observed. Data analytics is all about finding stories the data are trying to tell. Once they are discovered, the stories need to be presented in an effective manner. Grouping unrelated data together makes it easier to see how they change together. 3.3 Fundamental Components of Design Artists use balance, emphasis, movement, pattern, repetition, proportion, rhythm, variety, and unity as the design foundation of any work. If you want to take your data visualization from an everyday dashboard to a compelling data story, incorporate the following nine principles of design from graphic designer Melissa Anderson (???). Criteria Description Balance A design is said to be balanced if key visual elements such as color, shape, texture, and negative spaceare uniformly distributed. Emphasis Draw viewers attention towards important data by using key visual elements. Movement Ideally movement should mimic the way people usually read, starting at the top of the page, movingacross it, and then down. Movement can also be created by using complimentary colors to pull the user’s attentionacross the page. Pattern atterns are ideal for displaying similar sets of information, or for sets of data that equal in value. Disrupting the pattern can also be effective in drawing viewers attention; it naturally draws curiosity. Repetition Relationships between sets of data can be communicated by repeating chart types, shapes, or colors. Proportion If a person is portrayed next to a house, the house is going look bigger. In data visualization, proportion can indicate the importance of data sets, along with the actual relationship between numbers. Rhythm A design has proper rhythm when the design elements create movement that is pleasing to the eye. If thedesign is not able to do so, rearranging visual elements may help. Variety Variety in color, shape, and chart-type draws and keeps users engaged with data. Including more variety can increase information retention by the viewer. But when there is too much variety, important details can be overlooked. Unity Unity across design will happen naturally if all other design principles are implemented. Balance doesn’t mean that each side of the visualization needs perfect symmetry, but it is important to have the elements of the dashboard/visualization distributed evenly. And it is important to remember the non-data elements, such as a logo, title, caption, etc. that can affect the balance of the display. Another closely related component to balance is variety, which could seem counter to balance, but when done correctly, variety can help increase the recall of information. However if overdone, too much variety can feel cluttered and blur together the images and data in the mind of the viewer. Arguably the most critical of the components is proportion. Proportion can be subtle but it can go a long way to enhancing a viewer’s experience and understanding of the data. The danger of proportion though is that it can be easy to deceive people subconsciously. Naturally images will have a greater impact on how our brains perceive the dashboard or visualization. For example, someone can change the scale of a graph or images to inflate their results and even if they write the numbers next to it, the shortcut many people will take is to interpret the data based on the image. This is why it is important we take care to accurately reflect proportion in our data visualization and remain critical of how others use proportion in their visualization. Emphasis was the component that I most related to when reading through the nine principles of design in this article. From prior experience with art through photography, I understand it is the key to be concious of what I am drawing the viewers attention to in my art. When thinking about the art design of data visualization it is also very important to remain keen on the main point of your story and how the entire visualization is either drawing the viewer to that point of emphasis or how they are being distracted or drawn elsewhere. 3.3.1 Visualization and Graphics Principles to Refocus and Guide You Jonathon Corum is a graphics designer for The New York Times and he provided a very informative talk to a strictly scientific audience on how to create and design visualizations that explain material originally created for a certain audience, i.e. the scienctific community, but now is to be related to a different audience, (in his case, the readership of the Times or maybe the public at large). The talk is filled with examples and break downs of how he has moved from his base content to the final product, all of which are illuminative examples by themselves. There is also great power in the broader themes that he is trying to convey. First, of course is knowing the audience that you are producing the work for, but even in this step, do not lose sight of the ultimate goal of conveying understanding, of explaining a concept. You are searching for a visual idea in your content that can be communicated to your audience. Some of the main highlights to help you make this connection with your audience involve: Focusing the attention: What can be removed? Realize that consistency can help eliminate unecessary distractions. There may be a trade off between losing information but conveying the ultimate meaning more clearly. Label important things rather than relying on a legend, which requires the viewer to hold on to too much information at once. Involving your audience: Give them opportunities to connect their own general knowledge on the topic. Use real world comparisons or examples to help build and relate context. Encourage comparisons and make this easy for the viewer to process and see. Explaining why: Providing context, adding time sequence details, showing movement, change and mechanism will all guide your audience in connecting the dots and understanding the significance of what you are trying to communicate. 3.4 Data Visualization Tools Due to the rise of big data analytics, there has been an increased need for data visualization tools to help understand the data. Besides Tableau, there are several other software tools one can use for data visualization like Sisense, Plotly, FusionCharts, Highcharts, Datawrapper, and Qlikview. This article is from forbes and has a brief, clear introduction about these 7 powerful software options for data visualization. This could be helpful for future reference because for different purposes I may need to use different tools. Each option has its advantages and disadvantages and this article helps highlight them. Tool Description Tableau The most popular in the group and has many users. It is simple to use, making it easy to learn and can handle large datasets. Tableau can handle big data thanks to integration with database handling applications such as MySQL, Hadoop, and Amazon AWS. Qlikview The the main competitor to Tableau and is also quite popular. Qlikview is customizable and has a wide range of features which can be a double-edged sword. These features take more time to learn and get acquianted with. However, once one gets past the learning curve, they have a powerful tool at their disposal. FusionCharts The distinctive aspect of FusionCharts is that graphics do not have to be created from scratch. Users can start with a template and insert their own data from their project. Highcharts: It proudly claims to be used by 72% of the 100 biggest companies in the world. It is a simple tool that does not require specialized training and quickly generates the desired output. Unlike some tools, Highcharts focuses on cross-browser support, allowing for greater access and use. Datawrapper: It is making a name for itself in the media industry. It has a simple user interface making it easy to generate charts and embed into reports. Plotly: It can create more sophisticated visuals thanks to integration with programming languages such as Python and R. The danger is creating something more complicated than necessary. The whole point of data visualization is to quickly and clearly convey information. Sisense: It can bring together multiple sources of data for easier access. It can even work with large datasets. Sisense makes it easy to share finished products across departments, ensuring everyone can get the information they need. 3.5 What I learned recreating one chart using 24 tools Lisa Rost’s article “What I learned recreating one chart using 24 tools” describes lessons learned from recreating one chart using many different data visualization tools (Rost 2016). The author used apps Excel, Plotly, Easycharts, Google Sheets, Lyra, Highcharts, Tableau, Polestar, Quadrigram, Illustrator, RAW, and NodeBox, as well as charting libraries ggvis, Bokeh, Highcharts, ggplot2, Processing, NVD3, Seaborn, Vega, D3, matplotlib, Vega-Lite, and R. She links her github page on the project which details the dataset she used, containing the health expectancy in years as well as GDP per capita and population for about 200 countries in the year 2015, as well has her process and results of visualizing the data using each tool. However, in the article, she focuses on the main takeaways from the exercise, which was especially interesting in the context of our class discussion on different types of tools and their respective strengths. She also provides her own graphics to help illustrate her lessons learned. Takeaway 1: “There Are No Perfect Tools, Just Good Tools for People with Certain Goals” Since data visualization is necessary in many spheres, from science to journalism, data visualization projects will often have quite disparate objectives, and the people working on them will have different requirements. And as the author aptly points out, it is impossible for one tool to satisfy the needs of every data visualizer; so there will necessarily be tools better suited to specific situations. For example, does the user need a tool for exploratory visualization of the data, or does the user seek to create graphs and charts to show the public or a specific audience something? The author also notes that the flexibility of a tool is a sticking point as well—if you need to change your data while developing a data visualization, certain apps like Illustrator will not be ideal because changing the data even slightly requires you to build the graph again from scratch. Another thing to think about is the type of chart you are trying to create—is a basic, canned bar or line graph all you need (in which case something like Excel will do the trick), or does your project necessitate a more innovative or custom chart (like something possible in D3.js)? Interactivity is another big question—only certain tools will make this possible. Takeaway 2: “There Are No Perfect Tools, Just Good Tools for People with Certain Mindsets” This section of the article is all about the difference in people’s preferences and opinions; from the people who build the tools to the users, everyone thinks differently. Therefore, certain tools will be inherently more intuitive to use for different people. Takeaway 3: “ We Still Live in an ‘Apps Are for the Easy Stuff, Code Is for the Good Stuff in the World” Basically, writing code can be scary for anyone without a coding background, but it provides more flexibility, and, as mentioned in class, code is perfectly reproducible. On the other hand, apps are much more user-friendly for the less computer science-savvy. Takeaway 4: “‘Every Tool Forces You Down a Path’” Rost quotes her former NPR Visuals teammate for the final lesson header, pointing out that tools themselves influence the development of a data visualization with their respective features, strengths, and limitations. 3.5.1 Definions of Data Deception and Graphic Integrity Data visualization is becoming more and more popular to communicate and support arguments nowdays. There are lots of great resources online to create and design amazing data products, but at the same time, there are some poorly-designed, misleading deceptive, data visualizations. Data visualization is a powerful communication tool to support arguments with numbers in a way that is accessible and engaging. More people than ever before are making their own charts and infographics, which is presenting a unique problem. Despite the availability of some great charting resources, we are witnessing an influx of poorly-designed misleading or downright deceptive data visualizations (???),(???). So what does data deception mean? Data deception, defined by School of Law at the New York University, as “a graphical depiction of information, designed with or without an intent to deceive, that may create a belief about the message and/or its components, which varies from the actual message.” Edward Tufte already introduced the concept of graphical intergrity in his book and presented six principles of graphic integrity. Here are the principles from book: The representation of numbers, as physically measured on the surface of the graphic itself, should be directly proportional to the numerical quantities measured. Clear, detailed, and thorough labeling should be used to defeat graphical distortion and ambiguity. Write out explanations of the data on the graphic itself. Label important events in the data. In time-series displays of money, deﬂated and standardized units of monetary measurement are nearly always better than nominal units. The number of information-carrying (variable) dimensions depicted should not exceed the number of dimensions in the data. Show data variation, not design variation. Graphics must not quote data out of context. Deceptive, misleading, or distorted graphs are graphs created which skews the data, intentionally or unintentionally, resulting in a representation of incorrect conclusions. There are some ways in which distorted graphs can be created (???),(???): Tool Description Improper scaling of y axis This is one of the classic misleading graphs. Instead of scale starting from zero or a baseline, y axis is scaled conveniently to highlight the differences among bins. Improper labelling of graphs Lack of labels make the graph hard to interpret for the reader and lead to wrong conclusions. Paired graphs on different scale It is not a fair comparison if two elements are plotted side-by-side, on a different scale and compared. This makes one graph look better than the other, even when it is not. Dual axis with different scales If we are plotting two elements on the same graph with different scales, even if the axes are properly labeled, it is assumed that both axes are on the same scale. Incomplete data Short-term graphs are made to manipulate the trend, which will not be seen otherwise. Time-series data are cut intentionally to just show a trend within a particular period to create a more favorable visual impression. (Bishop 2017) focuses on a few methods that data visualizers utilize to mislead users about research findings. For each method, the author has highlighted the signifiers that are manipulated to promote an unrealistic understanding of the visualized data. The author has concentrated on examples of three areas to create deceptive data visualization: size, segmentation, and graph type. ** Size ** Size signifies quantity, volume or degree of variables within a data. In first figure the y-axis from the graph to the right is cut when transcribed onto the graph on the left. Here both the graphs show the same data but the one on the left represents the data in a misleading fashion because of the way the axis is cut, and the result is that interest rates have increased drastically from 2008 to 2012 – a misinterpretation that is avoided in the graph on the right. ** Quantity ** Quantity is the measure of size. When depicting points on a scatter plot, the author suggest that it is helpful to manipulate the size the points to represent differing values of a variable that is not represented on the x and y axes. Following graph shows quantity as a two completely different measure. One chart uses quantity as Area and other uses it as radius. The result is that the differences in quantity between points on such a scatter plot would appear more dramatic than they should be. ** Segmentation ** Figure shows an example of this with a deceptive instance of binning given in the legend on the left. Segmentation can be used to show category, parts, domains or ranges within a chart. The author states that correct use of segmentation can enable users to enhance understanding and if used incorrectly can be deceptive. It is shown here binning is different in both and since in the left figure binning is not done appropriately it is difficult to come up with actual values of the data. Figure 3: ** Graph ** Two graphs that are most often misrepresented are pie-charts and maps. The author explains that in the following figure Pie charts can’t be compared accurately to one another. When striving for an accurate portrayal of values, they should be avoided. The author further states that it would be difficult to understand the pie-charts had the numbers weren’t given. The author then states that when showing spatial data analysis always show population density when visualizing values that are person-dependent. On a heat map where color signifies quantity, The author suggests that a user will be drawn to the colors that a legend indicates are most extreme. In following figure, areas that are darkest are simply the most population-dense regions of the United States. Without accounting for population density, the newly created map may look the same as hundreds of maps bearing a striking resemblance to the figure, which are falsely considered informative and are regularly shared across social media sites. The above pointers are very helpful when analyzing a deceptive version of a data product. However, as data visualizers we carefully need to draw the line between creating misleading graphs that tells a different story and deceptive version which is meant for exaggeration. The above can be applied in our projects and can also be used to enhance our understanding of great data visualization product. Misleading graphs are sometimes deliberately misleading and sometimes it’s just a case of people not understanding the data behind the graph they create (Andalde 2014). But some real life misleading graphs go above and beyond the classic types. Some are intended to mislead, others are intended to shock. The “classic” types of misleading graphs include cases where: The Missing Baseline For example, the Vertical scale is too big or too small, or skips numbers, or doesn’t start at zero, like the graph below: You might be thinking that the graph on the right shows The Times makes double the sales of The Daily Telegraph. But take a closer look at the scale and you’ll see although The Times does make more sales, it’s only beating the competition by about 10%. The graph isn’t labeled properly. Graghs can have the correct figures, but still can mislead you. This one used a BIG HEADLINE makes you think that 5.3% of children get spinal cord injuries which is a pretty scary statistic for parents. But the real figure is about .0000003% (based on 2000 injuries per year out of a population of around 74,000,000). And for the figure 1 used in this article: Misleading Graphs: Displaying a Change in One Variable Using Area or Volume (Robbins 2012), the label for the smaller triangle in this graph says $26.4 while the label for the larger triangle says $114.6. $114.6 is 4.34 times $26.4. It certainly looks to me as if more than 4.34 smaller triangles will fit in the larger triangle. It is the altitudes of the triangles that are proportional to the numbers in the labels. Data is left out Only includes part of the data like the following graph which uses temperatures of the first half of the year to prove it was rising dramatically. For more examples and inspirations on misleading graphs or deceptive graphs refer the following articles : Bar charts without zero &amp; evenly spaced tick marks for uneven intervals: (Robbins 2011) Graphs not drawn to scale:(Robbins 2012) Treating correlation as causation. Even if the labels and data in your graph is correct, it does not mean that the conclusion is logically correct. A correlation between X and Y does not automatically indicate that the change in one variable is caused by the change in the values of the other one, whereas the causation means that one event is the result of the occurrence of the other event. From the graph, we should bear in mind that it only presents the correlation between ice cream sold and murders, rather than causation. Figure 3.1: A strange correlation between ice cream sales and murders (Source: (Harlin 2013)) Another trick of misleading graph is axis change: Changing thy y-axis maximum afftect how the graph look like. A higher maximum will make the grpha to appear less volatiliy ,less strrp than a lower maximum. The other way of axis change is changing the ratio of a graph’s dimensions. This way will affect how the graph appears. We demostrate chaning the ratio of graph dimension for below graphs. It is not technically wrong but it is definitely misleading.This is often called improper extraction or tactic omitting data, when only a certain chunk of data is included.This is more common in graphs that have time as one of their axis. Here is the graph to show what it is. In the data visulization terms, we call it truncated graph. A truncated graph (also known as a torn graph) has a y axis that does not start at 0. These graphs can create the impression of important change where there is relatively little change.Truncated graphs are useful in illustrating small differences.[16] Graphs may also be truncated to save space. Commercial software such as MS Excel will tend to truncate graphs by default if the values are all within a narrow range. Truncating graphs make the readers to change their judement for something that is not significant looks like a huge differece. A example of using good data in a misleading graph to fool readers comes from Fox News. 3.6 Data Visualization in Business (Lazarevich 2018) According to an Experian report, 95% of U.S. organizations say that they use data to power business opportunities, and another 84 percent believe data is an integral part of forming a business strategy. Visualization helps data impact business in following ways: 1. Cleaning The simplest way to explain the importance of visualization is to look at visualization as the means to making sense of data. Even the most basic, widely-used data visualization tools that combine simple pie charts and bar graphs help people comprehend large amounts of information fast and easily, compared to paper reports and spreadsheets. In other words, visualization is the initial filter for the quality of data streams. Combining data from various sources, visualization tools perform preliminary standardization, shape data in a unified way and create easy-to-verify visual objects. As a result, these tools become indispensable for data cleansing and vetting and help companies prepare quality assets to derive valuable insights. 2. Extracting Known versatile tools for data visualization and analytics – Elastic Stack, Tableau, Highcharts, and more complex database solutions like Hadoop, Amazon AWS and Teradata, have wide applications in business, from monitoring performance to improving customer experience on mobile tools. New generation of data visualization based on AR and VR technology, however, provides formerly infeasible advantages in terms of identifying patterns and drawing insights from various data streams. Building 3D data visualization spaces, companies can create an intuitive environment that helps data scientists grasp and analyze more data streams at the same time, observe data points from multiple dimensions, identify previously unavailable dependencies and manipulate data by naturally moving objects, zooming, and focusing on more granulated areas. Moreover, these tools allow us to expand the capabilities of data visualization by creating collaborative 3D environments for teams. As a result, new technology helps extract more valuable insights from the same volume of data. 3. Strategizing As the amount of data grows, it becomes harder to catch up with it. Therefore, data strategy becomes the necessary part of the success in applying data to business. Then how data visualization become an important tool in your strategic kit? First, it helps you cleanse your data. Secondly, it allows you to identify and extract meaningful information from it. Finally, data visualization tools enable continuous real-time monitoring of how your strategy and now data-driven decisions influence performance and business outcomes. In other words, these tools visualize not only the data, but also the results, and help correct and optimize strategy on the go. Data visualization is one of the initial steps made to derive value from data. It’s also one of the most important steps, as it determines how efficiently analysts can work with data assets, what insights they are able to extract and how their data strategy will develop over time. Therefore, the quality and capabilities of data visualization directly influence how data impacts your business strategy and what benefits data applications can bring to the companies and their industries._ 3.7 Pick the Right Chart Type Data visualization is a combination of art and science. When it comes to the artistic aspect, there are no correct answers for doing the visualization. There are many ways to present the data. However, when making sense of facts, numbers, and measurement, better understanding is promoted by a logical path to follow. To determine the best type of chart is hard for those new to data visulization. Most people learn it by referring to other people’s work without understanding the underlying logic, so they don’t have the theory in their mind to make the judgement. When we are choosing the type of chart, we need to answer some questions: How many features would you like to show in a chart? How many data points do you want to display for each variable? Will you display time serious data or among items or groups. After answered this question, you shoul able to get a better imagenation of your ideal graph. The simple guidance for using different type of chart is line charts for tracking trends over time, bar charts to compare quantities, scatter plots for joint variation of two data items, bubble charts showing joint variation of three data items, and pie charts to compare parts of a whole. Let’s review the most commonly used chart types and expalin what circumstance should better use typical chart and the pros and conts of each type of chart. Before introduce differnt types of charts, you can use the following website to familiar with different types of charts (???). Type 1 Column Charts. This should be the most popular chart type. This chart is good to do comparison between different values when specific values are important. TBD Still have hard time to choose? There are many resources on line can help you do the decision. For example, Dr. Andre Abela create a chart selection diagram that is helpful to pick the right chart depends on the data type. The link of website is 3.7.1 Typography and Data Visualization This article discusses less common applications of typography in data visualization. While data components such as quantitative or categorical data are commonly represented by visual features like colors, sizes or shapes, utilization of boldface, font variation, and other typographic elements in data visualization are less prevalent. Highlighted in the article are preattentive visual attributes; preattentive attributes are those that perceptual psychologists have determined to be easily recognized by the human brain irrespective of how many items are displayed. Therefore, “preattentive visual attributes are desirable in data visualization as they can demand attention only when a target is present, can be difficult to ignore, and are virtually unaffected by load.” Examples of preattentive attributes are size/area, hue, and curvature. This brings us to the disparateness of the popularity of visual aspects like color and size and typographic aspects such as font variation, capitalization and bold. The authors present several possible reasons for this, beginning with the preattentiveness of visual attributes like size and hue.However, some typographic attributes such as line width or size, intensity, or font weight (a combination of the two) are considered preattentive as well. Furthermore, these visual attributes are inherently more viscerally powerful, and they are easy to code in a variety of programming languages. Technology has also perhaps previously limited the use of typographic attributes, for only recently have fine details such as serifs, italics, etc. been made readily visible to the audiences of data visualizations by technological advances. Lastly, the authors remark that it is possible the lack of variety of typographic elements used in data visualizations is due to the limited knowledge of computer scientists and other individuals pursuing data visualization in how to apply these elements effectively. While the first few proposed explanations make sense from personal experience with technology and exposure to data visualizations and design in general, the hypothesis that lack of knowledge of typographic elements in data visualization seems more plausible if it was being applied to a small group of people rather than all of the data visualization design community. I would say that it is more likely that the use of typographic elements in data visualization is less popular because there are fewer instances in which it can be used appropriately, or a status quo bias—if current visual attributes are received well, the prevailing attitude may be not to fix what is not broken. However, the authors also point out that despite the dearth of typographic attributes in data visualization, other spheres like typography, cartography, mathematics, chemistry, and programming “have a rich history with type and font attributes that informs the scope of the parameter space.” The authors continue by pointing out some tips for using typographic attributes to encode different data types, since certain attributes may be suited to particular purposes. For example, font weight (size and intensity) is ideal for representing quantitative or ordered data, and font type (shape) is better suited to denote categories in the data. Furthermore, as in typography and cartography, use of typographic attributes in data visualization raises concerns of legibility, the ability to understand both individual characters and commonalities that identify a font family, and readability, the ability to read lines and blocks of words. Often, interactivity of a visualization will not only improve functionality, but also provide a solution to readability issues by providing a means to zoom in on small text. There are a few examples of unusual/innovative use of typography for data visualization in the article, not all of which I agree are made more effective by the interesting utilization of typographic attributes, but the “Who Survived the Titanic” visualization’s use of typographic attributes allowed it to not only answer macro-questions very quickly, such as if women and children were actually first to be evacuated across classes, but also to provide answers to micro-questions, like whether or not the Astors survived. It used common visual elements like color and area to indicate whether or not a person survived and number/proportion of people, as well as typographic aspects like italic and simple text replacement to indicate gender and the passengers names. The authors round out the article by addressing the most common criticisms of typography in data visualization, the foremost one being whether or not text should even be considered an element of data visualization, since visualization connotes preattentive visual encoding of information, and text or sequential information necessitates more investment of attention to understand. Another criticism is that textual representations are not as visually appealing even when used effectively. However, the authors counter that “this criticism indicates both the strength and weakness of type? that while text may not be suited for adding style or drama to a visualization, it can be particularly powerful in situations where a finer level of detail is needed, without sacrificing representation of higher level patterns. Lastly, a label length problem is common when using text in visualizations; differing lengths of names or labels may skew perception so that longer labels seem more important than shorter labels. This problem was encountered in the Titanic visualization with the varying lengths representations of passengers�? names, and was corrected by only including a given name and a surname, the length of which could only vary so much. 3.8 Contemporary Research Results &amp; What’s Next With the development, studies and new tools applied in data visualization, more people understand it matters (???) . But given its youth and interdisciplinary nature, research methods and training in the field of data visualization are still developing. So, we asked ourselves: what steps might help accelerate the development of the field? Based on a group brainstorm and discussion, this article shares some of the proposals of ongoing discussion and experiment with new approaches (???): Adapting the Publication and Review Process: As the article states, “both ‘good’ and ‘bad’ reviews could serve as valuable guides”, so providing reviewer guidelines could be helpful for fledgling practitioners in the field. Promoting Discussion and Accretion: Discussion of research papers actively occurs at conferences, on social media, and within research groups. Much of this discussion is either ephemeral or non-public. So ongoing discussion might explicitly transition to the online forum. Research Methods Training: Developing a core curriculum for data visualization research might help both cases, guiding students and instructors alike. For example, recognizing that empirical methods were critical to multiple areas of computer science, Stanford CS faculty organized a new course on Designing Computer Science Experiments. Also, online resources could be reinforced with a catalog of learning resources, ranging from tutorials and self-guided study to online courses. Useful examples include Jake Wobbrock’s Practical Statistics for HCI and Pierre Dragicevic’s resources for reforming statistical practice. 3.9 12. Using Data Visualization to find insights in data (???) is extracted from a book known as Data Journalism Handbook and this is one of the chapters of the book. The author starts the article by introducing a very simple idea that loading any dataset into a spreadsheet can also be a form of visualization as an invisible data becomes visible in a picture form into a table. Hence the focus should not be whether we need data visualization or not but should be on which form of data visualization is best in which situation. The author then proceeds by stating that data visualization will not always unleash a readymade story on its own. Sometimes the insights are known before the visualization and sometimes an insight can be completely new. The author has given a process for finding insights in the following way: Visualize Data-&gt; Analyze -&gt; Document Insights -&gt; Transform Datasets -&gt; Visualize Data Each stage is explained in-depth further. Data Visualization can be done in many ways such as tables which are great for one dimensional data however they are bad for multi-dimensional data. Then he goes further to explain the situation where each type of visualization such as bar charts, maps, scatterplots, graphs, etc. are used. This gives a thorough understanding of when to use which type of visualization. Once we visualize the data we need to ask the following questions: What can I see in this image? Is it what I expected? Are there any interesting patterns? What does this mean in the context of the data? The basic question answer format gives an idea to the viewers about what kind of perspectives can we look at the data. Sometimes we discover something and sometimes we don’t. But the author mentions that we always learn something from the visualization. Once we document the data insights based on the above question we need to have the following points into consideration: Why have I created this chart? What have I done to the data to create it? What does this chart tell me? The above question answer format compels the viewers to think deeper about what exactly we are trying to find. Because many times the viewers are simply too overwhelmed with the size of data that they lose the basic idea. Hence this kind of approach help to stay focused. The author then mentions that based on the above insights we might have some idea about some interesting patterns. Since we already have an idea we might want to see it in more detail and hence we transform data in more details such as Zooming, Filtering, Outlier Removal. The author then explains how transformed data can help us to see a more detailed view of our insights. Further the author gives a detailed explanation of which data visualization tool to use based on the situation. The entire process given above is explained in depth with the help of examples. The technical approach listed above is practical and can be implemented easily on our data visualization projects. I liked the author’s approach because he has cleverly integrated the step-by-step process of finding insights with the technical way of handling datasets using tools such as Tableau, Python, etc. And the process can be repeated many times till we find the insights we are looking for. 3.10 Best practices for visualization This article talks about the right charts to be used for various kinds of analysis (???). It is very relevant for data science students as we would be interested in presenting our analysis using simple and effective visualizations that tell the complete story. Some of key areas for which the author highlights some best practices are for visualizing trends over time, comparison and ranking, correlation, distribution, geographical data etc. The author gives examples on how simple graphs can also become more effective by just adding a few more elements or some simple adjustments. I feel this is a great starting point to create effective charts and we may use these principles also when we start doing advanced analytics. 3.11 Story Telling with Data Story telling is an essential part of data visualization. It is extremely important to effectively communicate information through the visualization. Stikeleather (2013)’s article talked about how a visual designer tells a story with a visualization. Mainly there are five strategies that can be applied during visualization: Find the compelling narrative. Think about the audience (e.g., novice, generalist, managerial, export, exectitve) Be objective and offer balance Don’t censor Finally, Edit, Edit, Edit. 3.11.1 Corporate Scorecards and Data Visualization Corporate transparency, flat organizations, open book policies, etc. are terms executives and entrepreneurs learn about all the time (Boost Labs 2015). As the corporate world shifts towards a more open culture, the demand for open data and insights have increased dramatically. This shift has helped the overall corporate strategic planning and management process–easing the alignment of business activities towards a series of goals. Being transparent top down aligns the culture to sail towards the same North Star. The growth of corporate transparency is not only important internally, but externally as well. Corporate certifications like B Corporations certifications (B Corp), require companies to provide a transparent view on their social conscious efforts to the general public. Achieving the certification is one step of the process; the true goal is to show the world how and why the certification is truly deserved. How does data visualization play a part? Data Visualization helps reveal insights and patterns that aren’t immediately visible in the raw data. Here’s the process on how to get it done: Step Name Description 1 Perform Data Discovery and Determine The Story Before this step it is easy to underestimate the effort level it takes to pull the best insights from the data. Data manipulation products like Tableau, Domo, Pentaho, IBM’s Many Eyes, and R, among others, make insight extraction that much easier to gain understanding of data using a visual medium. The key is to start with a simple portion of your data and to start pulling basic insights to visualize and correlate with each other. This process leads towards a compound series of questions, which helps provide an overall vision to the end product. We see the effect during our discovery process, which leads to unforeseen avenues for data intelligence. 2 Data Infrastructure Setup Data infrastructures can be simple or complex depending what the end goal is. Many clients prefer to go the route of complete data integration in order to centralize their data repositories. Technologies such as Hadoop have helped by unifying disparate data sources, but other options such as data cloud environments can help produce API’s for future product deployments. Why is this important? Accessibility of data is an important foundation not only within the context of dashboards, but also the possibility of branching out to other products. 3 Product Design &amp; Development Wireframing, prototyping, and application development are the main engines to transform an idea into a final product. Products can range from static presentations/reports to full interactive applications. Mobile, tablet, TV, and workstation platforms can all be mediums to help deliver the final product. The secret to a great end product is how well the data story is conceptualized. If the story is weak then the end product will also suffer. 4 QA &amp; Product Release The best part of any project is to get it finalized and released for all to see. All data gets verified for accuracy, functionality testing (if applicable), application flow (if applicable), design testing, and remaining items are all completed. The end result is an engaging visual product for all intended audiences to see and use. 3.11.2 Comparison of Different Tools Interactive Data Visualization In Data Mining, there are different processes involve carrying out the data mining process such as data extraction, data management, data transformations, data pre-processing, etc. In Data Visualization, the primary goal is to convey the information efficiently and clearly without any deviations or complexities in the form of statistical graphs, information graphs, and plots. Also, the author listed the top 7 comparisons between data mining and data visualization, and 12 key differences between data mining and data visualization. After reading the article, you will have a very clear understanding of what are data mining and data visualization and the characters for those two techniques. 3.12 Interactive Data Visualization Interactive or Dynamic data visualization delivers today’s complex sea of data in a graphically compelling and an easy-to-understand way. It enables direct actions on a plot to change elements and link between multiple plots. It enables users to accomplish traditional data exploration tasks by making charts interactive(???). Benefits of Interactive Data Visualization Software: Absorb information in constructive ways: With the volume and velocity of data created everyday, dynamic data viz enables enhanced process optimization, insight discovery and decision making. Visualize relationships and patterns: Helps inbetter understanding of correlations among operational data and business performance. Identify and act on emerging trends faster: Helps decision makers to grasp shifts in behaviors and trends across multiple data sets much more quickly. Manipulate and interact directly with data: Enables users to engage data more frequently. Foster a new business language : Ability to tell a story through data that instantly relates the performance of a business and its assets. There are multiple ways by which interactive data visualizations can be developed: 3.12.1 D3.js D3.js stands for Data Driven Document, a JS library for interactive Big Data visualization in literally ANY way required real-time(Cabot Technology Solution 2017). This is not a tool, mind you, so a user should have a solid understanding of Javascript to work with the data and present it in a humanly-understandable form. To say more, this library renders the data into SVG and HTML5 formats, so older browsers like IE7 and 8 cannot leverage D3.js capabilities. The data gathered from disparate sources like huge-scale data sets is binded in real-time with DOMto produce interactive animations ( 2D and 3D alike) in an extremely rapid way. The D3 architecture allows the users to intensively reuse the codes across a variety of add-ons and plug-ins. Some of the key advantages are: It is dynamic, free and open source and very flexible with all web technologies, the abiity to handle big data and the functional style allows to reuse the codes. The Hitchhiker’ Guide to d3.js is a wonderful guide for self-teaching d3.js. This guide is meant to prepare readers mentally as well as give readers some fruitful directions to pursue. There is a lot to learn besides the d3.js API, both technical knowledge around web standards like HTML, SVG, CSS and JavaScript as well as communication concepts and data visualization principles. Chances are you know something about some of those things, so this guide will attempt to give you good starting points for the things you want to learn more about. It starts from the insights of learning d3.js by showing interviews with those top visualization practitioners. Then the author gives key concepts and useful features for learning visualization like d3-shape, d3 selection, d3-collection, ds-hierarchy, ds-zoom as well as d3-force. My favorite part of this guide is it lists a lot of useful resources links for learning d3.js. For example, it recommends d3 API Reference, 2000+ d3 case studies and tutorials for d3. I did my exploratory analysis version of group project on d3. And I found this guide helpful during the progress. It also includes some meetup groups here in the bay area. So, maybe we can meet data friends through the group. 3.12.2 Tableau Tableau is amidst the market leaders for the Big Data visualization, especially efficient for delivering interactive data visualization for the results derived from Big Data operations, deep learning algorithms and multiple types of AI-driven apps (AbsentData 2018). Tableau can be integrated with Amazon AWS, MySQL, Hadoop, Teradata and SAP, making this solution a versatile tool for creating detailed graphs and intuitive data representation. This way the C-suite and middle-chain managers are able to make grounded decisions based on informative and easily-readable Tableau graphs. Tableau is business intelligence (BI) and analytics platform created for the purposes of helping people see, understand, and make decisions with data. It is the industry leader in interactive data visualization tools, offering a broad range of maps, charts, graphs, and more graphical data presentations. It is a painless option when cost is not a concern and you do not need advanced and complex analysis.The application is very handy for quickly visualizing trends in data, connecting to a variety of data sources, and mapping cities/regions and their associated data. The key advantages are: It provides non technical user the ability to build complex reports and dashboard with zero coding skills. Using drag-n-drop functionalities of Tableau, user can create a very interactive visuals within minutes. It can handle millions of rows of data with ease and users can make live to connections to different data sources like SQL etc. 3.12.3 R Shiny R Shiny enables us to produce interactive data visualizations with a minimum knowledge of HTML, CSS, or Java using a simple web application framework that runs under the R statistical platform (Castañón 2016). Standalone apps can be hosted on a webpage or embedded in R Markdown documents and dashboards can be built using R shiny. It combines the computational power of R with the interactivity of the modern web. The main advantages of using R Shiny are : Its flexibility of pulling in whatever package in R that you want to solve your problem, reaping the benefits of an open source ecosystem for R and Javascript visualization libraries, thereby allowing to create highly custom applications and enabling timely, high quality interactive data experience without (or with much less) web development and without the limitations or cost of proprietary BI tools. 3.12.4 Jupyter 3.12.5 Google chart A free and powerful integration of all Google power. The tool is rendering the resulting charts to HTML5/SVG, so they are compatible with any browser. Support for VML ensures compatibility with older IE versions, and the charts can be ported to the latest releases of Android and iOS. What’s even more important, Google chart combines the data from multiple Google services like Google Maps. This results in producing interactive charts that absorb data real-time and can be controlled using an interactive dashboard. https://towardsdatascience.com/top-4-popular-big-data-visualization-tools-4ee945fe207d 3.13 Tufte’s Design Principles of graphical excellence A graph should be impressive and can obtain audience’s attention. How can we achieve this? We must consider several aspects: efficiency, complexity, structure, density and beauty. We also should consider the audience whether they will be confused about the design. Statistical graphics are kind of graphics we use a lot for data analysis so I want to summarize some principles mentioned in this Tufte’s great book.Here we must follow some principles for statistical graphics: Principle 1: Maximizing the data-ink ratio, within reason. Data-ink is the non-erasable core of a graphic, the non-redundant inkarranged in response to variation in the numbers represented. Data-ink ratio = data-ink/total ink used to print the graphic = proportion of graphic’s ink devoted to the non-redundant display of data-information This basic principle follows by two principles: Erase non-data-ink, within reason. Erase redundant data-ink, within reason. always revise and edit. (source:(???)) (source: (Plotly 2017)) (source: (Plotly 2017)) (source:(???)) The graphs will be better for more information per unit of space an d per unit of ink is displayed. Graphics are almost always going to improve as they go through editing ,revision, and testing against differernt design options. Try to figure out whehter the audience looking at the new designs be confused? Nothing is lost to those puzzled by the frame of dashes,and something is gained by those who do understand. We can also assume that if you understand the statistical graphics, most other readers will, too because it is a frequent mistake in thinking about statistical graphics to underestimate the audience. Some of the new designs may appear odd, but this is probably because we have not seen them before. Principle 2: Mobilize every graphical element, perhaps several times over, to show the data. The danger of multifunctioning elements is that they tend to generate graphical puzzles, with encodings that can only be broken by their inventor.Thus design techniques for enhancing graphical clarity in the face of complexity must be developed along with multifunctioning elements. In other words, we should try to make all present graphical elements data encoding elements.We must make every graphical element effective. Example: (source:(???)) Principle 3: maximize data density and the size of the data matrix, within reason. High performation graphics should be design with special care. As volume of data increases, data measures must shrink (smaller dots ofr scatters,thinner lines for busy time-series) (J.Camm and Shaffer 2017). Data Density = # entries in data matrix /area of data graphic Principle 4: Escape flatland – small multiples, parallel sequencing. Data is multivariate. Doesn’t necessarily mean 3D projection. How can we enhance mulitvariate data on inherently 2D surfaces? Example for small multiples. (source:(???)) Example for parallel sequencing (source:(???)) Principle 5: Macro/Micro-Provide the user with both views (overview and detail). Carefully designed view can show a macro structure (overview) as well as micro structure (detail) in one space. Example: (source:(???)) Principle 6: Utilize Layering &amp; Separation. Supported by Gestalt laws (The principles of grouping): 1. Grouping with colors 2. Using Color to separate 3. 1+1 = 3 (clutter) Example: (source:(???)) Principle 7: Utilize narratives of space and time. Tell a story of position and chronology through visual elements. Example: (source: (Periscope 2018)) (source: (Periscope 2018)) 3.14 Visual Data Communication We want visualizations to speak about the data. This article is about some tips that can help visualizations to speak: Keep it simple: Keep charts simple and easy to interpret. Instead of overloading peoples brain with lots of information, keep only the necessary things in the chart and help the audience understand quickly what’s going on. Pretty doesn’t mean effective: There is a misconception that aesthetically pleasing visualization is more effective.To draw attention, sometimes we want them to be pretty and eye-catching. But if it fails to communicate that data properly, then you’ll lose people’s interest as quickly as you gained it. Color for Numerical Scales: Color for numerical scales should be used with caution.The way you interpret a shade depends on the colors around it and sometimes it can lead to false conclusions.For data with geographical fields, it may be tempting to use maps. But maps may not be very effective for the following reasons: Leverage Color Associations: When we say strawberries we associate red color with it. If we can leverage the how people associate different colors for different things, we will not even need legend to interpret things. Color can be used to leverage long-term memory very quickly. Use Bright Colors to Highlight: To attract attention to a certain part of data, bright colors can be used. Alarm colors draw the eye quickly to areas that need attention and help get that message across. Maps Use of maps can be tricky. Geographical data doesn’t imply a map. Maps can be useful for application where proximity matters they can be great for applications where proximity matters, but for straight “what is higher” type comparisons, they’re not very effective as large regions will draw attention easier than smaller regions due to more concentrated color. 5 Second Rule: Research shows that on average modern attention span for looking at things online is less than 5 seconds. So if you can’t grab attention within 5 minutes, you’ve likely lost your viewer. Includes clear titles and instructions and tell people succinctly what the visualization shows and how to interact with it. 3.15 Gestalt Principles for Data Viz (FusionCharts 2012) is a detailed white paper PDF from FusionCharts that explores key aspects of effective data visualization in the business world, from goals to preattentive attributes to applying Gestalt Principles. Because some of the aspects such as using color and design effectively have been covered earlier on in the Fundamentals section, this summary will mainly focus on the Gestalt Principles. Data is simply a collection of many individual elements (ie, observations, typically represented as rows in a data table). In data viz, our goal is usually to group these elements together in a meaningful way to highlight patterns and anomalies. Described this way, it makes sense that Gestalt Principles are a good set of guidelines for data viz, because these principles describe how we assemble different elements into groups. The Gestalt Principles include the following: Proximity: white space can be used to group elements together and separate others Similarity: objects that look similar are instinctively grouped together in our minds Enclosure: helps distinguish between groups Symmetry Closure: we tend to complete shapes and paths even if part of them is missing Continuity: similar to closure Connection: helps group elements together as well Figure and ground: we typically notice only one of several main visual aspects of a graph; what we do notice becomes the figure, and everything else becomes the “background”. This one is especially interesting because it is not as obvious as some of the others, but is really important in matching a data viz design to its purpose. The principles are quite theoretical and in practice, preattentive attributes such as spatial position, size, and color are means of applying the principles. 3.16 Resources for Aspiring Data Visualists 3.16.1 Tableau Community The following groups or communities help you to explore Tableau further (Tableau Software 2018a): * It will help us enhance our learning * Get answers for most of your doubts In tableau * Post new questions and crowd source answers * Attend events, seminars and join conferences conducted locally/ globally * Give back to the community once you become an expert in that field There are very active Tableau Social Media Groups (Tableau Software 2018b): Tableau Enthusiasts: Linkedin Group (19K members) Tableau Software Fans &amp; Friends: LinkedIn Group (45kK members) 3.16.2 Blogs Here is a list of the top 10 blogs that Tableau itself suggests following (Tableau Software 2018c): Storytelling with Data Information is Beautiful Flowing Data Visualising Data Junk Charts The Pudding The Atlas Graphic Detail US Census and FEMA Tableau Blog References "],
["case-studies.html", "Chapter 4 Case Studies 4.1 10 Best Data Visualization Projects of 2015 4.2 15 Cool Information Graphics and Data Viz from 2016** (Kayla Darling 2017) 4.3 16 Captivating Data Visualization Examples** (Crooks 2017) 4.4 3. 15 Data Visualizations That Explain Trump, the White Oscars and Other Crazy Current Events** (???) 4.5 Connecting the Dots Behind the Election 4.6 Spies in the Skies 4.7 Green Honey 4.8 8. How People Like You Spend Their Time 4.9 Is it Better to Rent or Buy? 4.10 Two Centuries of U.S. Immigration 4.11 What’s really warming the world? 4.12 The Strengths of Animated Data Visualization 4.13 An Aging Nation: Projected Number of Children and Older Adults 4.14 From Pyramid to Pillar: A Century of Change, Population of the U.S. 4.15 A guide to Who is Fighting Whom in Syria 4.16 Adding up the White Oscars Winners 4.17 Young voters, class and turnout: how Britain voted in 2017 4.18 Uber: Crafting Data-Driven Maps 4.19 Linguistic Concepts 4.20 Kissmetrics blog: visualization of metrics 4.21 How the Recession Reshaped the Economy, in 255 Charts 4.22 21. Vizwiz blog: case studies about how to improve your visualizations 4.23 15 Data Visualizations That Will Blow Your Mind 4.24 Other sources of great visualization 4.25 Application of Data Visualization 4.26 Two Awesome Visualists 4.27 Using Shapes as Filters in Tableau When Your Fields Are Measures 4.28 Visualization of big data security: a case study on the KDD99 cup data set 4.29 Britain’s diet in data", " Chapter 4 Case Studies 4.1 10 Best Data Visualization Projects of 2015 (Nathan Yau 2015a) picks the top 10 projects for the best data visualization of 2015, for each pick, the author showed the project plot and also described the reason why he chose. So after reading this article, I have a basic understanding of what kind of characters should include in a good visualization project. 4.2 15 Cool Information Graphics and Data Viz from 2016** (Kayla Darling 2017) The author chose fifteen of the best infographics and data visualizations from 2016 and described why they think these are the best.And the following six examples are from the articles: 4.3 16 Captivating Data Visualization Examples** (Crooks 2017) 4.4 3. 15 Data Visualizations That Explain Trump, the White Oscars and Other Crazy Current Events** (???) Case studies contain valuable information about development records. The evaluation and study of case study helps show that the new design is just as usable as existing techniques, making it suitable for future development. This chapter contains some very useful case studies. Many of the case studies below come from the following articles: Visualization is like art. It speaks where words fail. There are phenomenas like the Syrian war, the number flights during Thanksgiving in the USA, the understanding of depths for developing perspective about the range of the issue, the controversy of ‘#OscarsSoWhite’, etc. on which we can write bundles of paragraphs, but they might still have scope for ambiguity. The links show some intricate visualizations of the topics like those mentioned above, and speak volumes without requiring paragraphs to explain what is going on within these visualizations. According to me, it is really interesting to see that almost anything in this world can be explained by visualizations. Visualizations are not just limited to businesses and their analytics. Wars, rescue operations, etc. can also be visualized to get a clear idea of all the details of the issues. 4.5 Connecting the Dots Behind the Election This article by the New York Times lists several different candidates and creates compelling visuals that link their campaigns to previous ones (Aisch and Yourish 2015)(Kayla Darling 2017). Each visual contains several different-sized dots that represent a specific campaign, administration, or other governmental organization related to the candidate’s current campaign, which are then connected by arrows. Hovering over a specific dot highlights the connections between the groups. The visual is a great way to put what would otherwise be a long slog through years of information into an easily accessible, easily viewable format so that voters can figure out where the candidates’ experiences lie. Clinton 2016 Campaign Staff 4.6 Spies in the Skies (Aldhous and Seife 2016) referenced in (Kayla Darling 2017) The map is filled with red and blue lines (representing FBI and DHS aircraft, respectively) which illustrate the flight paths of the planes. When planes circle an area more than once, the circles become darker. The circles change in accordance to day and time, and individual cities can be typed into a search bar to see the flight patterns over them. The visualization, rather creatively, almost looks like a hand-drawn map. While presenting a normally uncomfortable topic, this allows individuals to check things for themselves, hopefully providing some peace of mind. New York Flight Patterns 4.7 Green Honey (Lee 2016) referenced in (Kayla Darling 2017) The visualization spans a webpage. As you scroll down, the text changes, as do many colored dots that move over the white background. The dots are used to represent not only each colors’ hue, but the numbers that fall into each category—for example, what colors are the most popular “base” colors for English and Chinese. The continuous flow of this visualization helps really bring it together, allowing users to scroll through the information at their own pace, but also creating a seamless, creative work. 4.8 8. How People Like You Spend Their Time (Yau 2016) referenced in (Kayla Darling 2017) The visual lists several categories along one side of a graph—such as “personal care” and “work”—with a line illustrating the amount of time the average person in a certain demographic spends on each subject. Entering different statistics at the top—such as changing gender or age—causes the lines to shift to feature that demographic. The simplicity of this visualization really helps the information get across and avoids bogging down the statistics. Sometimes, less is more. 4.9 Is it Better to Rent or Buy? reference: (Bostock, Carter, and Tse 2014) The calculator includes several sloping charts. Each chart includes a factor that’ll affect how much you’ll have to pay, such as the individual cost of your home and your mortgage rates. A movable scale along the bottom of each chart allows you to enter different data, changing the “cost of rent per month” on the side. If you can find a similar house to rent for that much per month or less, it’s more cost effective to just rent the home. This visualization is incredibly thorough and a useful tool for homeowners of any age and status. 4.10 Two Centuries of U.S. Immigration (???) referenced in (Kayla Darling 2017) The interactive map shows the rate of immigration into the U.S. from other countries over the last 200 years in 10-year segments. Colored dots represent 10,000 people coming from the specified country. Countries then light up when they have one of the highest rates of migration. What makes this a good visualization is that it is engaging and easy to read and interpret. The movement of the dots draws the reader’s attention while the brightly lit countries make it easy to pick out the highest total migrations. US Immigration 4.11 What’s really warming the world? (Roston and Migliozzi 2015) referenced in (Keating and Kirk 2015) In this case study, it first claimed the background story and the analytical questions clearly. Then it analyzed each different factor separately using both verbal explanations and dynamic graphics to compare with the observed temperature movements, and then grouped related factors into Natural factors category or Human factors category. After that, it combined all the dynamic graphics into one and made the results more straightforward in terms of comparisons. In the end, the authors also provided more detailed explanations with dataset sources to support the results shown above. Overall, this case study is straightforward, easy to understand but also with enough information shown on each graphics. Visualization is like art. It speaks where words fail. There are phenomenas like the Syrian war, the number flights during Thanksgiving in the USA, the understanding of depths for developing perspective about the range of the issue, the controversy of ‘#OscarsSoWhite’, etc. on which we can write bundles of paragraphs, but they might still have scope for ambiguity. The links show some intricate visualizations of the topics like those mentioned above, and speak volumes without requiring paragraphs to explain what is going on within these visualizations. 4.12 The Strengths of Animated Data Visualization (Nathan Yau 2015b) According to me, it is really interesting to see that almost anything in this world can be explained by visualizations. Visualizations are not just limited to businesses and their analytics. Wars, rescue operations, etc. can also be visualized to get a clear idea of all the details of the issues. The page linked above includes a great example of animated data visualization showing the time people spend on daily activities throughout the day. The plot is simple and easy to interpret, but it also includes a good number of variables including time, activity type, number of people doing each activity, and the order in which activities are done. One of the plot’s biggest strengths is that by using one dot to represent each person in the study and using animation, we can actually drill down to each individual and follow them throughout the day. The accumulation of dots for each particular activity also gives us an aggregate-level view of the same data, so we get both an individual and aggregate insights. A drawback of the plot is that it is hard for our eyes to keep track of 1000 simultaneously moving dots. The author of the post addresses this by creating subsequent plots with stationary lines at key times of the day. This represents people’s movements from one activity to another without overwhelming the reader. Overall, this is an engaging, informative, and fun animated plot that has relevance and tells a story. 4.13 An Aging Nation: Projected Number of Children and Older Adults (United States Census Bureau 2018) Aging population is always a hot topic in social economics and politics. I collected several different data visualizations that show the aging population in the world. They are good examples to learn and apply to census data. This one includes bar chart and line graph to demonstrate the aging population compared with population of children. The good things about this visualization: simple to see and compare, color to differentiate the category, highlight the intersection point. 4.14 From Pyramid to Pillar: A Century of Change, Population of the U.S. (???) This is a population pyramid. “A population pyramid is a pair of back-to to histograms for each sex that displays the distribution of a population in all age groups and in gender”. It is a good candidate to compare changes in population distributions (sex, age, year). Also the shape of pyramid is used to interpret a population. To illustrate, A pyramid with a very wide base and a narrow top section suggests a population with both high fertility and death rates. It is a useful tool in the census data. (Fathom Information Design 2010) offers an annimated pyramid. This is an animated and multiple population pyramids. It used to compare different patterns across countries. One additional benefit for the interactive population pyramid is that it shows the shape changes year by year, which is useful for countinous time-series comparison. A similar project with R code is here. 4.15 A guide to Who is Fighting Whom in Syria Picking up from one of the charts shown in the above mentioned link (Keating and Kirk 2015), the visualization of ‘A guide to Who is Fighting Whom in Syria’ is one of the most interesting charts in the list. The visualization and its report can be seen at (???) Picking up from one of the charts shown in the above mentioned link (Keating and Kirk 2015), the visualization of ‘A guide to Who is Fighting Whom in Syria’ is one of the most interesting charts in the list. The visualization and its report can be seen at Who is Fighting Whom in Syria This visualization makes an extremely complicated topic like the Syrian War easily understandable. It consists of 3 different emojis in three different colours, with each (colour+facial expression) combination showing the relationship between the various groups involved in the Syrian War. When you click on each of the emoji, a small dialogue box pops up which explains the relationship between the various countries and rebel groups involved in the war. This is not only easy to understand, but it is also pleasing to the eyes. Green emoji shows ‘Friendly’ relationship Red emoji shows the ‘Enemies’ relationship Yellow emoji shows ‘Complicated’ relationship 4.16 Adding up the White Oscars Winners (???) referenced in (???) A visualization of all previous winners of the Best Actor/Actress Oscar winners can be seen here (???) in an article by Bloomberg. The writers of this article developed the attributes of the future winners of Oscars by taking up the attributes of the past winners. It is extremely interesting to see how the article shows the features of the Best Actress, Actor, movies, etc. in a simple and captivating visual. The visualization is interactive and we can click on each attribute like ‘Hair Color’, ‘Eye Color’, etc. to see what are the features of the actors and actresses who are more likely to win the Oscars. Best Actor and Best Actress Source: (???) referenced in (???) Similarly, the visualization gives information about the different aspects of movies that are more likely to win, like ‘Length’, ‘Month’, ‘Budget’, etc. Best Picture 4.17 Young voters, class and turnout: how Britain voted in 2017 (Holder, Barr, and Kommenda 2017) The article’s goal is to convey the change in party votes in the 2017 UK general election compared to votes in 2015. The change in party votes was shown with regards to three demographic factors: age, class, and ethnicity. For each factor, there are four graphs (one per political party), each illustrated in their party’s standard color. The change in percent of votes is shown as an arrow where the arrow’s shaft is the length of the difference from 2015 to 2017 while the x-axis is the demographic factor split into different bins. What makes this a good visualization is that it is very easy to read and interpret. The color-coding of the arrows and party name makes it easy to pick out the different parties and the arrow lengths highlight just how large of a change happened. For example, in the Age section, it is easy to see the pattern between the Labour party gaining many voters ages 18 to 44 and the Conservative party gaining voters ages 45 and up. UK Party Votes by Age 4.18 Uber: Crafting Data-Driven Maps (Klimczak 2016) Map visualization is very important for companies like Uber that needs to track metrics using geo space points. In this article, the designer from Uber talks about the challenges of design such visualization and their solutions. While a lot of the problems are related to the large scale of the data, there are some insights on using scatter plots and hex bins, adding trip lines and making custom tools to help make decisions. The visualization in this article is beneficial for developing geo spatial graphics. 4.19 Linguistic Concepts (Alm, Meyers, and Prud’hommeaux 2017) Following the idea behind this article, it helped understand the case study and its importance. (Orphanides 2012). The case study follows. This case study is about the linguistic concepts usage. How the data is being used and how visual graphics is used to deliver the insight. It presents an educational tool that integrates computational linguistics resources for use in non-technical undergraduate language science courses. By using the tool in conjunction with case studies, it provides opportunities for students to gain an understanding of linguistic concepts and analysis through the lens of realistic problems in feasible ways. Reference: (Alm, Meyers, and Prud’hommeaux 2017) 4.20 Kissmetrics blog: visualization of metrics (Patel 2018) Kissmetrics blog is a place where people talk about analytics, marketing and testing through narratives and metrics visualization. Metrics are important in real-life world especially when developing/promoting products. Visualization of metrics are also essential so that stakeholders can monitor performance, identify problems and deep dive into potential issues. A good example from the Kissmetrics blog is about Facebook’s Organic Reach. One important point in the blog discussed whether the Facebook’s organic reach is decreasing drastically. The general trend shows that there is a huge decline in Facebook’s page organic reach. The following graphs show that the engagement is actually increasing, meaning while the quantity of content is decreasing, the quality is increasing. This resonates with what we have learnt at class in terms of how different perspectives of interpreting data can lead to different conclusions. 4.21 How the Recession Reshaped the Economy, in 255 Charts (Ashkenas and Parlapiano 2014) The first large graph contains 255 lines to show how the number of jobs has changed for every industry in America. Using color to highlight the lines lets viewers see the specifics for each industry. By hovering over a line, the detailed information of that industry’s job trend will show up. Keeping this extra data hidden until needed makes it easier for readers to absorb information from this otherwise huge data visualization. Below the overall chart on top are subsets categorized by job sector and sub-industries. Readers can choose the industry or sector they are interested in and, like in the first graph, view the more detailed information by hovering over a line. 4.22 21. Vizwiz blog: case studies about how to improve your visualizations This is a blog about Tableau based data visualization. The author is Andy Kriebel who is a famous Tableau Zen Master. I would like to recommend this blog because it is not only practical, but also full of insights. My favorite part of this blog is so called “Makeover Monday”, which will develop a new visualization based on an original one. An intersting case study could be (???). It is a thesis but it has intersting insights about visualization using mobile data. For example, the author re-designed “The Seasonality of Confirmed Malaria Cases in Zambia Southern Province” by pointing out “what works well”, “what could be improved” and also his goals for the new visualization (ref: http://www.vizwiz.com/2018/04/malaria.html) That’s how you can learn all the insight and reason behind a good visualization. (???) Besides, this blog also includes great tips and showcases for Tableau. 4.23 15 Data Visualizations That Will Blow Your Mind (Stadd 2015) “If a picture is worth a thousand words, a data visualization is worth at least a million. As inspiration for your own work with data, check out these 15 data visualizations that will wow you. Taken together, this roundup is an at-a-glance representation of the range of uses data analysis has, from pop culture to public good.” 4.23.1 Every Satellite Orbiting Earth By David Yanofsky and Tim Fernholz, Published:Nov17,2014 Reference: (Yanofsky and Fernholz 2015) This interactive graph, built using a database from the Union of Concerned Scientists, displays the trajectories of the 1,300 active satellites orbiting the Earth as you read this. Each satellite is represented by a circular icon, color-coded by country and sized according to launch mass. 4.23.2 Simpson’s Paradox http://vudlab.com/simpsons/ The Visualizing Urban Data Idealab (VUDlab) out of the University of California-Berkeley put together this visual look at data that disproves the claim in a 1973 suit that charged the school with sex discrimination. Though the graduate schools had accepted 44% of male applicants but only 35% of female applicants, researchers later uncovered that if the data were properly pooled, there was actually a small but statistically significant bias in favor of women. That’s called a Simpson’s Paradox. 4.23.3 Charles Minard’s Visualization of Napoleon’s 1812 March https://www.edwardtufte.com/tufte/minard This classic lithograph dates back to 1869, displaying the number of men in Napoleon’s 1812 Russian army, their movements, and the temperatures they encountered along their way. It’s been called one of the “best statistical drawings ever created.” The work is an important reminder that the fundamentals of data visualization lie in a nuanced understanding of the many dimensions of data. Tools like D3.js and HTML are no good without a firm grasp of your dataset and sharp communication skills. 4.23.4 Hans Rosling’s 200 Countries, 200 Years, 4 Minutes Global health data expert Hans Rosling’s famous statistical documentary The Joy of Stats aired on BBC in 2010, but it’s still turning heads. One segment in particular is pretty mind-blowing. In “200 Countries, 200 Years, 4 Minutes,” Rosling uses augmented reality to explore public health data in 200 countries over 200 years using 120,000 numbers, in just four minutes (Hans Rosling 2010). 4.23.5 Music Timeline https://research.google.com/bigpicture/music/ Google’s Music Timeline illustrates a variety of music genres waxing and waning in popularity from 2010 to present day, based on how many Google Play Music users have an artist or album in their library, and other data such as album release dates. 4.23.6 State of the Union 2014 Minute by Minute on Twitter http://twitter.github.io/interactive/sotu2014/#p1 Twitter’s data team assembled an impressive interactive data hub that depicts how Twitter users across the globe reacted to each paragraph of President Obama’s 2014 State of the Union address. You can slice and dice the data by topic hashtag (for example, #budget, #defense, or #education) and state. Pretty powerful. 4.23.7 An Interactive Visualization of NYC Street Trees (Zapata 2014) Using data from NYC Open Data, this interactive visualization shows the variety and quantity of street trees planted across the five New York City boroughs. 4.23.8 Millennial Generation Diversity Millennial generation is bigger, more diverse than boomers (Kurtz and Yellin 2018). CNNMoney’s interactive chart showing the size and diversity of the millennial generation compared to baby boomers was built using U.S. Census Data. It turns dry numbers into an intriguing story, illustrating the racial makeup of different age groups from 1913 to present. 4.23.9 Goldilocks Exoplanets https://news.nationalgeographic.com/news/2014/04/140417-exoplanet-interactive/ Using data from the Planetary Habitability Laboratory at the University of Puerto Rico, the interactive graph plots planetary mass, atmospheric pressure, and temperature to determine what exoplanets might be home, or have been home at one point, to living beings. 4.23.10 Washington Wizards’ Shooting Stars (Lindeman and Gamio 2014) This detailed data visualization demonstrates D.C.’s basketball team’s shooting success during the 2013 season. Using stats released by the NBA, the visualization lets you examine data for each of 15 players. See how successful each person was at a variety of types of shots from a range of spots on the court, compared with others in the league. 4.23.11 U.S. Migration Patterns (Gregor Aisch, Gebeloff, and Quealy 2014) The New York Times data team mapped out Americans’ moving patterns from 1900 to present, and the results are fascinating to play around with. You can see where people living in each state were born, and to what states people move from others. 4.23.12 Selfie City (Manovich et al. 2014) Selfie City, a detailed multi-component visual exploration of 3,200 selfies from five major cities around the world, offers a close look at the demographics and trends of selfies. The team behind the project collected and filtered the data using Instagram and Mechanical Turk. Explore the differences between selfies snapped in, say, New York and Berlin, as well as those between men and women across the world. 4.23.13 The American Workday NPR tapped into American Time Use Survey data to ascertain the share of workers in a wide range of industries who are at work at any given time. The chart overlays the traditional 9 AM-5 PM standard over the graph for a reference point, helping you draw interesting conclusions. 4.23.14 Global Carbon Emissions (World Resources Institute 2014) https://www.theguardian.com/environment/ng-interactive/2014/dec/01/carbon-emissions-past-present-and-future-interactive This data visualization, based on data from the World Resource Institute’s Climate Analysis Indicators Tool and the Intergovernmental Panel on Climate Change, shows how national CO₂ emissions have transformed over the last 150 years and what the future might hold. Explore emissions by country for a range of different scenarios. 4.24 Other sources of great visualization 4.24.1 Tableau: Viz of the Day Tableau has a gallery called Viz of the Day that displays great data visualization examples created by Tableau. It is cool to see how people are using all kinds of data to create informative yet fun data visuals. Data being used is also attached so we can try to mimic what other people did as well. Describe Artists with Emoji. Using the data from Spotify, the author listed the 10 most distinctive emoji used in the playlists related to popular artists. The table being used in this visual is very straight forward to link artist to the emojis and is very easy to compare among artists. When you hover over the emoji, further information is presented. 4.25 Application of Data Visualization There are ways to use data visualization at every level of an organization. These applications lets us quickly create insightful visualizations, in minutes. It allows users to visualize data and explore the vast domain interactively. Ref: (The Telegraph 2018) Some of them are mentioned below: 4.25.1 Data Augmentation (Rojasa, Quispea, and Villegas 2015) Computer interfacing is changing everyday, it is important for our clients to adapt the technology. The language of communicating data in 3D is explored to understand ways to take advantage of all dimensions in augmented reality and virtual reality to deliver information based on the user’s perspective, interest, and urgency. Creating a mechanism to become aware of the user’s intention by analyzing the gaze through reactive design, we achieved developing a complex system for demonstrating massive amount of data and organizing it in a spatial system. The user could walk through and explore the data and interact with different data visualizations. Moving through space is used to provide different levels of detail for specific data through Z axis. Analytical engineer Steluta Iordache states virtual reality is changing the environment of data analysis. It has long been predicted that augmented reality (AR) and virtual reality (VR) will, sooner rather than later, dive head first into the mainstream of public consciousness. Now, expectations are to meeting reality, and heavy investment from tech giants such as Facebook, Samsung, and Google, this seems inevitable. However, placing the headsets and gaming – the industry most experts believe AR and VR will most dynamically disrupt – to one side, these nascent technologies can be used by corporate organisations, too. By using proper visualization, it is possible to discover a solution more easily. By using proper visualisation, it is possible to simplify understanding of a problem and discover a solution more easily. Using VR and AR you could build a more efficient visualisation of the data. Recently we have seen data integrated in the real world and users have been able to interact with that data, which is not possible with traditional methods such as plots and charts. We believe AR and VR can build the presentation of the data and show more information at the same time, and it can allow the viewer to explore the data by interacting with it. But when we analyse data it can be difficult to see the big picture while also having access to the detail. So the question is: how can AR and VR be used to understand complex data by interacting with it within a virtual environment? You can find the answer here(Michael Phillips 2017) 4.25.2 Outlier Detection (Arribas-Gil and Romo 2014) We use data visualization for outliar detection in the dataset. Different methods for outlier detection in functional data have been developed during the years. Among them, several rely on different notions of functional depth , on robust principal components, or on random projections of infinite-dimensional data into R. Also, some distributional approaches have been considered (Gervini, 2009). In functional data analysis, we observe curves defined over a given real interval and shape outliers may be defined as those curves that exhibit a different shape from the rest of the sample. Whereas magnitude outliers, that is, curves that lie outside the range of the majority of the data, are in general easy to identify, shape outliers are often masked among the rest of the curves and thus difficult to detect. Ref:(Arribas-Gil and Romo 2014). Outlier treatment is important because, it can drastically bias/change the fit estimates and predictions. A simple example is mentioned below. Outlier treatment is important because, it can drastically bias/change the fit estimates and predictions. Illustration: # Inject outliers into data. cars1 &lt;- cars[1:30, ] # original data cars_outliers &lt;- data.frame(speed=c(19,19,20,20,20), dist=c(190, 186, 210, 220, 218)) # introduce outliers. cars2 &lt;- rbind(cars1, cars_outliers) # data with outliers. # Plot of data with outliers. par(mfrow=c(1, 2)) plot(cars2$speed, cars2$dist, xlim=c(0, 28), ylim=c(0, 230), main=&quot;With Outliers&quot;, xlab=&quot;speed&quot;, ylab=&quot;dist&quot;, pch=&quot;*&quot;, col=&quot;red&quot;, cex=2) plot(cars2$dist,cars2$speed) # Plot of original data without outliers. Note the change in slope (angle) of best fit line. plot(cars1$speed, cars1$dist, xlim=c(0, 28), ylim=c(0, 230), main=&quot;Outliers removed \\n A much better fit!&quot;, xlab=&quot;speed&quot;, ylab=&quot;dist&quot;, pch=&quot;*&quot;, col=&quot;red&quot;, cex=2) Detection of Outliers is prformed using: Univariate approach Multivariate approach Multivariate Model Approach 4.25.3 Genetic Network Reconstruction Data visualization techniques are used to reconstruct genetic networks from genomics data. Reconstructed genetic networks are predicted interactions among genes of interest and these interactions are inferred from genomics data,microarray data or DNA sequence. Genomics data are generally contaminated and high-dimensional. It is important to examine and clean data carefully to attain meaningful inferences. Thus visualization tools that are used in the preprocessing of data associated with genetic network reconstruction are also reviewed and chosen wisely. 4.26 Two Awesome Visualists 4.26.1 David McCandless David McCandless is a British data-journalist and his blog “Information is Beautiful” (???) hosts some of the most visually stunning graphs, charts and maps on a wide range of topics like science, food, dogs and countries. A chart on this blog “International Number Ones: Because every country is good at something (according to data)” is an interesting and captivating work that shows which country is No.1 in what. (???) Some of the interesting findings are as follows: Country ** No.1 in ** Canada Doughnuts USA Spam Emails India Bananas Norway Pizza Eaters Togo Unhappiness Colombia Happiness The visualizations on this website are updated and revised whenever new data is available. The original version of the above mentioned graph can be seen here: (???) 4.26.2 Hans Rosling Hans Rosling took his interest in Global Health and developed stunning visualizations about it using statistical methods and data from the UN. He was a noted TED speaker and one of his most interesting TED talks is “Asia’s Rise: How and When” (???). In this, Hans shows trends of the Western countries vs Developing countries like India and China and makes predictions using stunning visualizations like the Bubble chart. In this video, he also predicts the exact date on which India and China will move ahead of USA as strong economic forces. Hans was the co-founder and developer of the foundation “Gapminder”(Ruan et al. 2017) which develops tools to help the people make sense of global data. One of the most important goals of Gapminder foundation is to end ignorance in the world by developing fact-based visualizations to show how the world really is. 4.27 Using Shapes as Filters in Tableau When Your Fields Are Measures Reference: (???) I found this article quite useful for my individual project. This article introduces the methodologies on how to use shapes as filters in Tableau when your fields Are Measures. Basically, it teaches you how to load custom shape as action filters and use them for showing different graphs with those filters which can make your visualization more interesting and interactive. You can also download the tableau file for practice. This article is very useful to analyze and redesign the different graphs presented in the article “America’s unique gun violence problem, explained in 17 maps and charts”. Ref:(Lopez 2018). This article introduces the methodologies on how to use shapes as filters in Tableau when the fields are Measures. Basically, it teaches us how to load custom shape as action filters and use them for showing different graphs with those filters which can make the visualization more interesting and interactive. You can also download the tableau file for practice. Case studies document the development record of a project.They provide the user with an insight into what occurred and relevant details of the process. A person can gain valuable knowledge that can be reused in their own projects and allow their own system to be better simply by learning from what others have done. This article explains how data visualization can enhance awareness of the data available and its importance in business decisions. The Author explains a situation where poor data visualization led to bad decisions and the impact that these decisions had. 4.28 Visualization of big data security: a case study on the KDD99 cup data set This paper utilized visualization algorithm together with big data analysis in order to gain better insights into the KDD99 data set: Abstract Cyber security has been thrust into the limelight in the modern technological era because of an array of attacks often bypassing untrained intrusion detection systems (IDSs). Therefore, greater attention has been directed on being able deciphering better methods for identifying attack types to train IDSs more effectively. Keycyber-attack insights exist in big data; however, an efficient approach is required to determine strong attack types to train IDSs to become more effective in key areas. Despite the rising growth in IDS research, there is a lack of studies involving big data visualization, which is key. The KDD99 data set has served as a strong benchmark since 1999; therefore, we utilized this data set in our experiment. In this study, we utilized hash algorithm, a weight table, and sampling method to deal with the inherent problems caused by analyzing big data; volume, variety, and velocity. By utilizing a visualization algorithm, we were able to gain insights into the KDD99 data set with a clear identification of “normal” clusters and described distinct clusters of effective attacks. To read the full paper, please follow the reference link: (???) 4.29 Britain’s diet in data This is a very good example about how to present a large amount of comprehensive data - distributed across different categories and measured in different metrics - in a simple yet effective manner, while still making it interesting to look at. The data product attempts to show how the average Briton’s diet has changed over the last 4 decades for the better (???). It does this by displaying simple trend lines that show that more harmful and rich foods are being consumed less and the healthier and leaner foods are being consumed more. It further breaks down every major food categories into tens of its constituent products, and in both the overview and deep-dive versions, provides further levers to toggle and change to massage more meaning out of the data. It also shows how the contribution of different foods to the typical diet has changed over the years. Here, we can toggle the year to see exactly how much of each food was consumed, again with another deep-dive into the constituents of every major food group. Source: (???) referenced in (???) Source: (???) referenced in (???) Such a visualization is ideal for the layman wanting to walk away with a basic but accurate understanding of the dietary changes, but also provides plenty for the more discerning viewer who might have more time and inclination to dissect and parse through the graphs. It is very difficult to use the same visual/data product to cater to both types of viewers in such a satisfactory capacity, which is what makes this particular data product so alluring and effective. It satisfies the principles of graphical excellence as stated by Edward Tufte (Tufte 2013) Graphical excellence is that which gives to the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space. References "],
["patterns.html", "Chapter 5 Patterns 5.1 Avoiding Common Mistakes with Time Series 5.2 Building advanced analytics application with TabPy** 5.3 Why pie chart is bad: a comparison with bar chart 5.4 Chose the right baseline in data visualization 5.5 Using design patterns to find greater meaning in your data 5.6 Example Visualizations of Time Series Data 5.7 5 Tips to improve Data Visualization 5.8 6. More ways to improve your visualization design 5.9 7.Tips for Tableau 5.10 8.Word Cloud 5.11 An example to back some of our theories on ‘how to tell stories using data visualization’ / ‘exploratory data visualization’ 5.12 Reusable Data Visualization Code in R 5.13 Data Mining and Data Visualization **", " Chapter 5 Patterns 5.1 Avoiding Common Mistakes with Time Series This article explains how time series data visualization can sometimes be deceptive. It first takes an example of two random time series data and plots them on a graph which gives an impression that the two are strongly correlated. But if we do some statistical testing the two do not show any relationship, this is an example of “correlation does not necessary mean causation”. In another set of examples author has taken trending two random time series data and shown how even statistical tests can give a wrong interpretation. The article then explains using visualization how a general trended time series can be different than a more controlled and measured trending time series. master 5.2 Building advanced analytics application with TabPy** (???) Imagine a scenario where we can just enter some x values in a dashboard form, and the visualization would predict the y variable!!! Here is a link that shows how to integrate and visualize data from Python in Tableau. This is especially relevant to all data science students, as this is one of the tools used for visualizing advanced analytics. The author here has given an example using data from Seattle’s police department’s 911 calls and he tries to identify criminal hotspots in the area.The author uses machine learning (spatial clustering) and creates a great interactive visualization, where you can click on the type of criminal activity and the graph will show various clusters.There are other examples and use cases that may be downloaded, and the scripts are also given by the author for anyone who is interested in trying it out. 5.3 Why pie chart is bad: a comparison with bar chart Using pie chart is usually considered as a bad idea when it comes to data visualization. But why? Here, we explore some cons of using pie chart to convey information and compare its effectiveness to bar chart (Hickey 2013) (Henry 2017) (Quach 2016). Some information may look nearly identical in pie chart. But if the data is presented with bar charts, the story is different. See figure ?? and ?? for examples. Source: (Hickey 2013) Source: (Hickey 2013) It is difficult to compare the slices of a circle to figure out the distinctions in size between each pie slice, especially when there are a lot of categories. ** See figure ?? for example. (Source: (Hickey 2013)) Pie chart is easy to be manipulated (e.g. using a 3D pie chart). See figure ?? for example. Source: (Hickey 2013) Pie chart may be useful when comparing 2 different categories with different amounts of information. Specifically, it does a better job to distinguish two parts with a 25:75 split or one that is not 50:50 as people are sensitive to a right angle or a dividing line that is not straight. But this could be simply done by showing two numbers! See figure ?? and ?? for examples. (Source: (Henry 2017)) (Source: (Henry 2017)) 5.4 Chose the right baseline in data visualization Baseline is very important to data visualization. If baseline is different, the meanning will change a lot. Now here is a case study to show the importance of baseline and how to use it in different ways. Here I use the same method for a new dataset to . # Create the data. a &lt;-rep(c(2010,2011,2012,2013,2014,2015),each = 4) b &lt;- seq(1:24) c &lt;- c(64.9,65.33,71.67,79.17,68.78,69.83,78.61,92.68,89.28,90.43,97.96,106.96,100.66,107.53,117.06,119.21,110.05,97.42,93.62,97.99,80,88.74,102.06,83) data &lt;- as.data.frame(cbind(a,b,c)) colnames(data) &lt;-c(&quot;year&quot;,&quot;quater&quot;,&quot;sales&quot;) Regular quaterly sales. We can see sales decreased a lot around 2014. The baseline here is historical sales. # Regular time series for sales par(cex.axis=0.7) data.ts &lt;- ts(data$sales, start=c(2010, 1), frequency=4) plot(data.ts, xlab=&quot;&quot;, ylab=&quot;&quot;, main=&quot;sales per quater&quot;, las=1, bty=&quot;n&quot;) Quaterly and yearly change sales. The baseline here is zero and look at the percentage changes. # Quaterly change curr &lt;- as.numeric(data$sales[-1]) prev &lt;- as.numeric(data$sales[1:(length(data$sales)-1)]) quaChange &lt;- 100 * round( (curr-prev) / prev, 2 ) barCols &lt;- sapply(quaChange, function(x) { if (x &lt; 0) { return(&quot;#2cbd25&quot;) } else { return(&quot;gray&quot;) } }) barplot(quaChange, border=NA, space=0, las=1, col=barCols, main=&quot;% change, quaterly&quot;) # Year-over-year change curr &lt;- as.numeric(data$sales[-(1:4)]) prev &lt;- as.numeric(data$sales[1:(length(data$sales)-4)]) annChange &lt;- 100 * round( (curr-prev) / prev, 2 ) barCols &lt;- sapply(annChange, function(x) { if (x &lt; 0) { return(&quot;#2cbd25&quot;) } else { return(&quot;gray&quot;) } }) barplot(annChange, border=NA, space=0, las=1, col=barCols, main=&quot;% change, annual&quot;) From this plot, it is very clear that the magnitude of drops in sales for some quaters. The sales difference compare to now. The baseline here is the current sales. # Relative to current 2015 curr &lt;- as.numeric(data$sales[length(data$sales)]) salesDiff &lt;- as.numeric(data$sales) - curr barCols.diff &lt;- sapply(salesDiff, function(x) { if (x &lt; 0) { return(&quot;gray&quot;) } else { return(&quot;black&quot;) } } ) barplot(salesDiff, border=NA, space=0, las=1, col=barCols.diff, main=&quot;Sales difference from last quater 2015&quot;) Sales difference compared to the first quater. ** The baseline here is the first quater sales.** # Relative to first quater ori &lt;- as.numeric(data$sales[1]) salesDiff &lt;- as.numeric(data$sales) - ori barCols.diff &lt;- sapply(salesDiff, function(x) { if (x &lt; 0) { return(&quot;gray&quot;) } else { return(&quot;black&quot;) } } ) barplot(salesDiff, border=NA, space=0, las=1, col=barCols.diff, main=&quot;Sales difference from first quater 2010&quot;) The difference between quater sales and mean. ** The baseline is mean now.** # difference from the mean mean &lt;- mean(as.numeric(data$sales)) salesDiff &lt;- as.numeric(data$sales) - mean barCols.diff &lt;- sapply(salesDiff, function(x) { if (x &lt; 0) { return(&quot;gray&quot;) } else { return(&quot;black&quot;) } } ) barplot(salesDiff, border=NA, space=0, las=1, col=barCols.diff, main=&quot;Sales difference from mean&quot;) So before we start to plot, we should decide the baseline we want to use. Different baseline will lead to totally different graphs. 5.5 Using design patterns to find greater meaning in your data Visualizations that show comparisons, connections, and conclusions offer analytical clarity. Patterns based on function can help you see differences and similarities more clearly, understand relationships and behaviors more intimately, and predict future results with a greater level of certainty. When these patterns are presented as visualizations, they help you 1) see comparisons, 2) make connections, and 3) draw conclusions from your data sets. The major functions can be described as: 5.5.1 Comparisons As shown in Figure 1, the bar chart with sparkline enables you to review the data at two different levels: a high-level assessment of the short-term three-month returns is represented with the bar chart, while the sparkline (the line chart below the bar) provides the details of the historical returns. Quickly and concisely, the sparkline shows you the path that has led up to the most recent returns. You can then assess that a narrow path provides consistent returns across the years while a wide path provides varied returns. Side-by-side comparisons of funds organized into two columns—% Returns and % Ahead of Benchmark—enables peer comparisons and fund-specific benchmark comparisons. Hence, you can see that not only has Global Large Cap Core provided positive returns, it has also provided the best and most consistent returns when compared to the benchmark. 5.5.2 Connections The string of charts in Figure 2 shows 10-year to year-to-date (YTD) performance returns, which can be interpreted as individual charts or a group of category charts. Similar to sounds waves, the symmetrical area charts grow equidistant from the source (the zero line) at each time interval to accentuate the returns even further. Here, the y-axis is shown in percentage. Instead of using the zero line to indicate positive or negative returns, it uses color to denote if the category returns are positive (black) or negative (red). For example, Multi Cap Russell 3000 Growth produced 20% positive returns within the one-year time period and is shown with color fill in both directions from the zero line to purposefully duplicate the large gains and specifically uses black color fill to indicate the returns are positive. As evident from the name, the symmetrical chart doubles the returns to emphasize the amount with color fill. What else can you derive from organizing the information in a spectrum of negative to positive returns? Based on this organization, three groups of categories have resulted in straight losses (red), heavy gains (black), or a mix of gains and losses across a decade of returns. The string of charts makes it easier for you to see these three groups of categories to assess their distribution. Just like sound waves, each chart is a sound bite that streams the returns for each category with a “scream” announcing a huge gain (e.g., Multi-Cap Russel 3000 Growth) or loss (e.g., Mid Cap Russel Mid Cap Growth). In some cases (e.g., Large Cap S&amp;P 500), the chart quietly announces mixed returns to adequately demand less attention. Next, you might wonder how you would have fared if you had invested in certain funds. You might ask: if I had purchased this fund five years ago, what would my return be? And what about the YTD returns? Since market timing is key to investment choices, the following presentation of hypothetical investments represents a range of results. 5.5.3 Conclusions In Figure 3, varied performance results become clear with a layered approach to show five potential entry points (10-year, 5-year, 3-year, 1-year, YTD) into an investment. For example, the International Large Cap Core fund provided 27% YTD returns, which contrast the negative returns you would have received had you invested in the fund 1, 5, or 10 years ago. Here, conclusions are derived based on known inputs with a divided review of positive or negative outcomes (shown on the y-axis). The line weights help to identify each entry point and show the range of differences between the entry points. Accordingly so, resulting returns are shown with simplified curves that connect the inputs and outputs. In this case, the chart has been customized to show an instance in which the user has opted to see the YTD return values as percentages listed to the right of each resulting output.(???) 5.6 Example Visualizations of Time Series Data Reference: (Ayalasomayajula 2016) What are some of the most common data visualizations you see in newspapers, textbooks, and corporate annual reports? Graphs showing a country’s GDP growth trends or charts capturing a company’s sales growth in the last 4 quarters would be high up on the list. Essentially, these are visualizations that track time series data – the performance of an indicator over a period of time – also known as temporal visualizations. Temporal visualizations are one of the simplest, quickest ways to represent important time series data. There are 7 handy temporal visualization styles for your time series data. Line Graph. A line graph is the simplest way to represent time series data. It is intuitive, easy to create, and helps the viewer get a quick sense of how something has changed over time. Stacked Area Chart is an area chart similar to a line chart. In an area chart, multiple variables are “stacked” on top of each other, and the area below each line is colored to represent each variable. Bar Charts represent data as horizontal or vertical bars. The length of each bar is proportional to the value of the variable at that point in time. A bar chart is the right choice for you when you wish to look at how the variable moved over time or when you wish to compare variables versus each other. Grouped or stacked bar charts help you combine both these purposes in one chart while keeping your visualization simple and intuitive. A Gantt Chart is a horizontal bar chart showing work completed in a certain period of time with respect to the time allocated for that particular task. It is named after the American engineer and management consultant Henry Gantt who extensively used this framework for project management. A Stream Graph is essentially a stacked area graph, but displaced around a central horizontal axis. The stream graph looks like flowing liquid, hence the name. Heat Map Geospatial visualizations often use heat maps since they quickly help identify “Hot spots” or regions of high concentrations of a given variable. When adapted to temporal visualizations, heat maps can help us explore two levels of time in a 2D array. Polar Area Diagram. Think beyond the straight line! Sometimes, time series data can be cyclical – a season in a year, time of the day, and so on. Polar area diagrams help represent the cyclical nature time series data cleanly. A polar diagram looks like a traditional pie chart, but the sectors differ from each other not by the size of their angles but by how far they extend out from the centre of the circle. Figure 5.1 is a stacked area chart showing time series data: Figure 5.1: Student enrollments in India from 2001-10. (Source: (Ayalasomayajula 2016)) Stacked area charts are useful to show how both a cumulative total and individual components of that total changed over time. The order in which we stack the variables is crucial because there can sometimes be a difference in the actual plot versus human perception. The chart plots the value vertically whereas we perceive the value to be at right angles to the general direction of the chart. For instance, in the figure below, a bar graph would be a cleaner alternative. Figure 5.2: Human perception vs actual value. (Source: (Ayalasomayajula 2016)) For instance, this grouped bar chart in this interactive visualization of number of deaths by disease type in India not only lets you compare the deaths due to diarrhea, malaria, and acute respiratory disease across time, but also lets you compare the number of deaths by these three diseases in a given year. By switching to the stacked bar chart view, you get an intuitive sense of the proportion of deaths caused by each disease. Figure 5.3: Two different bar charts to represent time series data. (Source: (Ayalasomayajula 2016)) To avoid clutter and confusion, make sure to not use more than 3 variables in a stacked or group bar chart. It is also a good practice to use consistent bold colors and leave appropriate space between two bars in a bar chart. Also, check out our blog on 5 common mistakes that lead to bad data visualization to learn why the base axis for your bar charts should start from zero. Figure 5.4: A typical Gantt chart. (Source: (Ayalasomayajula 2016)) Assume you’re planning the logistics for a dance concert. There are lots of activities to be completed, some of which will take place simultaneously while some can be done only after another activity has been completed. For instance, the choreographers, soundtrack, and dancers need to be finalized before the choreography can begin. However, the costumes, props, and stage decor can be planned at the same time as the choreography. With careful preparation, Gantt charts can help you plan for complex, long-term projects that are likely to undergo several revisions and have various resource and task dependencies. Gantt charts are a popular project management tool since they present a concise snapshot of various tasks spread across various phases of the project. You can show additional information such as the correlation between individual tasks, resources used in each task, overlapping resources, etc., by the use of colors and placement of bars in a Gantt chart. Figure 5.5: A stream graph showing a randomly chosen listener’s last.fm music-listening habits over time. (Source: (Ayalasomayajula 2016)) Stream graphs are great to represent and compare time series data for multiple variables. Stream graphs are, thus, apt for large data sets. Remember that choice of colors is very important, especially when there are lots of variables. Variables that do not have significantly high values might tend to get drowned out in the visualization if the colors are not chosen well. This heat map visualizes birthdays for babies born in the United States between 1973 and 1999. The vertical axis represents the 31 days in a month while the horizontal axis represents the 12 months in a year. This chart quickly helps us identify that a large number of babies were born in the later half of July, August, and September. Figure 5.6: Heat map can be useful to present 2-D time data. (Source: (Ayalasomayajula 2016)) Heat maps are perfect for a two-tiered time frame – for instance, 7 days of the week spread across 52 weeks in the year, or 24 hours in a day spread across 30 days of the month, and so on. The limitation, though, is that only one variable can be visualized in a heat map. Comparison between two or more variables is very difficult to represent. This popular polar area diagram created by Florence Nightingale shows causes of mortality among British troops in the Crimean War. Each color in the diagram represents a different cause of death. (Check out the the text legend for more details.) Figure 5.7: Source: (Ayalasomayajula 2016) Polar area diagrams are useful for representing seasonal or cyclical time series data, such as climate or seasonal crop data. Multiple variables can be neatly stacked in the various sectors of the pie. It is crucial to clarify whether the variable is proportional to the area or radius of the sector. It is a good practice to have the area of the sectors proportional to the value being represented. In that case, the radius should be proportional to the square root of the value of the variable (since area of a circle is proportional to the square of the radius). 5.7 5 Tips to improve Data Visualization 5.7.1 Comparison Include a zero baseline if possibleAlthough a line chart does not have to start at a zero baseline, it should be included if it gives more context for comparison. If relatively small fluctuations in data are meaningful (e.g., in stock market data), you may truncate the scale to showcase these variances; Always choose the most efficient visualization; Watch your placement You may have two nice stacked bar charts that are meant to let your reader compare points, but if they’re placed too far apart to “get” the comparison, you’ve already lost; Tell the whole story. Maybe you had a 30% sales increase in Q4. Exciting! But what’s more exciting? Showing that you’ve actually had a 100% sales increase since Q1. 5.7.2 Copy Don’t over explain If the copy already mentions a fact, the subhead, callout, and chart header don’t have to reiterate it; Keep chart and graph headers simple and to the point There’s no need to get clever, verbose, or pun-tastic. Keep any descriptive text above the chart brief and directly related to the chart underneath. Remember: Focus on the quickest path to comprehension; Use callouts wisely Callouts are not there to fill space. They should be used intentionally to highlight relevant information or provide additional context; Don’t use distracting fonts or elements Sometimes you do need to emphasize a point. If so, only use bold or italic text to emphasize a point—and don’t use them both at the same time. 5.7.3 Color Use a single color to represent the same type of data; Watch out for positive and negative numbers Don’t use red for positive numbers or green for negative numbers. Those color associations are so strong it will automatically flip the meaning in the viewer’s mind; Make sure there is sufficient contrast between colors; Avoid patterns Stripes and polka dots sound fun, but they can be incredibly distracting. If you are trying to differentiate, say, on a map, use different saturations of the same color. On that note, only use solid-colored lines (not dashes); Select colors appropriately; Don’t use more than 6 colors in a single layout. 5.7.4 Ordering Order data intuitively There should be a logical hierarchy. Order categories alphabetically, sequentially, or by value; Order consistently; Order evenly Use natural increments on your axes (0, 5, 10, 15, 20) instead of awkward or uneven increments (0, 3, 5, 16, 50). 5.7.5 Audience perspective Let the users lead;Know your audience,Designers should consider the way users prefer to understand information, even in choosing basic analytic approaches. For users to feel comfortable adopting and sharing insights from analytics, they must be able to explain and defend the data. 5.7.6 Use layers to tell a story While style is one form of customization, layering unique data sets on a single visualization can tell a richer narrative and connect users to the data without getting too crowded. On a map, this can be as simple as zooming in and out, but it can also involve drill-downs (choosing a data point and expanding it to show more detail), links and other shortcuts. 5.7.7 Keep it simple Analytic results shouldn’t be presented to 10 decimal places when the user doesn’t need that level of precision to make a decision or understand a concept. Effective visual interfaces avoid 3-D effects or ornate gauge designs (a.k.a. “chart junk”) when simple numbers, maps or graphs will do. +reference: (French 2017) +reference: (Steier et al. 2012) 5.8 6. More ways to improve your visualization design 5.8.1 Free eBooks All Designers Should Read From online surveys to beefed-up analytics, we’re able to gather and analyze more data than ever before. But how do you turn your findings from a dense spreadsheet into something that really makes your point? Good information design is the key. There’s a wealth of free resources out there in the form of handy little design ebooks. Design’s Iron Fist — Jarrod Drysdale The free ebook, Design’s Iron Fist, is a collection of Drysdale’s previous work all wrapped up in one neat little package. Aside from practical tutorials and processes, this book also offers help on how to get into the mindset of being a truly great designer. The Creative Aid Handbook — Kooroo Kooroo Creativity doesn’t just happen overnight. It’s something that each and every designer has to work at on a day-to-day basis. If you find that your innovative juices are running dry, The Creative Aid Handbook could be the answer. The helpful guide looks at how you can boost your intellect, foster your well-being, and, most importantly, become more creative. Designbetter.co — InVision InVision released three fantastic design books that are available for free. Each book discusses various aspects of design like design process, management, and business. Moreover, some of the materials are available in audio format. Type Classification Type Classification is a helpful beginner’s guide to typography. It should give you the foundations you need to not only start classifying various forms of type but also understanding when and how to use them to alarmingly great effect. It covers a history of each of the type forms and the basic facts you need know about them.(???) 5.9 7.Tips for Tableau Running totals Common Baseline Weighted averages Moving average Grouping by aggregates Different years comparison Appending excel sheets Bar chart totals Fixed axis when re-drawing charts Auto-fitting screen behavior depending on data selection 5.10 8.Word Cloud A Word Cloud or Tag Cloud is a visual representation of text data in the form of tags, which are typically single words whose importance is visualized by way of their size and color. It displays how frequently words appear in a given body of text, by making the size of each word proportional to its frequency. Word clouds can add clarity during text analysis in order to effectively communicate your data results.It is an effective tool for Q researchers, marketers, Non-profits, Human resources ,Educators, Politicians and journalists. ** 8.1 Pros of Word Clouds ** It is easy to understand and make an impact. It can easily be shared. It is visually engaging than a table data. It is fast and reveals the essential. They delight and provide emotional connection.. ** 8.2 Cons of Word Clouds ** Emphasis based on length of the words. Words whose letters contain many ascenders and descenders may receive more attention. They’re not very accurate. Lot of data cleaning required before generating word cloud. Context is lost. (McKee 2014) ** 8.3 Ways of generating a word cloud ** R: The procedure of creating word clouds is very simple in R with text mining package (tm) and the word cloud generator package. The major steps involved are: text mining which involves text cleaning and transformation, building term-document matrix and generating word cloud (analysis 2018). Wordle: Wordle is a toy for generating “word clouds” from text that you provide.It is very popular, free and easy to use. You do need Java though Chrome. In Wordle, you generate word clouds from text you input. Clouds can be tweaked with different color schemes, layouts, and fonts. Images created from this tool can be saved and reused (Feinberg 2014). Other popular tools include ABCya, Tagul, Tag Crowd, CloudArt. 5.10.1 Calendar View (Redproducable code for reference) (???) We have all seen the calendar views in the various data products that we worked on. Please find below an open source code that I found, this will help you replicate and create your own calendar: (???) This example demonstrates loading of CSV data, which is then quantized into a diverging color scale. The values are visualized as colored cells per day. Days are arranged into columns by week, then grouped by month and years. 5.11 An example to back some of our theories on ‘how to tell stories using data visualization’ / ‘exploratory data visualization’ (???) MIT Media Lab in collaboration with Deloitte has created a new visualization tool, that aggregates US government open source data from various sources and mines information to generate trends and stories about cities, jobs, industries etc. to the common man. Just looking at any of the open data sources would give us an idea about the vastness (breadth and depth) of the available data. It is amazing to see how they have brought it all together on a single platform in a very easy to decipher format. What caught my attention here is the categorization of Information on the website that enables the following: Easy browsing of various categories of information available at a single glance Easy search on any topic of interest and get deeper information on each Logical construction of information using data and visuals under each category Comparative Analysis of cities Variety of exploratory visualizations to learn from Most important - Stories that these data tell For e.g. Evolution of the American Worker, Poverty is bad for your health, Men still dominate in the highest paying industries, Opioid addiction damage and so many others. We think of a topic, and its possible it’s there! Value add to students, organizations, governments etc. is better understanding of your consumers, talent pool, jobs, climate, and what not, that just improves our decision-making ability manifold by spending just a few seconds on the website And for this class, the best part is that the data is also available for download. So, we can easily download this data, replicate the visuals and try to redesign and tell our own stories with this data. There is also other similar websites, that has some good visualizations on census data: (???) https://flowingdata.com/2017/04/07/automatic-visualization-is-a-bad-idea-generally-speaking/ https://yseop.com/blog/automation-making-data-visualization-smarter/ http://blog.avenuecode.com/a-ui-engineers-thoughts-on-data-visualization-tools https://www.quora.com/What-is-the-future-of-data-visualization Plug in any dataset into a magic box and it spits out a lovely visualization you can show all of your co-workers, friends, and family. That’s the promise of a lot of startups, but it doesn’t quite work that way. The goal of data visualization tools was to make understanding data easier, but more often than not it doesn’t quite go to plan. The problem is that graphics alone don’t fully explain data, and so we are inundated with queries: why did the numbers fall in whatever month? Data visualization can’t explain data, leaving room for interpretation. Although simple visualizations such as standard chart types (bar chart, line chart etc.) are already automated to a certain extend in Microsoft Office tools and other software available in the market, but full on automation where insight fountains out from any dataset is farfetched at this point, because this requires automatic analysis. Automated analysis here means that the tool or algorithm has to understand the context and also select the best visualization. The focus in today’s world has been on open source tools and technologies and these tools although being free for most part require more effort to seamlessly integrate to the current visualization workflow. As mentioned in one of the articles about D3.js: D3.js is one of the first data visualization tools that comes to mind when talking about free, open-source alternatives. It’s a JavaScript based library for creating web visualization and displays the results on the web page. However, with great power comes great responsibility. D3.js is extremely powerful and flexible, because it allows you to build amazing things with it, but as a trade-off, it’s not the easiest tool to use, so you might need to spend some time going through the helpful library documentation. At the end its not only about the tool its more about what you are trying to do; what your professor, client, business or whatever needs. 5.12 Reusable Data Visualization Code in R (Prabhakaran 2017) This site includes full sets of R code to generate specific types of graphs in ggplot2. Plots in ggplot2 are created by using “layering”. There is a base plot and then other aspects of the plot such as aesthetics, titles and labels are added on using extra code. For those who favor Python for data viz, this layering approach in R is actually similar to the syntax in Python’s matplotlib library, in which set_style and specifying the axes labels and title are done separately from the code that generates the plot itself. To provide an example the “layering” mentioned above, here is a generic snippet of code for creating a scatterplot with ggplot2 and the mtcars dataset in R base, using this website’s code as a template: library(ggplot2) theme_set(theme_bw()) #set background theme plot1 &lt;- ggplot(mtcars, aes(x = hp, y = mpg)) + geom_point(aes(col=factor(vs), size = 2)) + geom_smooth(method = &quot;loess&quot;, se = F) + xlim(c(0, 400)) + ylim(c(0, 40)) + labs(title = &quot;Horsepower vs. MPG&quot;, y = &quot;Miles Per Gallon&quot;, x = &quot;Horsepower&quot;) plot(plot1) #we have to actually call the plot() function on the plot object we created The ggplot2 package allows R users to go beyond the simple and often rudimentary-looking graphs in R and offers many ways of customizing data visualizations. In a way, the layering technique also makes it easier to remember the code to generate these plots, since geom functions for the layers remain constant and they are all included in a single line of code. 5.13 Data Mining and Data Visualization ** https://www.educba.com/data-mining-vs-data-visualization/ This article gives me a clear understanding of data mining and data visualization. In Data Mining, there are different processes involve carrying out the data mining process such as data extraction, data management, data transformations, data pre-processing, etc. In Data Visualization, the primary goal is to convey the information efficiently and clearly without any deviations or complexities in the form of statistical graphs, information graphs, and plots. Also, the author listed the top 7 comparisons between data mining and data visualization, and 12 key differences between data mining and data visualization. After reading the article, you will have a very clear understanding of what are data mining and data visualization and the characters for those two techniques. References "],
["ethics.html", "Chapter 6 Ethics 6.1 Ethical Theory and Practice from Journalism and Engineering 6.2 Importance of Ethics in Visualization 6.3 Implications of (Good/Bad) Data Visualization 6.4 General Guidelines to Ethical Visuals", " Chapter 6 Ethics 6.1 Ethical Theory and Practice from Journalism and Engineering (Zinovyev 2011) Over the years, researchers and lawyers have come up with rules and practices for proper data collection and utilization, with particular attention on human subject research. Consent of the subjects to use their data, evaluation of any risk with use or collection of data, and protecting anonymity of data are some of the rules that must be considered for ethical research methods. Under U.S. law, research institutions receiving federal funding, must consider ethical aspects of their research. These rules continue to evolve. Data presented in charts can persuade viewers on the subject matter, even if viewers do not support the idea presented. This means that visualizations can also be used to deceive and there are many techniques for this leading viewers to wrong conclusions. Misleading, incomprehensible, or incredible data visualization can jeopardize people’s trust, goodwill, or faith in research and advocacy on vital human rights issues. Its ethical responsibility to create visualizations to give correct and faithful representation of data and subjects. The basic objective of data visualization is to provide an efficient graphical display for summarizing and reasoning about quantitative information. And during the last decades, political science has accumulated a large corpus of various kinds of data, which makes it gradually become a more quantitative scientific field and requires using quantitative information in the analysis and reasoning. Data visualization plays several important roles in it: it helps create informative illustrations of the data, recapitulating large amount of quantitative information on a diagram; it helps formulate new or supporting existing hypotheses from quantitative data; it guides a statistical analysis of data and checks its validity. Some useful visualization methods are: Statistical graphics and infographics; Geographical information systems (GIS); Graph visualization or network maps; Data cartography. 6.2 Importance of Ethics in Visualization (Cairo 2014) Alberto Cairo addresses the ethical ‘why’ of data visualization in this article, while still grounding the discussion in straightforward analysis of what to do and what not to do. He emphasizes that the effectiveness of the communicative display is as important as the information itself. This makes intuitive sense because useful information is rendered utterly useless if no one can understand it. Cairo sees data visualization as a harmonization of journalism and engineering. From these two disciplines, he takes the journalist ethos of truth-telling and honesty and combines this with an engineering focus on efficacy and efficiency. The result is a data visualization that contains accurate and relevant information which is clearly and concisely conveyed. Cairo describes himself as a “rule utilitarian” and uses this to explain why it is ethical or, in his words, “morally right,” to create graphics in this way. Here, it very useful to review his blogpost introducing the article. Essentially, the goal is to create the most good while doing the least harm. As such, conveying truthful and honest relevant information increases a persons understanding. Increased understanding and knowledge positively correlates with personal well-being. The information presented must be accurate and relevant. Cairo briefly addresses guidelines for this which are applicable in all information gathering fields: beware of selection bias when choosing preexisting datasets, validate the data, and include important context. False or irrelevant information doesn’t improve anyone’s decision-making capacity, so it cannot enhance well-being. Even if the information is both accurate and relevant, moral engineering pitfalls may remain. To avoid the unethical trap of inscrutable (or misleading) graphics, Cairo exhorts us to take an evidenced based approach when possible. The purpose of the graphic dictates the form it takes; aesthetic preferences should never override clarity.Again, since the ethical purpose is to improve well-being through understanding, a graphic which is confusing or misleading is unethical, regardless of intent, since it actually creates misunderstanding for the audience. While it can be a bit jarring to think of a poorly designed graphic as “morally wrong”, it is important to think of the unintended consequences of visuals which have a powerful impact on their viewers. 6.3 Implications of (Good/Bad) Data Visualization Raw data is often meaningless or their meaning is not easily concluded. When people face a large set of measurements they are unable or unwilling to spend the time required to process it. Our modern living contributes to an ever-growing pool of “big data” and our ability to collect this type of information becomes easier and easier. Thus filtering, visualization, and interpretation of data become increasingly important. We should understand what to do with data, but first we should understand why their presentation in graphical format is so powerful. Principle Description 1. Easy Recall People can process images more quickly than words. When data is transformed into images, the readability and cognition of the content greatly improves. While people can only remember just 10% of what they hear and 20% of what they read, retention jumps up to 80% when they for visual information with interaction. 2. Providing Window for Perspective With infographics you can pack a lot of information into a small space. Colors, shape, movement, contrast in scale and weight, and even sound can be used to denote different aspects of the data allowing for multi-layered understanding (Mullis 2015). 3. Enable Qualitative Analysis Color, shape, sounds, and size can make evident relationships within data very intuitive. When data points are represented as images or components of an entire scene, readers are able to see the big picture and understand how the information fits within a larger context. 4. Increase in User Participation Interactive infographics can substantially increase the amount of time someone will spend with the content. Because of their impact, infographics are widely used nowadays. A quick google will produce a huge array of great examples — as well as poor ones. Because while people recognize the value of information graphic design, and a number of tools are available today that make the creation of them possible for the layperson, it doesn’t mean that they’re all successful or even necessary. 6.3.0.1 Misrepresentation through Data Visualization While the ideal purpose of data visualization is to improve others’ understanding of the data presented, visualization can also be used to mislead. Some of the main methods of doing so are omitting baselines, axis manipulation, omitting data, and going against graphing convention. Omitting baselines is used to imply a greater difference between two categories, such as in poll results comparing political parties. Axis manipulation by increasing the highest value on the y-axis affects the visibility of a slope, making data with an otherwise visible trend appear flat. Omitting selected data points or narrowing the window of a graph is used to hide an overall trend, such as a graph of a stock only showing a current trend and hiding previous bubbles. Graphs can also be designed to subvert convention so that at first glance the graph is conveying the opposite message, for example, by using the reader’s associations of colors and temperature to create a graph where hot is blue and cold is red. 6.4 General Guidelines to Ethical Visuals (Skau 2012) Data visualization is an up and coming field that currently doesn’t have many regulations. This makes it easy to manipulate readers without technically reporting false information. However, certain standards should be followed in order to generate meaningful visuals. The process can be broken down into three steps, each with its own set of guiding rules. 1. Data Collection The first step in any project is gathering the data. This is relatively simple and does not offer much of an opportunity to introduce confusion. The one thing to remember is to always get data from a reliable source. The data provides the foundation for the entire project and must therefore be trustworthy and verifiable. 2. Data Analysis This is the stage where the discoveries are made and provides the first opportunity to manipulate the story for good or bad. There is usually a lot of data cleaning to do before creating a visual representation, but all manipulation should make sense. Code should be shared so anyone can follow the entire process. It is also important to explicitly state any assumptions taken, though these should be kept to a minimum.Here it is important to look at what the source data actually shows.its ethical responsibility of presenters for careful analysis of the data and find true stories from them. 3. Design Once a story is found, it must be presented in an honest way. This is where deceptive techniques could be tempting to make a stronger argument. An experienced individual will know how to spot these deceptions and disregard any findings. This ultimately hurts the credibility of the author and anyone else involved in the publication. Visualization should not be used to intentionally hide or confuse the truth, it should not mislead the uninformed. Visualization has got great power and so does lots of responsibility. References "],
["conclusion.html", "Chapter 7 Conclusion", " Chapter 7 Conclusion Reflection, Key Learnings, Outlook "],
["references-1.html", "References", " References "]
]
